<!DOCTYPE html>
<html lang="en">

<head>
    <title>MyArxiv</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
            integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
            crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
            integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
            crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                    {left: "\\begin{align}", right: "\\end{align}", display: true},
                    {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                    {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                    {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                ],
                // • rendering keys, e.g.:
                throwOnError: false
            });
        });
    </script>
</head>

<body>
<section class="header-container">
    <div style="display:flex; justify-content:space-between; align-items:flex-end;">
        <div>
            <div class="header-title">
                MyArxiv
            </div>
        </div>

        <div class=icons>
            <label class="theme-switch" for="checkbox">
                <input type="checkbox" id="checkbox"/>
                <i id="theme-icon" class="ri-moon-line" style="font-size: 32px" rel="noopener noreferrer"></i>
            </label>
        </div>
    </div>
</section>

    <section class="day-container">
        <div class="date">
            <time datetime="2024-07-18T00:00:00Z">2024-07-18</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">91</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Latent Causal Probing: A Formal Perspective on Probing with Causal
  Models of Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13765v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13765v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Charles Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As language models (LMs) deliver increasing performance on a range of NLP
tasks, probing classifiers have become an indispensable technique in the effort
to better understand their inner workings. A typical setup involves (1)
defining an auxiliary task consisting of a dataset of text annotated with
labels, then (2) supervising small classifiers to predict the labels from the
representations of a pretrained LM as it processed the dataset. A high probing
accuracy is interpreted as evidence that the LM has learned to perform the
auxiliary task as an unsupervised byproduct of its original pretraining
objective. Despite the widespread usage of probes, however, the robust design
and analysis of probing experiments remains a challenge. We develop a formal
perspective on probing using structural causal models (SCM). Specifically,
given an SCM which explains the distribution of tokens observed during
training, we frame the central hypothesis as whether the LM has learned to
represent the latent variables of the SCM. Empirically, we extend a recent
study of LMs in the context of a synthetic grid-world navigation task, where
having an exact model of the underlying causal structure allows us to draw
strong inferences from the result of probing experiments. Our techniques
provide robust empirical evidence for the ability of LMs to learn the latent
causal concepts underlying text.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>COLM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation
  of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13757v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13757v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuo Chen, Jiawei Liu, Haotan Liu, Qikai Cheng, Fan Zhang, Wei Lu, Xiaozhong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) is applied to solve hallucination
problems and real-time constraints of large language models, but it also
induces vulnerabilities against retrieval corruption attacks. Existing research
mainly explores the unreliability of RAG in white-box and closed-domain QA
tasks. In this paper, we aim to reveal the vulnerabilities of
Retrieval-Enhanced Generative (RAG) models when faced with black-box attacks
for opinion manipulation. We explore the impact of such attacks on user
cognition and decision-making, providing new insight to enhance the reliability
and security of RAG models. We manipulate the ranking results of the retrieval
model in RAG with instruction and use these results as data to train a
surrogate model. By employing adversarial retrieval attack methods to the
surrogate model, black-box transfer attacks on RAG are further realized.
Experiments conducted on opinion datasets across multiple topics show that the
proposed attack strategy can significantly alter the opinion polarity of the
content generated by RAG. This demonstrates the model's vulnerability and, more
importantly, reveals the potential negative impact on user cognition and
decision-making, making it easier to mislead users into accepting incorrect or
biased information.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLMs as Function Approximators: Terminology, Taxonomy, and Questions for
  Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13744v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13744v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Schlangen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural Language Processing has moved rather quickly from modelling specific
tasks to taking more general pre-trained models and fine-tuning them for
specific tasks, to a point where we now have what appear to be inherently
generalist models. This paper argues that the resultant loss of clarity on what
these models model leads to metaphors like "artificial general intelligences"
that are not helpful for evaluating their strengths and weaknesses. The
proposal is to see their generality, and their potential value, in their
ability to approximate specialist function, based on a natural language
specification. This framing brings to the fore questions of the quality of the
approximation, but beyond that, also questions of discoverability, stability,
and protectability of these functions. As the paper will show, this framing
hence brings together in one conceptual framework various aspects of
evaluation, both from a practical and a theoretical perspective, as well as
questions often relegated to a secondary status (such as "prompt injection" and
"jailbreaking").
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scaling Granite Code Models to 128K Context 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13739v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13739v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matt Stallone, Vaibhav Saxena, Leonid Karlinsky, Bridget McGinn, Tim Bula, Mayank Mishra, Adriana Meza Soria, Gaoyuan Zhang, Aditya Prasad, Yikang Shen, Saptha Surendran, Shanmukha Guttula, Hima Patel, Parameswaran Selvam, Xuan-Hong Dang, Yan Koyfman, Atin Sood, Rogerio Feris, Nirmit Desai, David D. Cox, Ruchir Puri, Rameswar Panda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces long-context Granite code models that support effective
context windows of up to 128K tokens. Our solution for scaling context length
of Granite 3B/8B code models from 2K/4K to 128K consists of a light-weight
continual pretraining by gradually increasing its RoPE base frequency with
repository-level file packing and length-upsampled long-context data.
Additionally, we also release instruction-tuned models with long-context
support which are derived by further finetuning the long context base models on
a mix of permissively licensed short and long-context instruction-response
pairs. While comparing to the original short-context Granite code models, our
long-context models achieve significant improvements on long-context tasks
without any noticeable performance degradation on regular code completion
benchmarks (e.g., HumanEval). We release all our long-context Granite code
models under an Apache 2.0 license for both research and commercial use.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Baba Is AI: Break the Rules to Beat the Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13729v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13729v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nathan Cloos, Meagan Jens, Michelangelo Naim, Yen-Ling Kuo, Ignacio Cases, Andrei Barbu, Christopher J. Cueva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans solve problems by following existing rules and procedures, and also by
leaps of creativity to redefine those rules and objectives. To probe these
abilities, we developed a new benchmark based on the game Baba Is You where an
agent manipulates both objects in the environment and rules, represented by
movable tiles with words written on them, to reach a specified goal and win the
game. We test three state-of-the-art multi-modal large language models (OpenAI
GPT-4o, Google Gemini-1.5-Pro and Gemini-1.5-Flash) and find that they fail
dramatically when generalization requires that the rules of the game must be
manipulated and combined.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding Reference Policies in Direct Preference Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13709v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13709v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixin Liu, Pengfei Liu, Arman Cohan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct Preference Optimization (DPO) has become a widely used training method
for the instruction fine-tuning of large language models (LLMs). In this work,
we explore an under-investigated aspect of DPO - its dependency on the
reference model or policy. Such reference policies, typically instantiated as
the model to be further fine-tuned, are important since they can impose an
upper limit on DPO's effectiveness. Therefore, we address three related
research questions in this work. First, we explore the optimal strength of the
KL-divergence constraint in DPO, which penalizes deviations from the reference
policy, and find that DPO is sensitive to this strength. Next, we examine the
necessity of reference policies for instruction fine-tuning by providing both
theoretical and empirical comparisons between DPO and related learning
objectives, demonstrating DPO's superiority. Additionally, we investigate
whether DPO benefits from stronger reference policies, finding that a stronger
reference policy can lead to improved performance, but only when it is similar
to the model being fine-tuned. Our findings highlight the confounding role of
reference policies in DPO and offer insights for best practices, while also
identifying open research questions for future studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ANHALTEN: Cross-Lingual Transfer for German Token-Level Reference-Free
  Hallucination Detection <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13702v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13702v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Janek Herrlein, Chia-Chien Hung, Goran Glavaš
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research on token-level reference-free hallucination detection has
predominantly focused on English, primarily due to the scarcity of robust
datasets in other languages. This has hindered systematic investigations into
the effectiveness of cross-lingual transfer for this important NLP application.
To address this gap, we introduce ANHALTEN, a new evaluation dataset that
extends the English hallucination detection dataset to German. To the best of
our knowledge, this is the first work that explores cross-lingual transfer for
token-level reference-free hallucination detection. ANHALTEN contains gold
annotations in German that are parallel (i.e., directly comparable to the
original English instances). We benchmark several prominent cross-lingual
transfer approaches, demonstrating that larger context length leads to better
hallucination detection in German, even without succeeding context.
Importantly, we show that the sample-efficient few-shot transfer is the most
effective approach in most setups. This highlights the practical benefits of
minimal annotation effort in the target language for reference-free
hallucination detection. Aiming to catalyze future research on cross-lingual
token-level reference-free hallucination detection, we make ANHALTEN publicly
available: https://github.com/janekh24/anhalten
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2024 Student Research Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Benchmark Agreement Testing Done Right: A Guide for LLM Benchmark
  Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13696v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13696v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yotam Perlitz, Ariel Gera, Ofir Arviv, Asaf Yehudai, Elron Bandel, Eyal Shnarch, Michal Shmueli-Scheuer, Leshem Choshen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Language Models (LMs) have catalyzed the creation of
multiple benchmarks, designed to assess these models' general capabilities. A
crucial task, however, is assessing the validity of the benchmarks themselves.
This is most commonly done via Benchmark Agreement Testing (BAT), where new
benchmarks are validated against established ones using some agreement metric
(e.g., rank correlation). Despite the crucial role of BAT for benchmark
builders and consumers, there are no standardized procedures for such agreement
testing. This deficiency can lead to invalid conclusions, fostering mistrust in
benchmarks and upending the ability to properly choose the appropriate
benchmark to use. By analyzing over 40 prominent benchmarks, we demonstrate how
some overlooked methodological choices can significantly influence BAT results,
potentially undermining the validity of conclusions. To address these
inconsistencies, we propose a set of best practices for BAT and demonstrate how
utilizing these methodologies greatly improves BAT robustness and validity. To
foster adoption and facilitate future research,, we introduce BenchBench, a
python package for BAT, and release the BenchBench-leaderboard, a
meta-benchmark designed to evaluate benchmarks using their peers. Our findings
underscore the necessity for standardized BAT, ensuring the robustness and
validity of benchmark evaluations in the evolving landscape of language model
research.
  BenchBench Package: https://github.com/IBM/BenchBench
  Leaderboard: https://huggingface.co/spaces/per/BenchBench
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Prover-Verifier Games improve legibility of LLM outputs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13692v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13692v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jan Hendrik Kirchner, Yining Chen, Harri Edwards, Jan Leike, Nat McAleese, Yuri Burda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One way to increase confidence in the outputs of Large Language Models (LLMs)
is to support them with reasoning that is clear and easy to check -- a property
we call legibility. We study legibility in the context of solving grade-school
math problems and show that optimizing chain-of-thought solutions only for
answer correctness can make them less legible. To mitigate the loss in
legibility, we propose a training algorithm inspired by Prover-Verifier Game
from Anil et al. (2021). Our algorithm iteratively trains small verifiers to
predict solution correctness, "helpful" provers to produce correct solutions
that the verifier accepts, and "sneaky" provers to produce incorrect solutions
that fool the verifier. We find that the helpful prover's accuracy and the
verifier's robustness to adversarial attacks increase over the course of
training. Furthermore, we show that legibility training transfers to
time-constrained humans tasked with verifying solution correctness. Over course
of LLM training human accuracy increases when checking the helpful prover's
solutions, and decreases when checking the sneaky prover's solutions. Hence,
training for checkability by small verifiers is a plausible technique for
increasing output legibility. Our results suggest legibility training against
small verifiers as a practical avenue for increasing legibility of large LLMs
to humans, and thus could help with alignment of superhuman models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FuLG: 150B Romanian Corpus for Language Model <span class="highlight-title">Pretrain</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13657v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13657v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vlad-Andrei Bădoiu, Mihai-Valentin Dumitru, Alexandru M. Gherghescu, Alexandru Agache, Costin Raiciu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research in the field of language models is rapidly evolving, with many open
models being released to the public. Openly available pretraining corpora
usually focus on only a handful of languages, with many others either missing
completely or extremely underrepresented. In this report, we introduce FuLG, a
hundred-fifty-billion-token Romanian corpus extracted from CommonCrawl. We
present our methodology for filtering FuLG and compare it via ablation studies
against existing Romanian corpora.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Weak-to-Strong Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13647v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13647v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuqing Yang, Yan Ma, Pengfei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When large language models (LLMs) exceed human-level capabilities, it becomes
increasingly challenging to provide full-scale and accurate supervisions for
these models. Weak-to-strong learning, which leverages a less capable model to
unlock the latent abilities of a stronger model, proves valuable in this
context. Yet, the efficacy of this approach for complex reasoning tasks is
still untested. Furthermore, tackling reasoning tasks under the weak-to-strong
setting currently lacks efficient methods to avoid blindly imitating the weak
supervisor including its errors. In this paper, we introduce a progressive
learning framework that enables the strong model to autonomously refine its
training data, without requiring input from either a more advanced model or
human-annotated data. This framework begins with supervised fine-tuning on a
selective small but high-quality dataset, followed by preference optimization
on contrastive samples identified by the strong model itself. Extensive
experiments on the GSM8K and MATH datasets demonstrate that our method
significantly enhances the reasoning capabilities of Llama2-70b using three
separate weak models. This method is further validated in a forward-looking
experimental setup, where Llama3-8b-instruct effectively supervises Llama3-70b
on the highly challenging OlympicArena dataset. This work paves the way for a
more scalable and sophisticated strategy to enhance AI reasoning powers. All
relevant code and resources are available in
\url{https://github.com/GAIR-NLP/weak-to-strong-reasoning}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Comparative Study on Automatic Coding of Medical Letters with
  Explainability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13638v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13638v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>working paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13623v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13623v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chaofan Tao, Qian Liu, Longxu Dou, Niklas Muennighoff, Zhongwei Wan, Ping Luo, Min Lin, Ngai Wong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research on scaling large language models (LLMs) has primarily focused on
model parameters and training data size, overlooking the role of vocabulary
size. % Intuitively, larger vocabularies enable more efficient tokenization by
representing sentences with fewer tokens, but they also increase the risk of
under-fitting representations for rare tokens. We investigate how vocabulary
size impacts LLM scaling laws by training models ranging from 33M to 3B
parameters on up to 500B characters with various vocabulary configurations. We
propose three complementary approaches for predicting the compute-optimal
vocabulary size: IsoFLOPs analysis, derivative estimation, and parametric fit
of the loss function. Our approaches converge on the same result that the
optimal vocabulary size depends on the available compute budget and that larger
models deserve larger vocabularies. However, most LLMs use too small vocabulary
sizes. For example, we predict that the optimal vocabulary size of Llama2-70B
should have been at least 216K, 7 times larger than its vocabulary of 32K. We
validate our predictions empirically by training models with 3B parameters
across different FLOPs budgets. Adopting our predicted optimal vocabulary size
consistently improves downstream performance over commonly used vocabulary
sizes. By increasing the vocabulary size from the conventional 32K to 43K, we
improve performance on ARC-Challenge from 29.1 to 32.0 with the same 2.3e21
FLOPs. Our work emphasizes the necessity of jointly considering model
parameters and vocabulary size for efficient scaling.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ dzNLP at NADI 2024 Shared Task: Multi-Classifier Ensemble with Weighted
  Voting and TF-IDF Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13608v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13608v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamed Lichouri, Khaled Lounnas, Boualem Nadjib Zahaf, Mehdi Ayoub Rabiai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents the contribution of our dzNLP team to the NADI 2024
shared task, specifically in Subtask 1 - Multi-label Country-level Dialect
Identification (MLDID) (Closed Track). We explored various configurations to
address the challenge: in Experiment 1, we utilized a union of n-gram analyzers
(word, character, character with word boundaries) with different n-gram values;
in Experiment 2, we combined a weighted union of Term Frequency-Inverse
Document Frequency (TF-IDF) features with various weights; and in Experiment 3,
we implemented a weighted major voting scheme using three classifiers: Linear
Support Vector Classifier (LSVC), Random Forest (RF), and K-Nearest Neighbors
(KNN).
  Our approach, despite its simplicity and reliance on traditional machine
learning techniques, demonstrated competitive performance in terms of F1-score
and precision. Notably, we achieved the highest precision score of 63.22% among
the participating teams. However, our overall F1 score was approximately 21%,
significantly impacted by a low recall rate of 12.87%. This indicates that
while our models were highly precise, they struggled to recall a broad range of
dialect labels, highlighting a critical area for improvement in handling
diverse dialectal variations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication in the conference proceedings of ArabicNLP
  2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ dzStance at StanceEval2024: Arabic Stance Detection based on Sentence
  <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13603v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13603v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamed Lichouri, Khaled Lounnas, Khelil Rafik Ouaras, Mohamed Abi, Anis Guechtouli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study compares Term Frequency-Inverse Document Frequency (TF-IDF)
features with Sentence Transformers for detecting writers' stances--favorable,
opposing, or neutral--towards three significant topics: COVID-19 vaccine,
digital transformation, and women empowerment. Through empirical evaluation, we
demonstrate that Sentence Transformers outperform TF-IDF features across
various experimental setups. Our team, dzStance, participated in a stance
detection competition, achieving the 13th position (74.91%) among 15 teams in
Women Empowerment, 10th (73.43%) in COVID Vaccine, and 12th (66.97%) in Digital
Transformation. Overall, our team's performance ranked 13th (71.77%) among all
participants. Notably, our approach achieved promising F1-scores, highlighting
its effectiveness in identifying writers' stances on diverse topics. These
results underscore the potential of Sentence Transformers to enhance stance
detection models for addressing critical societal issues.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication in the conference proceedings of ArabicNLP
  2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PLANTS: A Novel Problem and <span class="highlight-title">Dataset</span> for Summarization of Planning-Like
  (PL) Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13597v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13597v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vishal Pallagani, Biplav Srivastava, Nitin Gupta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text summarization is a well-studied problem that deals with deriving
insights from unstructured text consumed by humans, and it has found extensive
business applications. However, many real-life tasks involve generating a
series of actions to achieve specific goals, such as workflows, recipes,
dialogs, and travel plans. We refer to them as planning-like (PL) tasks noting
that the main commonality they share is control flow information. which may be
partially specified. Their structure presents an opportunity to create more
practical summaries to help users make quick decisions. We investigate this
observation by introducing a novel plan summarization problem, presenting a
dataset, and providing a baseline method for generating PL summaries. Using
quantitative metrics and qualitative user studies to establish baselines, we
evaluate the plan summaries from our method and large language models. We
believe the novel problem and dataset can reinvigorate research in
summarization, which some consider as a solved problem.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Zero-Shot Multimodal Machine Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13579v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13579v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matthieu Futeral, Cordelia Schmid, Benoît Sagot, Rachel Bawden
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current multimodal machine translation (MMT) systems rely on fully supervised
data (i.e models are trained on sentences with their translations and
accompanying images). However, this type of data is costly to collect, limiting
the extension of MMT to other language pairs for which such data does not
exist. In this work, we propose a method to bypass the need for fully
supervised data to train MMT systems, using multimodal English data only. Our
method, called ZeroMMT, consists in adapting a strong text-only machine
translation (MT) model by training it on a mixture of two objectives: visually
conditioned masked language modelling and the Kullback-Leibler divergence
between the original and new MMT outputs. We evaluate on standard MMT
benchmarks and the recently released CoMMuTE, a contrastive benchmark aiming to
evaluate how well models use images to disambiguate English sentences. We
obtain disambiguation performance close to state-of-the-art MMT models trained
additionally on fully supervised examples. To prove that our method generalizes
to languages with no fully supervised training data available, we extend the
CoMMuTE evaluation dataset to three new languages: Arabic, Russian and Chinese.
We further show that we can control the trade-off between disambiguation
capabilities and translation fidelity at inference time using classifier-free
guidance and without any additional data. Our code, data and trained models are
publicly accessible.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Large Language Models as Reliable Knowledge Bases? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13578v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13578v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Danna Zheng, Mirella Lapata, Jeff Z. Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The NLP community has recently shown a growing interest in leveraging Large
Language Models (LLMs) for knowledge-intensive tasks, viewing LLMs as potential
knowledge bases (KBs). However, the reliability and extent to which LLMs can
function as KBs remain underexplored. While previous studies suggest LLMs can
encode knowledge within their parameters, the amount of parametric knowledge
alone is not sufficient to evaluate their effectiveness as KBs. This study
defines criteria that a reliable LLM-as-KB should meet, focusing on factuality
and consistency, and covering both seen and unseen knowledge. We develop
several metrics based on these criteria and use them to evaluate 26 popular
LLMs, while providing a comprehensive analysis of the effects of model size,
instruction tuning, and in-context learning (ICL). Our results paint a worrying
picture. Even a high-performant model like GPT-3.5-turbo is not factual or
consistent, and strategies like ICL and fine-tuning are unsuccessful at making
LLMs better KBs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ New Capability to Look Up an ASL Sign from a Video Example 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13571v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13571v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Carol Neidle, Augustine Opoku, Carey Ballard, Yang Zhou, Xiaoxiao He, Gregory Dimitriadis, Dimitris Metaxas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Looking up an unknown sign in an ASL dictionary can be difficult. Most ASL
dictionaries are organized based on English glosses, despite the fact that (1)
there is no convention for assigning English-based glosses to ASL signs; and
(2) there is no 1-1 correspondence between ASL signs and English words.
Furthermore, what if the user does not know either the meaning of the target
sign or its possible English translation(s)? Some ASL dictionaries enable
searching through specification of articulatory properties, such as handshapes,
locations, movement properties, etc. However, this is a cumbersome process and
does not always result in successful lookup. Here we describe a new system,
publicly shared on the Web, to enable lookup of a video of an ASL sign (e.g., a
webcam recording or a clip from a continuous signing video). The user submits a
video for analysis and is presented with the five most likely sign matches, in
decreasing order of likelihood, so that the user can confirm the selection and
then be taken to our ASLLRP Sign Bank entry for that sign. Furthermore, this
video lookup is also integrated into our newest version of SignStream(R)
software to facilitate linguistic annotation of ASL video data, enabling the
user to directly look up a sign in the video being annotated, and, upon
confirmation of the match, to directly enter into the annotation the gloss and
features of that sign, greatly increasing the efficiency and consistency of
linguistic annotations of ASL video data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ dzFinNlp at AraFinNLP: Improving Intent Detection in Financial
  Conversational Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13565v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13565v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamed Lichouri, Khaled Lounnas, Mohamed Zakaria Amziane
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present our dzFinNlp team's contribution for intent
detection in financial conversational agents, as part of the AraFinNLP shared
task. We experimented with various models and feature configurations, including
traditional machine learning methods like LinearSVC with TF-IDF, as well as
deep learning models like Long Short-Term Memory (LSTM). Additionally, we
explored the use of transformer-based models for this task. Our experiments
show promising results, with our best model achieving a micro F1-score of
93.02% and 67.21% on the ArBanking77 dataset, in the development and test sets,
respectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication in the conference proceedings of ArabicNLP
  2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Research on Tibetan Tourism Viewpoints information generation system
  based on LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13561v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13561v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinhu Qi, Shuai Yan, Wentao Zhang, Yibo Zhang, Zirui Liu, Ke Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tibet, ensconced within China's territorial expanse, is distinguished by its
labyrinthine and heterogeneous topography, a testament to its profound
historical heritage, and the cradle of a unique religious ethos. The very
essence of these attributes, however, has impeded the advancement of Tibet's
tourism service infrastructure, rendering existing smart tourism services
inadequate for the region's visitors. This study delves into the ramifications
of informational disparities at tourist sites on Tibetan tourism and addresses
the challenge of establishing the Large Language Model (LLM) evaluation
criteria. It introduces an innovative approach, the DualGen Bridge AI system,
employing supervised fine-tuning techniques to bolster model functionality and
enhance optimization processes. Furthermore, it pioneers a multi-structured
generative results assessment framework. Empirical validation confirms the
efficacy of this framework. The study also explores the application of the
supervised fine-tuning method within the proprietary DualGen Bridge AI, aimed
at refining the generation of tourist site information. The study's findings
offer valuable insights for optimizing system performance and provide support
and inspiration for the application of LLM technology in Tibet's tourism
services and beyond, potentially revolutionizing the smart tourism industry
with advanced, tailored information generation capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Qalam : A Multimodal LLM for Arabic Optical Character and Handwriting
  Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13559v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13559v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gagan Bhatia, El Moatez Billah Nagoudi, Fakhraddin Alwajih, Muhammad Abdul-Mageed
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Arabic Optical Character Recognition (OCR) and Handwriting Recognition (HWR)
pose unique challenges due to the cursive and context-sensitive nature of the
Arabic script. This study introduces Qalam, a novel foundation model designed
for Arabic OCR and HWR, built on a SwinV2 encoder and RoBERTa decoder
architecture. Our model significantly outperforms existing methods, achieving a
Word Error Rate (WER) of just 0.80% in HWR tasks and 1.18% in OCR tasks. We
train Qalam on a diverse dataset, including over 4.5 million images from Arabic
manuscripts and a synthetic dataset comprising 60k image-text pairs. Notably,
Qalam demonstrates exceptional handling of Arabic diacritics, a critical
feature in Arabic scripts. Furthermore, it shows a remarkable ability to
process high-resolution inputs, addressing a common limitation in current OCR
systems. These advancements underscore Qalam's potential as a leading solution
for Arabic script recognition, offering a significant leap in accuracy and
efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can Open-Source LLMs Compete with Commercial Models? Exploring the
  Few-Shot Performance of Current <span class="highlight-title">GPT</span> Models in Biomedical Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13511v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13511v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Samy Ateia, Udo Kruschwitz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Commercial large language models (LLMs), like OpenAI's GPT-4 powering ChatGPT
and Anthropic's Claude 3 Opus, have dominated natural language processing (NLP)
benchmarks across different domains. New competing Open-Source alternatives
like Mixtral 8x7B or Llama 3 have emerged and seem to be closing the gap while
often offering higher throughput and being less costly to use. Open-Source LLMs
can also be self-hosted, which makes them interesting for enterprise and
clinical use cases where sensitive data should not be processed by third
parties. We participated in the 12th BioASQ challenge, which is a retrieval
augmented generation (RAG) setting, and explored the performance of current GPT
models Claude 3 Opus, GPT-3.5-turbo and Mixtral 8x7b with in-context learning
(zero-shot, few-shot) and QLoRa fine-tuning. We also explored how additional
relevant knowledge from Wikipedia added to the context-window of the LLM might
improve their performance. Mixtral 8x7b was competitive in the 10-shot setting,
both with and without fine-tuning, but failed to produce usable results in the
zero-shot setting. QLoRa fine-tuning and Wikipedia context did not lead to
measurable performance gains. Our results indicate that the performance gap
between commercial and open-source models in RAG setups exists mainly in the
zero-shot setting and can be closed by simply collecting few-shot examples for
domain-specific use cases. The code needed to rerun these experiments is
available through GitHub.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Version as accepted at the BioASQ Lab at CLEF 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spontaneous Style Text-to-Speech Synthesis with Controllable Spontaneous
  Behaviors Based on Language Models <span class="chip">INTERSPEECH 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13509v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13509v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weiqin Li, Peiji Yang, Yicheng Zhong, Yixuan Zhou, Zhisheng Wang, Zhiyong Wu, Xixin Wu, Helen Meng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spontaneous style speech synthesis, which aims to generate human-like speech,
often encounters challenges due to the scarcity of high-quality data and
limitations in model capabilities. Recent language model-based TTS systems can
be trained on large, diverse, and low-quality speech datasets, resulting in
highly natural synthesized speech. However, they are limited by the difficulty
of simulating various spontaneous behaviors and capturing prosody variations in
spontaneous speech. In this paper, we propose a novel spontaneous speech
synthesis system based on language models. We systematically categorize and
uniformly model diverse spontaneous behaviors. Moreover, fine-grained prosody
modeling is introduced to enhance the model's ability to capture subtle prosody
variations in spontaneous speech.Experimental results show that our proposed
method significantly outperforms the baseline methods in terms of prosody
naturalness and spontaneous behavior naturalness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by INTERSPEECH 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Biomedical Knowledge Discovery for Diseases: An End-To-End
  Open-Source Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13492v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13492v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christos Theodoropoulos, Andrei Catalin Coman, James Henderson, Marie-Francine Moens
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ever-growing volume of biomedical publications creates a critical need
for efficient knowledge discovery. In this context, we introduce an open-source
end-to-end framework designed to construct knowledge around specific diseases
directly from raw text. To facilitate research in disease-related knowledge
discovery, we create two annotated datasets focused on Rett syndrome and
Alzheimer's disease, enabling the identification of semantic relations between
biomedical entities. Extensive benchmarking explores various ways to represent
relations and entity representations, offering insights into optimal modeling
strategies for semantic relation detection and highlighting language models'
competence in knowledge discovery. We also conduct probing experiments using
different layer representations and attention scores to explore transformers'
ability to capture semantic relations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Combining Constraint Programming Reasoning with Large Language Model
  Predictions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13490v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13490v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Florian Régin, Elisabetta De Maria, Alexandre Bonlarron
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Constraint Programming (CP) and Machine Learning (ML) face challenges in text
generation due to CP's struggle with implementing "meaning'' and ML's
difficulty with structural constraints. This paper proposes a solution by
combining both approaches and embedding a Large Language Model (LLM) in CP. The
LLM handles word generation and meaning, while CP manages structural
constraints. This approach builds on GenCP, an improved version of On-the-fly
Constraint Programming Search (OTFS) using LLM-generated domains. Compared to
Beam Search (BS), a standard NLP method, this combined approach (GenCP with
LLM) is faster and produces better results, ensuring all constraints are
satisfied. This fusion of CP and ML presents new possibilities for enhancing
text generation under constraints.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at The 30th International Conference on Principles and
  Practice of Constraint Programming (CP 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Attention Overflow: Language Model Input Blur during Long-Context
  Missing Items Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13481v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13481v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Damien Sileo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) can suggest missing elements from items listed
in a prompt, which can be used for list completion or recommendations based on
users' history. However, their performance degrades when presented with too
many items, as they start to suggest items already included in the input list.
This occurs at around 100 items for mid-2024 flagship LLMs. We evaluate this
phenomenon on both synthetic problems (e.g., finding missing numbers in a given
range of shuffled integers) and realistic movie recommendation scenarios. We
refer to this issue as \textit{attention overflow}, as preventing repetition
requires attending to all items simultaneously. Although iterative loops can
mitigate this problem, their costs increase with the repetition rate, affecting
the language models' ability to derive novelty from lengthy inputs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Dataset URL:
  https://huggingface.co/datasets/sileod/missing-item-prediction</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fixed and Adaptive Simultaneous Machine Translation Strategies Using
  Adapters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13469v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13469v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abderrahmane Issam, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Simultaneous machine translation aims at solving the task of real-time
translation by starting to translate before consuming the full input, which
poses challenges in terms of balancing quality and latency of the translation.
The wait-$k$ policy offers a solution by starting to translate after consuming
$k$ words, where the choice of the number $k$ directly affects the latency and
quality. In applications where we seek to keep the choice over latency and
quality at inference, the wait-$k$ policy obliges us to train more than one
model. In this paper, we address the challenge of building one model that can
fulfil multiple latency levels and we achieve this by introducing lightweight
adapter modules into the decoder. The adapters are trained to be specialized
for different wait-$k$ values and compared to other techniques they offer more
flexibility to allow for reaping the benefits of parameter sharing and
minimizing interference. Additionally, we show that by combining with an
adaptive strategy, we can further improve the results. Experiments on two
language directions show that our method outperforms or competes with other
strong baselines on most latency values.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at IWSLT 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ End-To-End Clinical Trial Matching with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13463v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13463v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dyke Ferber, Lars Hilgers, Isabella C. Wiest, Marie-Elisabeth Leßmann, Jan Clusmann, Peter Neidlinger, Jiefu Zhu, Georg Wölflein, Jacqueline Lammert, Maximilian Tschochohei, Heiko Böhme, Dirk Jäger, Mihaela Aldea, Daniel Truhn, Christiane Höper, Jakob Nikolas Kather
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Matching cancer patients to clinical trials is essential for advancing
treatment and patient care. However, the inconsistent format of medical free
text documents and complex trial eligibility criteria make this process
extremely challenging and time-consuming for physicians. We investigated
whether the entire trial matching process - from identifying relevant trials
among 105,600 oncology-related clinical trials on clinicaltrials.gov to
generating criterion-level eligibility matches - could be automated using Large
Language Models (LLMs). Using GPT-4o and a set of 51 synthetic Electronic
Health Records (EHRs), we demonstrate that our approach identifies relevant
candidate trials in 93.3% of cases and achieves a preliminary accuracy of 88.0%
when matching patient-level information at the criterion level against a
baseline defined by human experts. Utilizing LLM feedback reveals that 39.3%
criteria that were initially considered incorrect are either ambiguous or
inaccurately annotated, leading to a total model accuracy of 92.7% after
refining our human baseline. In summary, we present an end-to-end pipeline for
clinical trial matching using LLMs, demonstrating high precision in screening
and matching trials to individual patients, even outperforming the performance
of qualified medical doctors. Our fully end-to-end pipeline can operate
autonomously or with human supervision and is not restricted to oncology,
offering a scalable solution for enhancing patient-trial matching in real-world
settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>149 pages, including Supplements. 3 Main Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BEAF: Observing BEfore-AFter Changes to Evaluate Hallucination in
  Vision-language Models <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13442v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13442v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Moon Ye-Bin, Nam Hyeon-Woo, Wonseok Choi, Tae-Hyun Oh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision language models (VLMs) perceive the world through a combination of a
visual encoder and a large language model (LLM). The visual encoder,
pre-trained on large-scale vision-text datasets, provides zero-shot
generalization to visual data, and the LLM endows its high reasoning ability to
VLMs. It leads VLMs to achieve high performance on wide benchmarks without
fine-tuning, exhibiting zero or few-shot capability. However, recent studies
show that VLMs are vulnerable to hallucination. This undesirable behavior
degrades reliability and credibility, thereby making users unable to fully
trust the output from VLMs. To enhance trustworthiness and better tackle the
hallucination of VLMs, we curate a new evaluation dataset, called the
BEfore-AFter hallucination dataset (BEAF), and introduce new metrics: True
Understanding (TU), IGnorance (IG), StuBbornness (SB), and InDecision (ID).
Unlike prior works that focus only on constructing questions and answers, the
key idea of our benchmark is to manipulate visual scene information by image
editing models and to design the metrics based on scene changes. This allows us
to clearly assess whether VLMs correctly understand a given scene by observing
the ability to perceive changes. We also visualize image-wise object
relationship by virtue of our two-axis view: vision and text. Upon evaluating
VLMs with our dataset, we observed that our metrics reveal different aspects of
VLM hallucination that have not been reported before. Project page:
\url{https://beafbench.github.io/}
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ECCV 2024. [Project Pages] https://beafbench.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Out-of-Vocabulary Performance of Indian TTS Systems for
  Practical Applications through Low-Effort Data Strategies <span class="chip">INTERSPEECH 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13435v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13435v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Srija Anand, Praveen Srinivasa Varadhan, Ashwin Sankar, Giri Raju, Mitesh M. Khapra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Publicly available TTS datasets for low-resource languages like Hindi and
Tamil typically contain 10-20 hours of data, leading to poor vocabulary
coverage. This limitation becomes evident in downstream applications where
domain-specific vocabulary coupled with frequent code-mixing with English,
results in many OOV words. To highlight this problem, we create a benchmark
containing OOV words from several real-world applications. Indeed,
state-of-the-art Hindi and Tamil TTS systems perform poorly on this OOV
benchmark, as indicated by intelligibility tests. To improve the model's OOV
performance, we propose a low-effort and economically viable strategy to obtain
more training data. Specifically, we propose using volunteers as opposed to
high quality voice artists to record words containing character bigrams unseen
in the training data. We show that using such inexpensive data, the model's
performance improves on OOV words, while not affecting voice quality and
in-domain performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at INTERSPEECH 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From Words to Worlds: Compositionality for Cognitive Architectures <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13419v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13419v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruchira Dhar, Anders Søgaard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are very performant connectionist systems, but
do they exhibit more compositionality? More importantly, is that part of why
they perform so well? We present empirical analyses across four LLM families
(12 models) and three task categories, including a novel task introduced below.
Our findings reveal a nuanced relationship in learning of compositional
strategies by LLMs -- while scaling enhances compositional abilities,
instruction tuning often has a reverse effect. Such disparity brings forth some
open issues regarding the development and improvement of large language models
in alignment with human cognitive capacities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICML 2024 Workshop on LLMs & Cognition</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Correcting the Mythos of KL-Regularization: Direct Alignment without
  Overparameterization via Chi-squared Preference Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13399v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13399v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Audrey Huang, Wenhao Zhan, Tengyang Xie, Jason D. Lee, Wen Sun, Akshay Krishnamurthy, Dylan J. Foster
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language model alignment methods, such as reinforcement learning from human
feedback (RLHF), have led to impressive advances in language model
capabilities, but existing techniques are limited by a widely observed
phenomenon known as overoptimization, where the quality of the language model
plateaus or degrades over the course of the alignment process. Overoptimization
is often attributed to overfitting to an inaccurate reward model, and while it
can be mitigated through online data collection, this is infeasible in many
settings. This raises a fundamental question: Do existing offline alignment
algorithms make the most of the data they have, or can their sample-efficiency
be improved further?
  We address this question with a new algorithm for offline alignment,
$\chi^2$-Preference Optimization ($\chi$PO). $\chi$PO is a one-line change to
Direct Preference Optimization (DPO; Rafailov et al., 2023), which only
involves modifying the logarithmic link function in the DPO objective. Despite
this minimal change, $\chi$PO implicitly implements the principle of pessimism
in the face of uncertainty via regularization with the $\chi^2$-divergence --
which quantifies uncertainty more effectively than KL-regularization -- and
provably alleviates overoptimization, achieving sample-complexity guarantees
based on single-policy concentrability -- the gold standard in offline
reinforcement learning. $\chi$PO's simplicity and strong guarantees make it the
first practical and general-purpose offline alignment algorithm that is
provably robust to overoptimization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Linear-Complexity <span class="highlight-title">Self-Supervised</span> Learning for Speech Processing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13377v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13377v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shucong Zhang, Titouan Parcollet, Rogier van Dalen, Sourav Bhattacharya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervised learning (SSL) models usually require weeks of pre-training
with dozens of high-end GPUs. These models typically have a multi-headed
self-attention (MHSA) context encoder. However, MHSA takes quadratic time and
space in the input length, contributing to the high pre-training cost.
Linear-complexity alternatives to MHSA have been proposed. For instance, in
supervised training, the SummaryMixing model is the first to outperform MHSA
across multiple speech processing tasks. However, these cheaper alternatives
have not been explored for SSL yet. This paper studies a linear-complexity
context encoder for SSL for the first time. With better or equivalent
performance for the downstream tasks of the MP3S benchmark, SummaryMixing
reduces the pre-training time and peak VRAM of wav2vec 2.0 model by 18% and by
23%, respectively, leading to the pre-training of a 155M wav2vec 2.0 model
finished within one week with 4 Tesla A100 GPUs. Code is available at
https://github.com/SamsungLabs/SummaryMixing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Interspeech 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Capturing Style in Author and Document Representation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13358v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13358v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Enzo Terreau, Antoine Gourru, Julien Velcin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A wide range of Deep Natural Language Processing (NLP) models integrates
continuous and low dimensional representations of words and documents.
Surprisingly, very few models study representation learning for authors. These
representations can be used for many NLP tasks, such as author identification
and classification, or in recommendation systems. A strong limitation of
existing works is that they do not explicitly capture writing style, making
them hardly applicable to literary data. We therefore propose a new
architecture based on Variational Information Bottleneck (VIB) that learns
embeddings for both authors and documents with a stylistic constraint. Our
model fine-tunes a pre-trained document encoder. We stimulate the detection of
writing style by adding predefined stylistic features making the representation
axis interpretable with respect to writing style indicators. We evaluate our
method on three datasets: a literary corpus extracted from the Gutenberg
Project, the Blog Authorship Corpus and IMDb62, for which we show that it
matches or outperforms strong/recent baselines in authorship attribution while
capturing much more accurately the authors stylistic aspects.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning-From-Mistakes <span class="highlight-title">Prompt</span>ing for Indigenous Language Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13343v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13343v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        You-Cheng Liao, Chen-Jui Yu, Chi-Yi Lin, He-Feng Yun, Yen-Hsiang Wang, Hsiao-Min Li, Yao-Chung Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Using large language models, this paper presents techniques to improve
extremely low-resourced indigenous language translations. Our approaches are
grounded in the use of (1) the presence of a datastore consisting of a limited
number of parallel translation examples, (2) the inherent capabilities of LLMs
like GPT-3.5, and (3) a word-level translation dictionary. We harness the
potential of LLMs and in-context learning techniques in such a setting for
using LLMs as universal translators for extremely low-resourced languages. Our
methodology hinges on utilizing LLMs as language compilers for selected
language pairs, hypothesizing that they could internalize syntactic structures
to facilitate accurate translation. We introduce three techniques: KNNPrompting
with Retrieved Prompting Context, Chain-of-Thought Prompting and
Learningfrom-Mistakes Prompting, with the last method addressing past errors.
The evaluation results suggest that, even with limited corpora, LLMs can
effectively translate extremely low-resource languages when paired with proper
prompting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Why do you cite? An investigation on citation intents and
  decision-making classification processes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13329v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13329v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lorenzo Paolini, Sahar Vahdati, Angelo Di Iorio, Robert Wardenga, Ivan Heibi, Silvio Peroni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Identifying the reason for which an author cites another work is essential to
understand the nature of scientific contributions and to assess their impact.
Citations are one of the pillars of scholarly communication and most metrics
employed to analyze these conceptual links are based on quantitative
observations. Behind the act of referencing another scholarly work there is a
whole world of meanings that needs to be proficiently and effectively revealed.
This study emphasizes the importance of trustfully classifying citation intents
to provide more comprehensive and insightful analyses in research assessment.
We address this task by presenting a study utilizing advanced Ensemble
Strategies for Citation Intent Classification (CIC) incorporating Language
Models (LMs) and employing Explainable AI (XAI) techniques to enhance the
interpretability and trustworthiness of models' predictions. Our approach
involves two ensemble classifiers that utilize fine-tuned SciBERT and XLNet LMs
as baselines. We further demonstrate the critical role of section titles as a
feature in improving models' performances. The study also introduces a web
application developed with Flask and currently available at
http://137.204.64.4:81/cic/classifier, aimed at classifying citation intents.
One of our models sets as a new state-of-the-art (SOTA) with an 89.46% Macro-F1
score on the SciCite benchmark. The integration of XAI techniques provides
insights into the decision-making processes, highlighting the contributions of
individual words for level-0 classifications, and of individual models for the
metaclassification. The findings suggest that the inclusion of section titles
significantly enhances classification performances in the CIC task. Our
contributions provide useful insights for developing more robust datasets and
methodologies, thus fostering a deeper understanding of scholarly
communication.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>42 pages, 14 figures, 1 table, submitted to Scientometrics Journal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13301v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13301v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junying Chen, Chi Gui, Anningzhe Gao, Ke Ji, Xidong Wang, Xiang Wan, Benyou Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The field of medical diagnosis has undergone a significant transformation
with the advent of large language models (LLMs), yet the challenges of
interpretability within these models remain largely unaddressed. This study
introduces Chain-of-Diagnosis (CoD) to enhance the interpretability of
LLM-based medical diagnostics. CoD transforms the diagnostic process into a
diagnostic chain that mirrors a physician's thought process, providing a
transparent reasoning pathway. Additionally, CoD outputs the disease confidence
distribution to ensure transparency in decision-making. This interpretability
makes model diagnostics controllable and aids in identifying critical symptoms
for inquiry through the entropy reduction of confidences. With CoD, we
developed DiagnosisGPT, capable of diagnosing 9604 diseases. Experimental
results demonstrate that DiagnosisGPT outperforms other LLMs on diagnostic
benchmarks. Moreover, DiagnosisGPT provides interpretability while ensuring
controllability in diagnostic rigor.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust ASR Error Correction with Conservative Data Filtering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13300v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13300v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Takuma Udagawa, Masayuki Suzuki, Masayasu Muraoka, Gakuto Kurata
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Error correction (EC) based on large language models is an emerging
technology to enhance the performance of automatic speech recognition (ASR)
systems. Generally, training data for EC are collected by automatically pairing
a large set of ASR hypotheses (as sources) and their gold references (as
targets). However, the quality of such pairs is not guaranteed, and we observed
various types of noise which can make the EC models brittle, e.g. inducing
overcorrection in out-of-domain (OOD) settings. In this work, we propose two
fundamental criteria that EC training data should satisfy: namely, EC targets
should (1) improve linguistic acceptability over sources and (2) be inferable
from the available context (e.g. source phonemes). Through these criteria, we
identify low-quality EC pairs and train the models not to make any correction
in such cases, the process we refer to as conservative data filtering. In our
experiments, we focus on Japanese ASR using a strong Conformer-CTC as the
baseline and finetune Japanese LLMs for EC. Through our evaluation on a suite
of 21 internal benchmarks, we demonstrate that our approach can significantly
reduce overcorrection and improve both the accuracy and quality of ASR results
in the challenging OOD settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SpeciaLex: A Benchmark for In-Context Specialized Lexicon Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13297v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13297v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joseph Marvin Imperial, Harish Tayyar Madabushi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Specialized lexicons are collections of words with associated constraints
such as special definitions, specific roles, and intended target audiences.
These constraints are necessary for content generation and documentation tasks
(e.g., writing technical manuals or children's books), where the goal is to
reduce the ambiguity of text content and increase its overall readability for a
specific group of audience. Understanding how large language models can capture
these constraints can help researchers build better, more impactful tools for
wider use beyond the NLP community. Towards this end, we introduce SpeciaLex, a
benchmark for evaluating a language model's ability to follow specialized
lexicon-based constraints across 18 diverse subtasks with 1,285 test instances
covering core tasks of Checking, Identification, Rewriting, and Open
Generation. We present an empirical evaluation of 15 open and closed-source
LLMs and discuss insights on how factors such as model scale, openness, setup,
and recency affect performance upon evaluating with the benchmark.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Low-Resourced Speech Recognition for Iu Mien Language via
  Weakly-Supervised Phoneme-based Multilingual <span class="highlight-title">Pre-train</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13292v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13292v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukuan Dong, Donghong Qin, Fengbo Bai, Fanhua Song, Yan Liu, Chen Xu, Zhijian Ou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The mainstream automatic speech recognition (ASR) technology usually requires
hundreds to thousands of hours of annotated speech data. Three approaches to
low-resourced ASR are phoneme or subword based supervised pre-training, and
self-supervised pre-training over multilingual data. The Iu Mien language is
the main ethnic language of the Yao ethnic group in China and is low-resourced
in the sense that the annotated speech is very limited. With less than 10 hours
of transcribed Iu Mien language, this paper investigates and compares the three
approaches for Iu Mien speech recognition. Our experiments are based on the
recently released, three backbone models pretrained over the 10 languages from
the CommonVoice dataset (CV-Lang10), which correspond to the three approaches
for low-resourced ASR. It is found that phoneme supervision can achieve better
results compared to subword supervision and self-supervision, thereby providing
higher data-efficiency. Particularly, the Whistle models, i.e., obtained by the
weakly-supervised phoneme-based multilingual pre-training, obtain the most
competitive results.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are Large Language Models Capable of Generating Human-Level Narratives? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13248v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13248v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yufei Tian, Tenghao Huang, Miri Liu, Derek Jiang, Alexander Spangher, Muhao Chen, Jonathan May, Nanyun Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates the capability of LLMs in storytelling, focusing on
narrative development and plot progression. We introduce a novel computational
framework to analyze narratives through three discourse-level aspects: i) story
arcs, ii) turning points, and iii) affective dimensions, including arousal and
valence. By leveraging expert and automatic annotations, we uncover significant
discrepancies between the LLM- and human- written stories. While human-written
stories are suspenseful, arousing, and diverse in narrative structures, LLM
stories are homogeneously positive and lack tension. Next, we measure narrative
reasoning skills as a precursor to generative capacities, concluding that most
LLMs fall short of human abilities in discourse understanding. Finally, we show
that explicit integration of aforementioned discourse features can enhance
storytelling, as is demonstrated by over 40% improvement in neural storytelling
in terms of diversity, suspense, and arousal.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PM-LLM-Benchmark: Evaluating Large Language Models on Process Mining
  Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13244v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13244v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alessandro Berti, Humam Kourani, Wil M. P. van der Aalst
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have the potential to semi-automate some process
mining (PM) analyses. While commercial models are already adequate for many
analytics tasks, the competitive level of open-source LLMs in PM tasks is
unknown. In this paper, we propose PM-LLM-Benchmark, the first comprehensive
benchmark for PM focusing on domain knowledge (process-mining-specific and
process-specific) and on different implementation strategies. We focus also on
the challenges in creating such a benchmark, related to the public availability
of the data and on evaluation biases by the LLMs. Overall, we observe that most
of the considered LLMs can perform some process mining tasks at a satisfactory
level, but tiny models that would run on edge devices are still inadequate. We
also conclude that while the proposed benchmark is useful for identifying LLMs
that are adequate for process mining tasks, further research is needed to
overcome the evaluation biases and perform a more thorough ranking of the
competitive LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Large Language Models for Anxiety and Depression
  Classification using Counseling and Psychotherapy Transcripts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13228v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13228v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junwei Sun, Siqi Ma, Yiran Fan, Peter Washington
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We aim to evaluate the efficacy of traditional machine learning and large
language models (LLMs) in classifying anxiety and depression from long
conversational transcripts. We fine-tune both established transformer models
(BERT, RoBERTa, Longformer) and more recent large models (Mistral-7B), trained
a Support Vector Machine with feature engineering, and assessed GPT models
through prompting. We observe that state-of-the-art models fail to enhance
classification outcomes compared to traditional machine learning methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Transformer</span>-based Single-Cell Language Model: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13205v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13205v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Lan, Guohang He, Mingyang Liu, Qingfeng Chen, Junyue Cao, Wei Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The transformers have achieved significant accomplishments in the natural
language processing as its outstanding parallel processing capabilities and
highly flexible attention mechanism. In addition, increasing studies based on
transformers have been proposed to model single-cell data. In this review, we
attempt to systematically summarize the single-cell language models and
applications based on transformers. First, we provide a detailed introduction
about the structure and principles of transformers. Then, we review the
single-cell language models and large language models for single-cell data
analysis. Moreover, we explore the datasets and applications of single-cell
language models in downstream tasks such as batch correction, cell clustering,
cell type annotation, gene regulatory network inference and perturbation
response. Further, we discuss the challenges of single-cell language models and
provide promising research directions. We hope this review will serve as an
up-to-date reference for researchers interested in the direction of single-cell
language models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retrieval-Augmented Generation for Natural Language Processing: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13193v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13193v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan, Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated great success in various
fields, benefiting from their huge amount of parameters that store knowledge.
However, LLMs still suffer from several key issues, such as hallucination
problems, knowledge update issues, and lacking domain-specific expertise. The
appearance of retrieval-augmented generation (RAG), which leverages an external
knowledge database to augment LLMs, makes up those drawbacks of LLMs. This
paper reviews all significant techniques of RAG, especially in the retriever
and the retrieval fusions. Besides, tutorial codes are provided for
implementing the representative techniques in RAG. This paper further discusses
the RAG training, including RAG with/without datastore update. Then, we
introduce the application of RAG in representative natural language processing
tasks and industrial scenarios. Finally, this paper discusses the future
directions and challenges of RAG for promoting its development.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SciCode: A Research Coding Benchmark Curated by Scientists 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13168v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13168v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minyang Tian, Luyu Gao, Shizhuo Dylan Zhang, Xinan Chen, Cunwei Fan, Xuefei Guo, Roland Haas, Pan Ji, Kittithat Krongchon, Yao Li, Shengyan Liu, Di Luo, Yutao Ma, Hao Tong, Kha Trinh, Chenyu Tian, Zihan Wang, Bohao Wu, Yanyu Xiong, Shengzhu Yin, Minhui Zhu, Kilian Lieret, Yanxin Lu, Genglin Liu, Yufeng Du, Tianhua Tao, Ofir Press, Jamie Callan, Eliu Huerta, Hao Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Since language models (LMs) now outperform average humans on many challenging
tasks, it has become increasingly difficult to develop challenging,
high-quality, and realistic evaluations. We address this issue by examining
LMs' capabilities to generate code for solving real scientific research
problems. Incorporating input from scientists and AI researchers in 16 diverse
natural science sub-fields, including mathematics, physics, chemistry, biology,
and materials science, we created a scientist-curated coding benchmark,
SciCode. The problems in SciCode naturally factorize into multiple subproblems,
each involving knowledge recall, reasoning, and code synthesis. In total,
SciCode contains 338 subproblems decomposed from 80 challenging main problems.
It offers optional descriptions specifying useful scientific background
information and scientist-annotated gold-standard solutions and test cases for
evaluation. Claude3.5-Sonnet, the best-performing model among those tested, can
solve only 4.6% of the problems in the most realistic setting. We believe that
SciCode demonstrates both contemporary LMs' progress towards becoming helpful
scientific assistants and sheds light on the development and evaluation of
scientific AI in the future.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 9 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Translate-and-Revise: Boosting Large Language Models for Constrained
  Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13164v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13164v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengcheng Huang, Yongyu Mu, Yuzhang Wu, Bei Li, Chunyang Xiao, Tong Xiao, Jingbo Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Imposing constraints on machine translation systems presents a challenging
issue because these systems are not trained to make use of constraints in
generating adequate, fluent translations. In this paper, we leverage the
capabilities of large language models (LLMs) for constrained translation, given
that LLMs can easily adapt to this task by taking translation instructions and
constraints as prompts. However, LLMs cannot always guarantee the adequacy of
translation, and, in some cases, ignore the given constraints. This is in part
because LLMs might be overly confident in their predictions, overriding the
influence of the constraints. To overcome this overiding behaviour, we propose
to add a revision process that encourages LLMs to correct the outputs by
prompting them about the constraints that have not yet been met. We evaluate
our approach on four constrained translation tasks, encompassing both lexical
and structural constraints in multiple constraint domains. Experiments show
15\% improvement in constraint-based translation accuracy over standard LLMs
and the approach also significantly outperforms neural machine translation
(NMT) state-of-the-art methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Preset-Voice Matching for Privacy Regulated Speech-to-Speech Translation
  Systems <span class="chip">ACL</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13153v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13153v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Platnick, Bishoy Abdelnour, Eamon Earl, Rahul Kumar, Zahra Rezaei, Thomas Tsangaris, Faraj Lagum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, there has been increased demand for speech-to-speech
translation (S2ST) systems in industry settings. Although successfully
commercialized, cloning-based S2ST systems expose their distributors to
liabilities when misused by individuals and can infringe on personality rights
when exploited by media organizations. This work proposes a regulated S2ST
framework called Preset-Voice Matching (PVM). PVM removes cross-lingual voice
cloning in S2ST by first matching the input voice to a similar prior consenting
speaker voice in the target-language. With this separation, PVM avoids cloning
the input speaker, ensuring PVM systems comply with regulations and reduce risk
of misuse. Our results demonstrate PVM can significantly improve S2ST system
run-time in multi-speaker settings and the naturalness of S2ST synthesized
speech. To our knowledge, PVM is the first explicitly regulated S2ST framework
leveraging similarly-matched preset-voices for dynamic S2ST tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the ACL PrivateNLP 2024 Workshop, 7 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A light-weight and efficient punctuation and word casing prediction
  model for on-device streaming ASR 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13142v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13142v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian You, Xiangfeng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Punctuation and word casing prediction are necessary for automatic speech
recognition (ASR). With the popularity of on-device end-to-end streaming ASR
systems, the on-device punctuation and word casing prediction become a
necessity while we found little discussion on this. With the emergence of
Transformer, Transformer based models have been explored for this scenario.
However, Transformer based models are too large for on-device ASR systems. In
this paper, we propose a light-weight and efficient model that jointly predicts
punctuation and word casing in real time. The model is based on Convolutional
Neural Network (CNN) and Bidirectional Long Short-Term Memory (BiLSTM).
Experimental results on the IWSLT2011 test set show that the proposed model
obtains 9% relative improvement compared to the best of non-Transformer models
on overall F1-score. Compared to the representative of Transformer based
models, the proposed model achieves comparable results to the representative
model while being only one-fortieth its size and 2.5 times faster in terms of
inference time. It is suitable for on-device streaming ASR systems. Our code is
publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TrialEnroll: Predicting Clinical Trial Enrollment Success with Deep &
  Cross Network and Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13115v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13115v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ling Yue, Sixue Xing, Jintai Chen, Tianfan Fu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Clinical trials need to recruit a sufficient number of volunteer patients to
demonstrate the statistical power of the treatment (e.g., a new drug) in curing
a certain disease. Clinical trial recruitment has a significant impact on trial
success. Forecasting whether the recruitment process would be successful before
we run the trial would save many resources and time. This paper develops a
novel deep & cross network with large language model (LLM)-augmented text
feature that learns semantic information from trial eligibility criteria and
predicts enrollment success. The proposed method enables interpretability by
understanding which sentence/word in eligibility criteria contributes heavily
to prediction. We also demonstrate the empirical superiority of the proposed
method (0.7002 PR-AUC) over a bunch of well-established machine learning
methods. The code and curated dataset are publicly available at
https://anonymous.4open.science/r/TrialEnroll-7E12.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retrieve, Summarize, Plan: Advancing Multi-hop Question Answering with
  an Iterative Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13101v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13101v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhouyu Jiang, Mengshu Sun, Lei Liang, Zhiqiang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-hop question answering is a challenging task with distinct industrial
relevance, and Retrieval-Augmented Generation (RAG) methods based on large
language models (LLMs) have become a popular approach to tackle this task.
Owing to the potential inability to retrieve all necessary information in a
single iteration, a series of iterative RAG methods has been recently
developed, showing significant performance improvements. However, existing
methods still face two critical challenges: context overload resulting from
multiple rounds of retrieval, and over-planning and repetitive planning due to
the lack of a recorded retrieval trajectory. In this paper, we propose a novel
iterative RAG method called ReSP, equipped with a dual-function summarizer.
This summarizer compresses information from retrieved documents, targeting both
the overarching question and the current sub-question concurrently.
Experimental results on the multi-hop question-answering datasets HotpotQA and
2WikiMultihopQA demonstrate that our method significantly outperforms the
state-of-the-art, and exhibits excellent robustness concerning context length.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AlcLaM: Arabic Dialectal Language Model <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13097v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13097v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Murtadha Ahmed, Saghir Alfasly, Bo Wen, Jamaal Qasem, Mohammed Ahmed, Yunfeng Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained Language Models (PLMs) are integral to many modern natural
language processing (NLP) systems. Although multilingual models cover a wide
range of languages, they often grapple with challenges like high inference
costs and a lack of diverse non-English training data. Arabic-specific PLMs are
trained predominantly on modern standard Arabic, which compromises their
performance on regional dialects. To tackle this, we construct an Arabic
dialectal corpus comprising 3.4M sentences gathered from social media
platforms. We utilize this corpus to expand the vocabulary and retrain a
BERT-based model from scratch. Named AlcLaM, our model was trained using only
13 GB of text, which represents a fraction of the data used by existing models
such as CAMeL, MARBERT, and ArBERT, compared to 7.8%, 10.2%, and 21.3%,
respectively. Remarkably, AlcLaM demonstrates superior performance on a variety
of Arabic NLP tasks despite the limited training data. AlcLaM is available at
GitHub https://github.com/amurtadha/Alclam and HuggingFace
https://huggingface.co/rahbi.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ArabicNLP 2024, presented in ACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for
  Fact-Checking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13089v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13089v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ting-Chih Chen, Chia-Wei Tang, Chris Thomas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fact-checking real-world claims often requires reviewing multiple multimodal
documents to assess a claim's truthfulness, which is a highly laborious and
time-consuming task. In this paper, we present a summarization model designed
to generate claim-specific summaries useful for fact-checking from multimodal,
multi-document datasets. The model takes inputs in the form of documents,
images, and a claim, with the objective of assisting in fact-checking tasks. We
introduce a dynamic perceiver-based model that can handle inputs from multiple
modalities of arbitrary lengths. To train our model, we leverage a novel
reinforcement learning-based entailment objective to generate summaries that
provide evidence distinguishing between different truthfulness labels. To
assess the efficacy of our approach, we conduct experiments on both an existing
benchmark and a new dataset of multi-document claims that we contribute. Our
approach outperforms the SOTA approach by 4.6% in the claim verification task
on the MOCHEG dataset and demonstrates strong performance on our new
Multi-News-Fact-Checking dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 7 figures, The 62nd Annual Meeting of the Association for
  Computational Linguistics</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Sentiment Analysis with Local Large Language Models using
  Majority Voting: A Study on Factors Affecting Restaurant Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13069v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13069v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junichiro Niimi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  User-generated contents (UGCs) on online platforms allow marketing
researchers to understand consumer preferences for products and services. With
the advance of large language models (LLMs), some studies utilized the models
for annotation and sentiment analysis. However, the relationship between the
accuracy and the hyper-parameters of LLMs is yet to be thoroughly examined. In
addition, the issues of variability and reproducibility of results from each
trial of LLMs have rarely been considered in existing literature. Since actual
human annotation uses majority voting to resolve disagreements among
annotators, this study introduces a majority voting mechanism to a sentiment
analysis model using local LLMs. By a series of three analyses of online
reviews on restaurant evaluations, we demonstrate that majority voting with
multiple attempts using a medium-sized model produces more robust results than
using a large model with a single attempt. Furthermore, we conducted further
analysis to investigate the effect of each aspect on the overall evaluation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This manuscript is under peer review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Transformer</span>s Get Stable: An End-to-End Signal Propagation Theory for
  Language Models <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.09635v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.09635v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akhil Kedia, Mohd Abbas Zaidi, Sushil Khyalia, Jungho Jung, Harshith Goka, Haejun Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In spite of their huge success, transformer models remain difficult to scale
in depth. In this work, we develop a unified signal propagation theory and
provide formulae that govern the moments of the forward and backward signal
through the transformer model. Our framework can be used to understand and
mitigate vanishing/exploding gradients, rank collapse, and instability
associated with high attention scores. We also propose DeepScaleLM, an
initialization and scaling scheme that conserves unit output/gradient moments
throughout the model, enabling the training of very deep models with 1000
layers. We find that transformer models could be much deeper - our deep models
with fewer parameters outperform shallow models in Language Modeling, Speech
Translation, and Image Classification, across encoder-only, decoder-only and
encoder-decoder variants, for both Pre-LN and Post-LN transformers, for
multiple datasets and model sizes. These improvements also translate into
improved performance on downstream Question Answering tasks and improved
robustness for Image Classification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICML 2024. Source code is available at
  https://github.com/akhilkedia/TranformersGetStable. Akhil Kedia, Mohd Abbas
  Zaidi, Sushil Khyalia equal contribution</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AWQ: Activation-aware Weight Quantization for LLM Compression and
  Acceleration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.00978v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.00978v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Wei-Ming Chen, Wei-Chen Wang, Guangxuan Xiao, Xingyu Dang, Chuang Gan, Song Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have transformed numerous AI applications.
On-device LLM is becoming increasingly important: running LLMs locally on edge
devices can reduce the cloud computing cost and protect users' privacy.
However, the astronomical model size and the limited hardware resource pose
significant deployment challenges. We propose Activation-aware Weight
Quantization (AWQ), a hardware-friendly approach for LLM low-bit weight-only
quantization. AWQ finds that not all weights in an LLM are equally important.
Protecting only 1% salient weights can greatly reduce quantization error. To
identify salient weight channels, we should refer to the activation
distribution, not weights. To avoid the hardware-inefficient mix-precision
quantization, we mathematically derive that scaling up the salient channels can
reduce the quantization error. AWQ employs an equivalent transformation to
scale the salient weight channels to protect them. The scale is determined by
collecting the activation statistics offline. AWQ does not rely on any
backpropagation or reconstruction, so it generalizes to different domains and
modalities without overfitting the calibration set. AWQ outperforms existing
work on various language modeling and domain-specific benchmarks (coding and
math). Thanks to better generalization, it achieves excellent quantization
performance for instruction-tuned LMs and, for the first time, multi-modal LMs.
Alongside AWQ, we implement TinyChat, an efficient and flexible inference
framework tailored for 4-bit on-device LLM/VLMs. With kernel fusion and
platform-aware weight packing, TinyChat offers more than 3x speedup over the
Huggingface FP16 implementation on both desktop and mobile GPUs. It also
democratizes the deployment of the 70B Llama-2 model on mobile GPUs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>MLSys 2024 Best Paper Award. Code available at:
  https://github.com/mit-han-lab/llm-awq</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Benchmarking Vision Language Models for Cultural Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10920v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10920v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shravan Nayak, Kanishk Jain, Rabiul Awal, Siva Reddy, Sjoerd van Steenkiste, Lisa Anne Hendricks, Karolina Stańczak, Aishwarya Agrawal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation models and vision-language pre-training have notably advanced
Vision Language Models (VLMs), enabling multimodal processing of visual and
linguistic data. However, their performance has been typically assessed on
general scene understanding - recognizing objects, attributes, and actions -
rather than cultural comprehension. This study introduces CulturalVQA, a visual
question-answering benchmark aimed at assessing VLM's geo-diverse cultural
understanding. We curate a collection of 2,378 image-question pairs with 1-5
answers per question representing cultures from 11 countries across 5
continents. The questions probe understanding of various facets of culture such
as clothing, food, drinks, rituals, and traditions. Benchmarking VLMs on
CulturalVQA, including GPT-4V and Gemini, reveals disparity in their level of
cultural understanding across regions, with strong cultural understanding
capabilities for North America while significantly lower performance for
Africa. We observe disparity in their performance across cultural facets too,
with clothing, rituals, and traditions seeing higher performances than food and
drink. These disparities help us identify areas where VLMs lack cultural
understanding and demonstrate the potential of CulturalVQA as a comprehensive
evaluation set for gauging VLM progress in understanding diverse cultures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Learning to Summarize with Large Language Models as References <span class="chip">NAACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.14239v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.14239v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixin Liu, Kejian Shi, Katherine S He, Longtian Ye, Alexander R. Fabbri, Pengfei Liu, Dragomir Radev, Arman Cohan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies have found that summaries generated by large language models
(LLMs) are favored by human annotators over the original reference summaries in
commonly used summarization datasets. Therefore, we study an LLM-as-reference
learning setting for smaller text summarization models to investigate whether
their performance can be substantially improved. To this end, we use LLMs as
both oracle summary generators for standard supervised fine-tuning and oracle
summary evaluators for efficient contrastive learning that leverages the LLMs'
supervision signals. We conduct comprehensive experiments with source news
articles and find that (1) summarization models trained under the
LLM-as-reference setting achieve significant performance improvement in both
LLM and human evaluations; (2) contrastive learning outperforms standard
supervised fine-tuning under both low and high resource settings. Our
experimental results also enable a meta-analysis of LLMs' summary evaluation
capacities under a challenging setting, showing that LLMs are not well-aligned
with human evaluators. Particularly, our expert human evaluation reveals
remaining nuanced performance gaps between LLMs and our fine-tuned models,
which LLMs fail to capture. Thus, we call for further studies into both the
potential and challenges of using LLMs in summarization model development.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2024, GitHub Repo: https://github.com/yixinL7/SumLLM</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ QJL: 1-Bit Quantized JL Transform for KV Cache Quantization with Zero
  Overhead 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.03482v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.03482v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amir Zandieh, Majid Daliri, Insu Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Serving LLMs requires substantial memory due to the storage requirements of
Key-Value (KV) embeddings in the KV cache, which grows with sequence length. An
effective approach to compress KV cache is quantization. However, traditional
quantization methods face significant memory overhead due to the need to store
quantization constants (at least a zero point and a scale) in full precision
per data block. Depending on the block size, this overhead can add 1 or 2 bits
per quantized number. We introduce QJL, a new quantization approach that
consists of a Johnson-Lindenstrauss (JL) transform followed by sign-bit
quantization. In contrast to existing methods, QJL eliminates memory overheads
by removing the need for storing quantization constants. We propose an
asymmetric estimator for the inner product of two vectors and demonstrate that
applying QJL to one vector and a standard JL transform without quantization to
the other provides an unbiased estimator with minimal distortion. We have
developed an efficient implementation of the QJL sketch and its corresponding
inner product estimator, incorporating a lightweight CUDA kernel for optimized
computation. When applied across various LLMs and NLP tasks to quantize the KV
cache to only 3 bits, QJL demonstrates a more than fivefold reduction in KV
cache memory usage without compromising accuracy, all while achieving faster
runtime. Codes are available at \url{https://github.com/amirzandieh/QJL}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision
  Language Models <span class="chip">NAACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.17912v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.17912v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manav Nitin Kapadnis, Sohan Patnaik, Abhilash Nandy, Sourjyadip Ray, Pawan Goyal, Debdoot Sheet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Radiology Report Generation (R2Gen) demonstrates how Multi-modal Large
Language Models (MLLMs) can automate the creation of accurate and coherent
radiological reports. Existing methods often hallucinate details in text-based
reports that don't accurately reflect the image content. To mitigate this, we
introduce a novel strategy, SERPENT-VLM (SElf Refining Radiology RePort
GENeraTion using Vision Language Models), which improves the R2Gen task by
integrating a self-refining mechanism into the MLLM framework. We employ a
unique self-supervised loss that leverages similarity between pooled image
representations and the contextual representations of the generated
radiological text, alongside the standard Causal Language Modeling objective,
to refine image-text representations. This allows the model to scrutinize and
align the generated text through dynamic interaction between a given image and
the generated text, therefore reducing hallucination and continuously enhancing
nuanced report generation. SERPENT-VLM outperforms existing baselines such as
LLaVA-Med, BiomedGPT, etc., achieving SoTA performance on the IU X-ray and
Radiology Objects in COntext (ROCO) datasets, and also proves to be robust
against noisy images. A qualitative case study emphasizes the significant
advancements towards more sophisticated MLLM frameworks for R2Gen, opening
paths for further research into self-supervised refinement in the medical
imaging domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 3 figures, 4 tables, Accepted as oral at Clinical NLP
  workshop at NAACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Chinchilla-Optimal: Accounting for Inference in Language Model
  Scaling Laws 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.00448v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.00448v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nikhil Sardana, Jacob Portes, Sasha Doubov, Jonathan Frankle
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language model (LLM) scaling laws are empirical formulas that estimate
changes in model quality as a result of increasing parameter count and training
data. However, these formulas, including the popular Deepmind Chinchilla
scaling laws, neglect to include the cost of inference. We modify the
Chinchilla scaling laws to calculate the optimal LLM parameter count and
pre-training data size to train and deploy a model of a given quality and
inference demand. We conduct our analysis both in terms of a compute budget and
real-world costs and find that LLM researchers expecting reasonably large
inference demand (~1B requests) should train models smaller and longer than
Chinchilla-optimal. Furthermore, we train 47 models of varying sizes and
parameter counts to validate our formula and find that model quality continues
to improve as we scale tokens per parameter to extreme ranges (up to 10,000).
Finally, we ablate the procedure used to fit the Chinchilla scaling law
coefficients and find that developing scaling laws only from data collected at
typical token/parameter ratios overestimates the impact of additional tokens at
these extreme ranges.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 7 figures, To appear in the 41st International Conference
  on Machine Learning, 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Making Reasoning Matter: Measuring and Improving Faithfulness of
  Chain-of-Thought Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.13950v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.13950v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Debjit Paul, Robert West, Antoine Bosselut, Boi Faltings
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have been shown to perform better when asked to
reason step-by-step before answering a question. However, it is unclear to what
degree the model's final answer is faithful to the stated reasoning steps. In
this paper, we perform a causal mediation analysis on twelve LLMs to examine
how intermediate reasoning steps generated by the LLM influence the final
outcome and find that LLMs do not reliably use their intermediate reasoning
steps when generating an answer. To address this issue, we introduce FRODO, a
framework to tailor small-sized LMs to generate correct reasoning steps and
robustly reason over these steps. FRODO consists of an inference module that
learns to generate correct reasoning steps using an implicit causal reward
function and a reasoning module that learns to faithfully reason over these
intermediate inferences using a counterfactual and causal preference objective.
Our experiments show that FRODO significantly outperforms four competitive
baselines. Furthermore, FRODO improves the robustness and generalization
ability of the reasoning LM, yielding higher performance on out-of-distribution
test sets. Finally, we find that FRODO's rationales are more faithful to its
final answer predictions than standard supervised fine-tuning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Open-Source Conversational AI with SpeechBrain 1.0 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.00463v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.00463v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mirco Ravanelli, Titouan Parcollet, Adel Moumen, Sylvain de Langen, Cem Subakan, Peter Plantinga, Yingzhi Wang, Pooneh Mousavi, Luca Della Libera, Artem Ploujnikov, Francesco Paissan, Davide Borra, Salah Zaiem, Zeyu Zhao, Shucong Zhang, Georgios Karakasidis, Sung-Lin Yeh, Pierre Champion, Aku Rouhe, Rudolf Braun, Florian Mai, Juan Zuluaga-Gomez, Seyed Mahed Mousavi, Andreas Nautsch, Xuechen Liu, Sangeet Sagar, Jarod Duret, Salima Mdhaffar, Gaelle Laperriere, Mickael Rouvier, Renato De Mori, Yannick Esteve
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  SpeechBrain is an open-source Conversational AI toolkit based on PyTorch,
focused particularly on speech processing tasks such as speech recognition,
speech enhancement, speaker recognition, text-to-speech, and much more. It
promotes transparency and replicability by releasing both the pre-trained
models and the complete "recipes" of code and algorithms required for training
them. This paper presents SpeechBrain 1.0, a significant milestone in the
evolution of the toolkit, which now has over 200 recipes for speech, audio, and
language processing tasks, and more than 100 models available on Hugging Face.
SpeechBrain 1.0 introduces new technologies to support diverse learning
modalities, Large Language Model (LLM) integration, and advanced decoding
strategies, along with novel models, tasks, and modalities. It also includes a
new benchmark repository, offering researchers a unified platform for
evaluating models across diverse tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to JMLR (Machine Learning Open Source Software)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Pronunciation Assessment with Multi-modal Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09209v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09209v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaiqi Fu, Linkai Peng, Nan Yang, Shuran Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs), renowned for their powerful conversational
abilities, are widely recognized as exceptional tools in the field of
education, particularly in the context of automated intelligent instruction
systems for language learning. In this paper, we propose a scoring system based
on LLMs, motivated by their positive impact on text-related scoring tasks.
Specifically, the speech encoder first maps the learner's speech into
contextual features. The adapter layer then transforms these features to align
with the text embedding in latent space. The assessment task-specific prefix
and prompt text are embedded and concatenated with the features generated by
the modality adapter layer, enabling the LLMs to predict accuracy and fluency
scores. Our experiments demonstrate that the proposed scoring systems achieve
competitive results compared to the baselines on the Speechocean762 datasets.
Moreover, we also conducted an ablation study to better understand the
contributions of the prompt text and training strategy in the proposed scoring
system.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UMBRAE: Unified Multimodal Brain Decoding <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.07202v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.07202v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weihao Xia, Raoul de Charette, Cengiz Öztireli, Jing-Hao Xue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address prevailing challenges of the brain-powered research, departing
from the observation that the literature hardly recover accurate spatial
information and require subject-specific models. To address these challenges,
we propose UMBRAE, a unified multimodal decoding of brain signals. First, to
extract instance-level conceptual and spatial details from neural signals, we
introduce an efficient universal brain encoder for multimodal-brain alignment
and recover object descriptions at multiple levels of granularity from
subsequent multimodal large language model (MLLM). Second, we introduce a
cross-subject training strategy mapping subject-specific features to a common
feature space. This allows a model to be trained on multiple subjects without
extra resources, even yielding superior results compared to subject-specific
models. Further, we demonstrate this supports weakly-supervised adaptation to
new subjects, with only a fraction of the total training data. Experiments
demonstrate that UMBRAE not only achieves superior results in the newly
introduced tasks but also outperforms methods in well established tasks. To
assess our method, we construct and share with the community a comprehensive
brain understanding benchmark BrainHub. Our code and benchmark are available at
https://weihaox.github.io/UMBRAE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024. Project: https://weihaox.github.io/UMBRAE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Survey</span> in Characterization of Semantic Change 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.19088v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.19088v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jader Martins Camboim de Sá, Marcos Da Silveira, Cédric Pruski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Live languages continuously evolve to integrate the cultural change of human
societies. This evolution manifests through neologisms (new words) or
\textbf{semantic changes} of words (new meaning to existing words).
Understanding the meaning of words is vital for interpreting texts coming from
different cultures (regionalism or slang), domains (e.g., technical terms), or
periods. In computer science, these words are relevant to computational
linguistics algorithms such as translation, information retrieval, question
answering, etc. Semantic changes can potentially impact the quality of the
outcomes of these algorithms. Therefore, it is important to understand and
characterize these changes formally. The study of this impact is a recent
problem that has attracted the attention of the computational linguistics
community. Several approaches propose methods to detect semantic changes with
good precision, but more effort is needed to characterize how the meaning of
words changes and to reason about how to reduce the impact of semantic change.
This survey provides an understandable overview of existing approaches to the
\textit{characterization of semantic changes} and also formally defines three
classes of characterizations: if the meaning of a word becomes more general or
narrow (change in dimension) if the word is used in a more pejorative or
positive/ameliorated sense (change in orientation), and if there is a trend to
use the word in a, for instance, metaphoric or metonymic context (change in
relation). We summarized the main aspects of the selected publications in a
table and discussed the needs and trends in the research activities on semantic
change characterization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Words: On Large Language Models Actionability in Mission-Critical
  Risk Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10273v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10273v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matteo Esposito, Francesco Palagiano, Valentina Lenarduzzi, Davide Taibi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Context. Risk analysis assesses potential risks in specific scenarios. Risk
analysis principles are context-less; the same methodology can be applied to a
risk connected to health and information technology security. Risk analysis
requires a vast knowledge of national and international regulations and
standards and is time and effort-intensive. A large language model can quickly
summarize information in less time than a human and can be fine-tuned to
specific tasks.
  Aim. Our empirical study aims to investigate the effectiveness of
Retrieval-Augmented Generation and fine-tuned LLM in risk analysis. To our
knowledge, no prior study has explored its capabilities in risk analysis.
  Method. We manually curated 193 unique scenarios leading to 1283
representative samples from over 50 mission-critical analyses archived by the
industrial context team in the last five years. We compared the base GPT-3.5
and GPT-4 models versus their Retrieval-Augmented Generation and fine-tuned
counterparts. We employ two human experts as competitors of the models and
three other human experts to review the models and the former human experts'
analysis. The reviewers analyzed 5,000 scenario analyses.
  Results and Conclusions. Human experts demonstrated higher accuracy, but LLMs
are quicker and more actionable. Moreover, our findings show that RAG-assisted
LLMs have the lowest hallucination rates, effectively uncovering hidden risks
and complementing human expertise. Thus, the choice of model depends on
specific needs, with FTMs for accuracy, RAG for hidden risks discovery, and
base models for comprehensiveness and actionability. Therefore, experts can
leverage LLMs as an effective complementing companion in risk analysis within a
condensed timeframe. They can also save costs by averting unnecessary expenses
associated with implementing unwarranted countermeasures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HORAE: A Domain-Agnostic Modeling Language for Automating Multimodal
  Service Regulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.06600v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.06600v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yutao Sun, Mingshuai Chen, Tiancheng Zhao, Kangjia Zhao, He Li, Jintao Chen, Liqiang Lu, Xinkui Zhao, Shuiguang Deng, Jianwei Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial intelligence is rapidly encroaching on the field of service
regulation. This work presents the design principles behind HORAE, a unified
specification language to model multimodal regulation rules across a diverse
set of domains. We show how HORAE facilitates an intelligent service regulation
pipeline by further exploiting a fine-tuned large language model named HORAE
that automates the HORAE modeling process, thereby yielding an end-to-end
framework for fully automated intelligent service regulation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Assessing LLMs Suitability for Knowledge Graph Completion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17249v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17249v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vasile Ionut Remus Iga, Gheorghe Cosmin Silaghi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent work has shown the capability of Large Language Models (LLMs) to solve
tasks related to Knowledge Graphs, such as Knowledge Graph Completion, even in
Zero- or Few-Shot paradigms. However, they are known to hallucinate answers, or
output results in a non-deterministic manner, thus leading to wrongly reasoned
responses, even if they satisfy the user's demands. To highlight opportunities
and challenges in knowledge graphs-related tasks, we experiment with three
distinguished LLMs, namely Mixtral-8x7b-Instruct-v0.1, GPT-3.5-Turbo-0125 and
GPT-4o, on Knowledge Graph Completion for static knowledge graphs, using
prompts constructed following the TELeR taxonomy, in Zero- and One-Shot
contexts, on a Task-Oriented Dialogue system use case. When evaluated using
both strict and flexible metrics measurement manners, our results show that
LLMs could be fit for such a task if prompts encapsulate sufficient information
and relevant examples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at 18th International Conference on Neural-Symbolic Learning
  and Reasoning, NESY 2024. Evaluating Mixtral-8x7b-Instruct-v0.1,
  GPT-3.5-Turbo-0125 and GPT-4o for Knowledge Graph Completion task with
  prompts formatted according to the TELeR taxonomy</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> of Multimodal Large Language Model from A Data-centric
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16640v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16640v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyi Bai, Hao Liang, Binwang Wan, Yanran Xu, Xi Li, Shiyu Li, Ling Yang, Bozhou Li, Yifan Wang, Bin Cui, Ping Huang, Jiulong Shan, Conghui He, Binhang Yuan, Wentao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal large language models (MLLMs) enhance the capabilities of standard
large language models by integrating and processing data from multiple
modalities, including text, vision, audio, video, and 3D environments. Data
plays a pivotal role in the development and refinement of these models. In this
survey, we comprehensively review the literature on MLLMs from a data-centric
perspective. Specifically, we explore methods for preparing multimodal data
during the pretraining and adaptation phases of MLLMs. Additionally, we analyze
the evaluation methods for the datasets and review the benchmarks for
evaluating MLLMs. Our survey also outlines potential future research
directions. This work aims to provide researchers with a detailed understanding
of the data-driven aspects of MLLMs, fostering further exploration and
innovation in this field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Self-play with Execution Feedback: Improving Instruction-following
  Capabilities of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13542v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13542v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guanting Dong, Keming Lu, Chengpeng Li, Tingyu Xia, Bowen Yu, Chang Zhou, Jingren Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One core capability of large language models (LLMs) is to follow natural
language instructions. However, the issue of automatically constructing
high-quality training data to enhance the complex instruction-following
abilities of LLMs without manual annotation remains unresolved. In this paper,
we introduce AutoIF, the first scalable and reliable method for automatically
generating instruction-following training data. AutoIF transforms the
validation of instruction-following data quality into code verification,
requiring LLMs to generate instructions, the corresponding code to check the
correctness of the instruction responses, and unit test samples to verify the
code's correctness. Then, execution feedback-based rejection sampling can
generate data for Supervised Fine-Tuning (SFT) and Reinforcement Learning from
Human Feedback (RLHF) training. AutoIF achieves significant improvements across
three training algorithms, SFT, Offline DPO, and Online DPO, when applied to
the top open-source LLMs, Qwen2 and LLaMA3, in self-alignment and
strong-to-weak distillation settings. Our code is publicly available at
https://github.com/QwenLM/AutoIF.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PAS: Data-Efficient Plug-and-Play <span class="highlight-title">Prompt</span> Augmentation System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06027v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06027v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Miao Zheng, Hao Liang, Fan Yang, Haoze Sun, Tianpeng Li, Lingchu Xiong, Yan Zhang, Youzhen Wu, Kun Li, Yanjun Shen, Mingan Lin, Tao Zhang, Guosheng Dong, Yujing Qiao, Kun Fang, Weipeng Chen, Bin Cui, Wentao Zhang, Zenan Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, the rise of Large Language Models (LLMs) has spurred a
growing demand for plug-and-play AI systems. Among the various AI techniques,
prompt engineering stands out as particularly significant. However, users often
face challenges in writing prompts due to the steep learning curve and
significant time investment, and existing automatic prompt engineering (APE)
models can be difficult to use. To address this issue, we propose PAS, an
LLM-based plug-and-play APE system. PAS utilizes LLMs trained on high-quality,
automatically generated prompt complementary datasets, resulting in exceptional
performance. In comprehensive benchmarks, PAS achieves state-of-the-art (SoTA)
results compared to previous APE models, with an average improvement of 6.09
points. Moreover, PAS is highly efficient, achieving SoTA performance with only
9000 data points. Additionally, PAS can autonomously generate prompt
augmentation data without requiring additional human labor. Its flexibility
also allows it to be compatible with all existing LLMs and applicable to a wide
range of tasks. PAS excels in human evaluations, underscoring its suitability
as a plug-in for users. This combination of high performance, efficiency, and
flexibility makes PAS a valuable system for enhancing the usability and
effectiveness of LLMs through improved prompt engineering.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLM Factoscope: Uncovering LLMs' Factual Discernment through Inner
  States Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.16374v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.16374v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinwen He, Yujia Gong, Kai Chen, Zijin Lin, Chengan Wei, Yue Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have revolutionized various domains with
extensive knowledge and creative capabilities. However, a critical issue with
LLMs is their tendency to produce outputs that diverge from factual reality.
This phenomenon is particularly concerning in sensitive applications such as
medical consultation and legal advice, where accuracy is paramount. In this
paper, we introduce the LLM factoscope, a novel Siamese network-based model
that leverages the inner states of LLMs for factual detection. Our
investigation reveals distinguishable patterns in LLMs' inner states when
generating factual versus non-factual content. We demonstrate the LLM
factoscope's effectiveness across various architectures, achieving over 96%
accuracy in factual detection. Our work opens a new avenue for utilizing LLMs'
inner states for factual detection and encourages further exploration into
LLMs' inner workings for enhanced reliability and transparency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Understand What LLM Needs: Dual Preference Alignment for
  Retrieval-Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18676v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18676v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guanting Dong, Yutao Zhu, Chenghao Zhang, Zechen Wang, Zhicheng Dou, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) has demonstrated effectiveness in
mitigating the hallucination problem of large language models (LLMs). However,
the difficulty of aligning the retriever with the diverse LLMs' knowledge
preferences inevitably poses an inevitable challenge in developing a reliable
RAG system. To address this issue, we propose DPA-RAG, a universal framework
designed to align diverse knowledge preferences within RAG systems.
Specifically, we initially introduce a preference knowledge construction
pipline and incorporate five novel query augmentation strategies to alleviate
preference data scarcity. Based on preference data, DPA-RAG accomplishes both
external and internal preference alignment: 1) It jointly integrate pair-wise,
point-wise, and contrastive preference alignment abilities into the reranker,
achieving external preference alignment among RAG components. 2) It further
introduces a pre-aligned stage before vanilla Supervised Fine-tuning (SFT),
enabling LLMs to implicitly capture knowledge aligned with their reasoning
preferences, achieving LLMs' internal alignment. Experimental results across
four knowledge-intensive QA datasets demonstrate that DPA-RAG outperforms all
baselines and seamlessly integrates both black-box and open-sourced LLM
readers. Further qualitative analysis and discussions also provide empirical
guidance for achieving reliable RAG systems. Our code is publicly available at
https://github.com/dongguanting/DPA-RAG.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Common Sense Reasoning for Deepfake Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.00126v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.00126v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yue Zhang, Ben Colman, Xiao Guo, Ali Shahriyari, Gaurav Bharaj
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State-of-the-art deepfake detection approaches rely on image-based features
extracted via neural networks. While these approaches trained in a supervised
manner extract likely fake features, they may fall short in representing
unnatural `non-physical' semantic facial attributes -- blurry hairlines, double
eyebrows, rigid eye pupils, or unnatural skin shading. However, such facial
attributes are easily perceived by humans and used to discern the authenticity
of an image based on human common sense. Furthermore, image-based feature
extraction methods that provide visual explanations via saliency maps can be
hard to interpret for humans. To address these challenges, we frame deepfake
detection as a Deepfake Detection VQA (DD-VQA) task and model human intuition
by providing textual explanations that describe common sense reasons for
labeling an image as real or fake. We introduce a new annotated dataset and
propose a Vision and Language Transformer-based framework for the DD-VQA task.
We also incorporate text and image-aware feature alignment formulation to
enhance multi-modal representation learning. As a result, we improve upon
existing deepfake detection models by integrating our learned vision
representations, which reason over common sense knowledge from the DD-VQA task.
We provide extensive empirical results demonstrating that our method enhances
detection performance, generalization ability, and language-based
interpretability in the deepfake detection task.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating the Elementary Multilingual Capabilities of Large Language
  Models with MultiQ 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.03814v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.03814v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Carolin Holtermann, Paul Röttger, Timm Dill, Anne Lauscher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) need to serve everyone, including a global
majority of non-English speakers. However, most LLMs today, and open LLMs in
particular, are often intended for use in just English (e.g. Llama2, Mistral)
or a small handful of high-resource languages (e.g. Mixtral, Qwen). Recent
research shows that, despite limits in their intended use, people prompt LLMs
in many different languages. Therefore, in this paper, we investigate the basic
multilingual capabilities of state-of-the-art open LLMs beyond their intended
use. For this purpose, we introduce MultiQ, a new silver standard benchmark for
basic open-ended question answering with 27.4k test questions across a
typologically diverse set of 137 languages. With MultiQ, we evaluate language
fidelity, i.e. whether models respond in the prompted language, and question
answering accuracy. All LLMs we test respond faithfully and/or accurately for
at least some languages beyond their intended use. Most models are more
accurate when they respond faithfully. However, differences across models are
large, and there is a long tail of languages where models are neither accurate
nor faithful. We explore differences in tokenization as a potential explanation
for our findings, identifying possible correlations that warrant further
investigation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning From Correctness Without <span class="highlight-title">Prompt</span>ing Makes LLM Efficient Reasoner 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.19094v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.19094v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Yao, Han Wu, Zhijiang Guo, Biyan Zhou, Jiahui Gao, Sichun Luo, Hanxu Hou, Xiaojin Fu, Linqi Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated outstanding performance across
various tasks, yet they still exhibit limitations such as hallucination,
unfaithful reasoning, and toxic content. One potential approach to mitigate
these issues is learning from human or external feedback (e.g. tools). In this
paper, we introduce an intrinsic self-correct reasoning framework for LLMs that
eliminates the need for human feedback, external tools, and handcraft prompts.
The proposed framework, based on a multi-step reasoning paradigm
\textbf{Le}arning from \textbf{Co}rrectness (\textsc{LeCo}), improves reasoning
performance without needing to learn from errors. This paradigm prioritizes
learning from correct reasoning steps, and a unique method to measure
confidence for each reasoning step based on generation logits. Experimental
results across various multi-step reasoning tasks demonstrate the effectiveness
of the framework in improving reasoning performance with reduced token
consumption.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to COLM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Computation Efficiency in Large Language Models through Weight
  and Activation Quantization <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.05161v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.05161v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Janghwan Lee, Minsoo Kim, Seungcheol Baek, Seok Joong Hwang, Wonyong Sung, Jungwook Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are proficient in natural language processing
tasks, but their deployment is often restricted by extensive parameter sizes
and computational demands. This paper focuses on post-training quantization
(PTQ) in LLMs, specifically 4-bit weight and 8-bit activation (W4A8)
quantization, to enhance computational efficiency -- a topic less explored
compared to weight-only quantization. We present two innovative techniques:
activation-quantization-aware scaling (AQAS) and sequence-length-aware
calibration (SLAC) to enhance PTQ by considering the combined effects on
weights and activations and aligning calibration sequence lengths to target
tasks. Moreover, we introduce dINT, a hybrid data format combining integer and
denormal representations, to address the underflow issue in W4A8 quantization,
where small values are rounded to zero. Through rigorous evaluations of LLMs,
including OPT and LLaMA, we demonstrate that our techniques significantly boost
task accuracies to levels comparable with full-precision models. By developing
arithmetic units compatible with dINT, we further confirm that our methods
yield a 2$\times$ hardware efficiency improvement compared to 8-bit integer MAC
unit.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2023 Main Conference. Corrected an error in the first author
  name</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Conversational Abilities of Quantized Large Language Models
  via Direct Preference Alignment <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.03051v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.03051v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Janghwan Lee, Seongmin Park, Sukjin Hong, Minsoo Kim, Du-Seong Chang, Jungwook Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of large language models (LLMs) has facilitated their
transformation into conversational chatbots that can grasp contextual nuances
and generate pertinent sentences, closely mirroring human values through
advanced techniques such as instruction tuning and reinforcement learning from
human feedback (RLHF). However, the computational efficiency required for LLMs,
achieved through techniques like post-training quantization (PTQ), presents
challenges such as token-flipping that can impair chatbot performance. In
response, we propose a novel preference alignment approach, quantization-aware
direct preference optimization (QDPO), that aligns quantized LLMs with their
full-precision counterparts, improving conversational abilities. Evaluated on
two instruction-tuned LLMs in various languages, QDPO demonstrated superior
performance in improving conversational abilities compared to established PTQ
and knowledge-distillation fine-tuning techniques, marking a significant step
forward in the development of efficient and effective conversational LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LGDE: Local Graph-based Dictionary Expansion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.07764v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.07764v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dominik J. Schindler, Sneha Jha, Xixuan Zhang, Kilian Buehling, Annett Heft, Mauricio Barahona
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Local Graph-based Dictionary Expansion (LGDE), a method for
data-driven discovery of the semantic neighbourhood of words using tools from
manifold learning and network science. At the heart of LGDE lies the creation
of a word similarity graph from the geometry of word embeddings followed by
local community detection based on graph diffusion. The diffusion in the local
graph manifold allows the exploration of the complex nonlinear geometry of word
embeddings to capture word similarities based on paths of semantic association,
over and above direct pairwise similarities. Exploiting such semantic
neighbourhoods enables the expansion of dictionaries of pre-selected keywords,
an important step for tasks in information retrieval, such as database queries
and online data collection. We validate LGDE on a corpus of English-language
hate speech-related posts from Reddit and Gab and show that LGDE enriches the
list of keywords with significantly better performance than threshold methods
based on direct word similarities. We further demonstrate our method through a
real-world use case from communication science, where LGDE is evaluated
quantitatively on the expansion of a conspiracy-related dictionary from online
data collected and analysed by domain experts. Our empirical results and expert
user assessment indicate that LGDE expands the seed dictionary with more useful
keywords due to the manifold-learning-based similarity network.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Python code available at:
  https://github.com/barahona-research-group/LGDE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Detecting out-of-distribution text using topological features of
  <span class="highlight-title">transformer</span>-based language models <span class="chip">IJCAI-2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.13102v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.13102v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andres Pollano, Anupam Chaudhuri, Anj Simmons
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To safeguard machine learning systems that operate on textual data against
out-of-distribution (OOD) inputs that could cause unpredictable behaviour, we
explore the use of topological features of self-attention maps from
transformer-based language models to detect when input text is out of
distribution. Self-attention forms the core of transformer-based language
models, dynamically assigning vectors to words based on context, thus in theory
our methodology is applicable to any transformer-based language model with
multihead self-attention. We evaluate our approach on BERT and compare it to a
traditional OOD approach using CLS embeddings. Our results show that our
approach outperforms CLS embeddings in distinguishing in-distribution samples
from far-out-of-domain samples, but struggles with near or same-domain
datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 6 figures, 3 tables, to be published in proceedings of the
  IJCAI-2024 AISafety Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Should we be going MAD? A Look at Multi-Agent Debate Strategies for LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.17371v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.17371v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andries Smit, Paul Duckworth, Nathan Grinsztajn, Thomas D. Barrett, Arnu Pretorius
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in large language models (LLMs) underscore their
potential for responding to inquiries in various domains. However, ensuring
that generative agents provide accurate and reliable answers remains an ongoing
challenge. In this context, multi-agent debate (MAD) has emerged as a promising
strategy for enhancing the truthfulness of LLMs. We benchmark a range of
debating and prompting strategies to explore the trade-offs between cost, time,
and accuracy. Importantly, we find that multi-agent debating systems, in their
current form, do not reliably outperform other proposed prompting strategies,
such as self-consistency and ensembling using multiple reasoning paths.
However, when performing hyperparameter tuning, several MAD systems, such as
Multi-Persona, perform better. This suggests that MAD protocols might not be
inherently worse than other approaches, but that they are more sensitive to
different hyperparameter settings and difficult to optimize. We build on these
results to offer insights into improving debating strategies, such as adjusting
agent agreement levels, which can significantly enhance performance and even
surpass all other non-debate protocols we evaluated. We provide an open-source
repository to the community with several state-of-the-art protocols together
with evaluation scripts to benchmark across popular research datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>2 pages, 13 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RoT: Enhancing Large Language Models with Reflection on Search Trees 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.05449v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.05449v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenyang Hui, Kewei Tu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated impressive capability in
reasoning and planning when integrated with tree-search-based prompting
methods. However, since these methods ignore the previous search experiences,
they often make the same mistakes in the search process. To address this issue,
we introduce Reflection on search Trees (RoT), an LLM reflection framework
designed to improve the performance of tree-search-based prompting methods. It
uses a strong LLM to summarize guidelines from previous tree search experiences
to enhance the ability of a weak LLM. The guidelines are instructions about
solving this task through tree search which can prevent the weak LLMs from
making similar mistakes in the past search process. In addition, we proposed a
novel state selection method, which identifies the critical information from
historical search processes to help RoT generate more specific and meaningful
guidelines. In our extensive experiments, we find that RoT significantly
improves the performance of LLMs in reasoning or planning tasks with various
tree-search-based prompting methods (e.g., BFS and MCTS). Non-tree-search-based
prompting methods such as Chain-of-Thought (CoT) can also benefit from RoT
guidelines since RoT can provide task-specific knowledge collected from the
search experience.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Labelled <span class="highlight-title">Dataset</span> for Sentiment Analysis of Videos on YouTube, TikTok,
  and Other Sources about the 2024 Outbreak of Measles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.07693v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.07693v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nirmalya Thakur, Vanessa Su, Mingchen Shao, Kesha A. Patel, Hongseok Jeong, Victoria Knieling, Andrew Bian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The work of this paper presents a dataset that contains the data of 4011
videos about the ongoing outbreak of measles published on 264 websites on the
internet between January 1, 2024, and May 31, 2024. The dataset is available at
https://dx.doi.org/10.21227/40s8-xf63. These websites primarily include YouTube
and TikTok, which account for 48.6% and 15.2% of the videos, respectively. The
remainder of the websites include Instagram and Facebook as well as the
websites of various global and local news organizations. For each of these
videos, the URL of the video, title of the post, description of the post, and
the date of publication of the video are presented as separate attributes in
the dataset. After developing this dataset, sentiment analysis (using VADER),
subjectivity analysis (using TextBlob), and fine-grain sentiment analysis
(using DistilRoBERTa-base) of the video titles and video descriptions were
performed. This included classifying each video title and video description
into (i) one of the sentiment classes i.e. positive, negative, or neutral, (ii)
one of the subjectivity classes i.e. highly opinionated, neutral opinionated,
or least opinionated, and (iii) one of the fine-grain sentiment classes i.e.
fear, surprise, joy, sadness, anger, disgust, or neutral. These results are
presented as separate attributes in the dataset for the training and testing of
machine learning algorithms for performing sentiment analysis or subjectivity
analysis in this field as well as for other applications. Finally, this paper
also presents a list of open research questions that may be investigated using
this dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PersLLM: A Personified Training Approach for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12393v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12393v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheni Zeng, Jiayi Chen, Huimin Chen, Yukun Yan, Yuxuan Chen, Zhiyuan Liu, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models exhibit aspects of human-level intelligence that
catalyze their application as human-like agents in domains such as social
simulations, human-machine interactions, and collaborative multi-agent systems.
However, the absence of distinct personalities, such as displaying ingratiating
behaviors, inconsistent opinions, and uniform response patterns, diminish LLMs
utility in practical applications. Addressing this, the development of
personality traits in LLMs emerges as a crucial area of research to unlock
their latent potential. Existing methods to personify LLMs generally involve
strategies like employing stylized training data for instruction tuning or
using prompt engineering to simulate different personalities. These methods
only capture superficial linguistic styles instead of the core of personalities
and are therefore not stable. In this study, we propose PersLLM, integrating
psychology-grounded principles of personality: social practice, consistency,
and dynamic development, into a comprehensive training methodology. We
incorporate personality traits directly into the model parameters, enhancing
the model's resistance to induction, promoting consistency, and supporting the
dynamic evolution of personality. Single-agent evaluation validates our
method's superiority, as it produces responses more aligned with reference
personalities compared to other approaches. Case studies for multi-agent
communication highlight its benefits in enhancing opinion consistency within
individual agents and fostering collaborative creativity among multiple agents
in dialogue contexts, potentially benefiting human simulation and multi-agent
cooperation. Additionally, human-agent interaction evaluations indicate that
our personified models significantly enhance interactive experiences,
underscoring the practical implications of our research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages for main text, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Qwen2 Technical Report 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10671v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10671v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jianxin Yang, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Xuejing Liu, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zhifang Guo, Zhihao Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This report introduces the Qwen2 series, the latest addition to our large
language models and large multimodal models. We release a comprehensive suite
of foundational and instruction-tuned language models, encompassing a parameter
range from 0.5 to 72 billion, featuring dense models and a Mixture-of-Experts
model. Qwen2 surpasses most prior open-weight models, including its predecessor
Qwen1.5, and exhibits competitive performance relative to proprietary models
across diverse benchmarks on language understanding, generation, multilingual
proficiency, coding, mathematics, and reasoning.
  The flagship model, Qwen2-72B, showcases remarkable performance: 84.2 on
MMLU, 37.9 on GPQA, 64.6 on HumanEval, 89.5 on GSM8K, and 82.4 on BBH as a base
language model. The instruction-tuned variant, Qwen2-72B-Instruct, attains 9.1
on MT-Bench, 48.1 on Arena-Hard, and 35.7 on LiveCodeBench. Moreover, Qwen2
demonstrates robust multilingual capabilities, proficient in approximately 30
languages, spanning English, Chinese, Spanish, French, German, Arabic, Russian,
Korean, Japanese, Thai, Vietnamese, and more, underscoring its versatility and
global reach.
  To foster community innovation and accessibility, we have made the Qwen2
model weights openly available on Hugging Face and ModelScope, and the
supplementary materials including example code on GitHub. These platforms also
include resources for quantization, fine-tuning, and deployment, facilitating a
wide range of applications and research endeavors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and
  Visual Question Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.10005v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.10005v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kohei Uehara, Nabarun Goswami, Hanqin Wang, Toshiaki Baba, Kohtaro Tanaka, Tomohiro Hashimoto, Kai Wang, Rei Ito, Takagi Naoya, Ryo Umagami, Yingyi Wen, Tanachai Anakewat, Tatsuya Harada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing demand for intelligent systems capable of interpreting and
reasoning about visual content requires the development of large
Vision-and-Language Models (VLMs) that are not only accurate but also have
explicit reasoning capabilities. This paper presents a novel approach to
develop a VLM with the ability to conduct explicit reasoning based on visual
content and textual instructions. We introduce a system that can ask a question
to acquire necessary knowledge, thereby enhancing the robustness and
explicability of the reasoning process. To this end, we developed a novel
dataset generated by a Large Language Model (LLM), designed to promote
chain-of-thought reasoning combined with a question-asking mechanism. The
dataset covers a range of tasks, from common ones like caption generation to
specialized VQA tasks that require expert knowledge. Furthermore, using the
dataset we created, we fine-tuned an existing VLM. This training enabled the
models to generate questions and perform iterative reasoning during inference.
The results demonstrated a stride toward a more robust, accurate, and
interpretable VLM, capable of reasoning explicitly and seeking information
proactively when confronted with ambiguous visual input.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Model Enhanced Knowledge Representation Learning: A
  <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.00936v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.00936v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Wang, Zirui Chen, Haofen Wang, Leong Hou U, Zhao Li, Wenbin Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of Large Language Models (LLM) with Knowledge Representation
Learning (KRL) signifies a significant advancement in the field of artificial
intelligence (AI), enhancing the ability to capture and utilize both structure
and textual information. Despite the increasing research on enhancing KRL with
LLMs, a thorough survey that analyse processes of these enhanced models is
conspicuously absent. Our survey addresses this by categorizing these models
based on three distinct Transformer architectures, and by analyzing
experimental data from various KRL downstream tasks to evaluate the strengths
and weaknesses of each approach. Finally, we identify and explore potential
future research directions in this emerging yet underexplored domain.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PairEval: Open-domain Dialogue Evaluation with Pairwise Comparison 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.01015v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.01015v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        ChaeHun Park, Minseok Choi, Dohyun Lee, Jaegul Choo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Building a reliable and automated evaluation metric is a necessary but
challenging problem for open-domain dialogue systems. Recent studies proposed
evaluation metrics that assess generated responses by considering their
relevance to previous dialogue histories. Although effective, these metrics
evaluate individual responses directly rather than considering their relative
quality compared to other responses. To handle this, we propose PairEval, a
novel dialogue evaluation metric for assessing responses by comparing their
quality against responses in different conversations. PairEval is built on top
of open-sourced and moderate-size language models, and we make them specialized
in pairwise comparison between dialogue responses. Extensive experiments on
multiple benchmarks demonstrate that our metric exhibits a higher correlation
with human judgments than baseline metrics. We also find that the proposed
comparative metric is more robust in detecting common failures from open-domain
dialogue systems, including repetition and speaker insensitivity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>COLM2024 (accepted)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BIMCV-R: A Landmark <span class="highlight-title">Dataset</span> for 3D CT Text-Image Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.15992v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.15992v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yinda Chen, Che Liu, Xiaoyu Liu, Rossella Arcucci, Zhiwei Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The burgeoning integration of 3D medical imaging into healthcare has led to a
substantial increase in the workload of medical professionals. To assist
clinicians in their diagnostic processes and alleviate their workload, the
development of a robust system for retrieving similar case studies presents a
viable solution. While the concept holds great promise, the field of 3D medical
text-image retrieval is currently limited by the absence of robust evaluation
benchmarks and curated datasets. To remedy this, our study presents a
groundbreaking dataset, {BIMCV-R}, which includes an extensive collection of
8,069 3D CT volumes, encompassing over 2 million slices, paired with their
respective radiological reports. Expanding upon the foundational work of our
dataset, we craft a retrieval strategy, MedFinder. This approach employs a
dual-stream network architecture, harnessing the potential of large language
models to advance the field of medical image retrieval beyond existing
text-image retrieval solutions. It marks our preliminary step towards
developing a system capable of facilitating text-to-image, image-to-text, and
keyword-based retrieval tasks. Our project is available at
\url{https://huggingface.co/datasets/cyd0806/BIMCV-R}.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GroupMamba: Parameter-Efficient and Accurate Group Visual State Space
  Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13772v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13772v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abdelrahman Shaker, Syed Talal Wasim, Salman Khan, Juergen Gall, Fahad Shahbaz Khan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in state-space models (SSMs) have showcased effective
performance in modeling long-range dependencies with subquadratic complexity.
However, pure SSM-based models still face challenges related to stability and
achieving optimal performance on computer vision tasks. Our paper addresses the
challenges of scaling SSM-based models for computer vision, particularly the
instability and inefficiency of large model sizes. To address this, we
introduce a Modulated Group Mamba layer which divides the input channels into
four groups and applies our proposed SSM-based efficient Visual Single
Selective Scanning (VSSS) block independently to each group, with each VSSS
block scanning in one of the four spatial directions. The Modulated Group Mamba
layer also wraps the four VSSS blocks into a channel modulation operator to
improve cross-channel communication. Furthermore, we introduce a
distillation-based training objective to stabilize the training of large
models, leading to consistent performance gains. Our comprehensive experiments
demonstrate the merits of the proposed contributions, leading to superior
performance over existing methods for image classification on ImageNet-1K,
object detection, instance segmentation on MS-COCO, and semantic segmentation
on ADE20K. Our tiny variant with 23M parameters achieves state-of-the-art
performance with a classification top-1 accuracy of 83.3% on ImageNet-1K, while
being 26% efficient in terms of parameters, compared to the best existing Mamba
design of same model size. Our code and models are available at:
https://github.com/Amshaker/GroupMamba.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Our code and models are available at:
  https://github.com/Amshaker/GroupMamba</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Training-Free Model Merging for Multi-target Domain Adaptation <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13771v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13771v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenyi Li, Huan-ang Gao, Mingju Gao, Beiwen Tian, Rong Zhi, Hao Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study multi-target domain adaptation of scene understanding
models. While previous methods achieved commendable results through
inter-domain consistency losses, they often assumed unrealistic simultaneous
access to images from all target domains, overlooking constraints such as data
transfer bandwidth limitations and data privacy concerns. Given these
challenges, we pose the question: How to merge models adapted independently on
distinct domains while bypassing the need for direct access to training data?
Our solution to this problem involves two components, merging model parameters
and merging model buffers (i.e., normalization layer statistics). For merging
model parameters, empirical analyses of mode connectivity surprisingly reveal
that linear merging suffices when employing the same pretrained backbone
weights for adapting separate models. For merging model buffers, we model the
real-world distribution with a Gaussian prior and estimate new statistics from
the buffers of separately trained models. Our method is simple yet effective,
achieving comparable performance with data combination training baselines,
while eliminating the need for accessing training data. Project page:
https://air-discover.github.io/ModelMerging
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Addressing Imbalance for Class Incremental Learning in Medical Image
  Classification <span class="chip">ACM MM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13768v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13768v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuze Hao, Wenqian Ni, Xuhao Jiang, Weimin Tan, Bo Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep convolutional neural networks have made significant breakthroughs in
medical image classification, under the assumption that training samples from
all classes are simultaneously available. However, in real-world medical
scenarios, there's a common need to continuously learn about new diseases,
leading to the emerging field of class incremental learning (CIL) in the
medical domain. Typically, CIL suffers from catastrophic forgetting when
trained on new classes. This phenomenon is mainly caused by the imbalance
between old and new classes, and it becomes even more challenging with
imbalanced medical datasets. In this work, we introduce two simple yet
effective plug-in methods to mitigate the adverse effects of the imbalance.
First, we propose a CIL-balanced classification loss to mitigate the classifier
bias toward majority classes via logit adjustment. Second, we propose a
distribution margin loss that not only alleviates the inter-class overlap in
embedding space but also enforces the intra-class compactness. We evaluate the
effectiveness of our method with extensive experiments on three benchmark
datasets (CCH5000, HAM10000, and EyePACS). The results demonstrate that our
approach outperforms state-of-the-art methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM MM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Visual Haystacks: Answering Harder Questions About Sets of Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13766v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13766v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tsung-Han Wu, Giscard Biamby, Jerome Quenum, Ritwik Gupta, Joseph E. Gonzalez, Trevor Darrell, David M. Chan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Large Multimodal Models (LMMs) have made significant
progress in the field of single-image visual question answering. However, these
models face substantial challenges when tasked with queries that span extensive
collections of images, similar to real-world scenarios like searching through
large photo albums, finding specific information across the internet, or
monitoring environmental changes through satellite imagery. This paper explores
the task of Multi-Image Visual Question Answering (MIQA): given a large set of
images and a natural language query, the task is to generate a relevant and
grounded response. We propose a new public benchmark, dubbed "Visual Haystacks
(VHs)," specifically designed to evaluate LMMs' capabilities in visual
retrieval and reasoning over sets of unrelated images, where we perform
comprehensive evaluations demonstrating that even robust closed-source models
struggle significantly. Towards addressing these shortcomings, we introduce
MIRAGE (Multi-Image Retrieval Augmented Generation), a novel retrieval/QA
framework tailored for LMMs that confronts the challenges of MIQA with marked
efficiency and accuracy improvements over baseline methods. Our evaluation
shows that MIRAGE surpasses closed-source GPT-4o models by up to 11% on the VHs
benchmark and offers up to 3.4x improvements in efficiency over text-focused
multi-stage approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://visual-haystacks.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Shape of Motion: 4D Reconstruction from a Single Video 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13764v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13764v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qianqian Wang, Vickie Ye, Hang Gao, Jake Austin, Zhengqi Li, Angjoo Kanazawa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Monocular dynamic reconstruction is a challenging and long-standing vision
problem due to the highly ill-posed nature of the task. Existing approaches are
limited in that they either depend on templates, are effective only in
quasi-static scenes, or fail to model 3D motion explicitly. In this work, we
introduce a method capable of reconstructing generic dynamic scenes, featuring
explicit, full-sequence-long 3D motion, from casually captured monocular
videos. We tackle the under-constrained nature of the problem with two key
insights: First, we exploit the low-dimensional structure of 3D motion by
representing scene motion with a compact set of SE3 motion bases. Each point's
motion is expressed as a linear combination of these bases, facilitating soft
decomposition of the scene into multiple rigidly-moving groups. Second, we
utilize a comprehensive set of data-driven priors, including monocular depth
maps and long-range 2D tracks, and devise a method to effectively consolidate
these noisy supervisory signals, resulting in a globally consistent
representation of the dynamic scene. Experiments show that our method achieves
state-of-the-art performance for both long-range 3D/2D motion estimation and
novel view synthesis on dynamic scenes. Project Page:
https://shape-of-motion.github.io/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SegPoint: Segment Any Point Cloud via Large Language Model <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13761v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13761v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuting He, Henghui Ding, Xudong Jiang, Bihan Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite significant progress in 3D point cloud segmentation, existing methods
primarily address specific tasks and depend on explicit instructions to
identify targets, lacking the capability to infer and understand implicit user
intentions in a unified framework. In this work, we propose a model, called
SegPoint, that leverages the reasoning capabilities of a multi-modal Large
Language Model (LLM) to produce point-wise segmentation masks across a diverse
range of tasks: 1) 3D instruction segmentation, 2) 3D referring segmentation,
3) 3D semantic segmentation, and 4) 3D open-vocabulary semantic segmentation.
To advance 3D instruction research, we introduce a new benchmark, Instruct3D,
designed to evaluate segmentation performance from complex and implicit
instructional texts, featuring 2,565 point cloud-instruction pairs. Our
experimental results demonstrate that SegPoint achieves competitive performance
on established benchmarks such as ScanRefer for referring segmentation and
ScanNet for semantic segmentation, while delivering outstanding outcomes on the
Instruct3D dataset. To our knowledge, SegPoint is the first model to address
these varied segmentation tasks within a single framework, achieving
satisfactory performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024, Project Page: https://heshuting555.github.io/SegPoint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Streetscapes: Large-scale Consistent Street View Generation Using
  Autoregressive Video Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13759v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13759v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boyang Deng, Richard Tucker, Zhengqi Li, Leonidas Guibas, Noah Snavely, Gordon Wetzstein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a method for generating Streetscapes-long sequences of views
through an on-the-fly synthesized city-scale scene. Our generation is
conditioned by language input (e.g., city name, weather), as well as an
underlying map/layout hosting the desired trajectory. Compared to recent models
for video generation or 3D view synthesis, our method can scale to much
longer-range camera trajectories, spanning several city blocks, while
maintaining visual quality and consistency. To achieve this goal, we build on
recent work on video diffusion, used within an autoregressive framework that
can easily scale to long sequences. In particular, we introduce a new temporal
imputation method that prevents our autoregressive approach from drifting from
the distribution of realistic city imagery. We train our Streetscapes system on
a compelling source of data-posed imagery from Google Street View, along with
contextual map data-which allows users to generate city views conditioned on
any desired city layout, with controllable camera poses. Please see more
results at our project page at https://boyangdeng.com/streetscapes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>*Equal Contributions, Project Page:
  https://boyangdeng.com/streetscapes</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring Facial Biomarkers for Depression through Temporal Analysis of
  Action Units 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13753v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13753v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aditya Parikh, Misha Sadeghi, Bjorn Eskofier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Depression is characterized by persistent sadness and loss of interest,
significantly impairing daily functioning and now a widespread mental disorder.
Traditional diagnostic methods rely on subjective assessments, necessitating
objective approaches for accurate diagnosis. Our study investigates the use of
facial action units (AUs) and emotions as biomarkers for depression. We
analyzed facial expressions from video data of participants classified with or
without depression. Our methodology involved detailed feature extraction, mean
intensity comparisons of key AUs, and the application of time series
classification models. Furthermore, we employed Principal Component Analysis
(PCA) and various clustering algorithms to explore the variability in emotional
expression patterns. Results indicate significant differences in the
intensities of AUs associated with sadness and happiness between the groups,
highlighting the potential of facial analysis in depression assessment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LogoSticker: Inserting Logos into Diffusion Models for Customized
  Generation <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13752v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13752v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingkang Zhu, Xi Chen, Zhongdao Wang, Hengshuang Zhao, Jiaya Jia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in text-to-image model customization have underscored the
importance of integrating new concepts with a few examples. Yet, these
progresses are largely confined to widely recognized subjects, which can be
learned with relative ease through models' adequate shared prior knowledge. In
contrast, logos, characterized by unique patterns and textual elements, are
hard to establish shared knowledge within diffusion models, thus presenting a
unique challenge. To bridge this gap, we introduce the task of logo insertion.
Our goal is to insert logo identities into diffusion models and enable their
seamless synthesis in varied contexts. We present a novel two-phase pipeline
LogoSticker to tackle this task. First, we propose the actor-critic relation
pre-training algorithm, which addresses the nontrivial gaps in models'
understanding of the potential spatial positioning of logos and interactions
with other objects. Second, we propose a decoupled identity learning algorithm,
which enables precise localization and identity extraction of logos.
LogoSticker can generate logos accurately and harmoniously in diverse contexts.
We comprehensively validate the effectiveness of LogoSticker over customization
methods and large models such as DALLE~3.
\href{https://mingkangz.github.io/logosticker}{Project page}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pose-guided multi-task video <span class="highlight-title">transformer</span> for driver action recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13750v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13750v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ricardo Pizarro, Roberto Valle, Luis Miguel Bergasa, José M. Buenaposada, Luis Baumela
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate the task of identifying situations of distracted driving
through analysis of in-car videos. To tackle this challenge we introduce a
multi-task video transformer that predicts both distracted actions and driver
pose. Leveraging VideoMAEv2, a large pre-trained architecture, our approach
incorporates semantic information from human keypoint locations to enhance
action recognition and decrease computational overhead by minimizing the number
of spatio-temporal tokens. By guiding token selection with pose and class
information, we notably reduce the model's computational requirements while
preserving the baseline accuracy. Our model surpasses existing state-of-the art
results in driver action recognition while exhibiting superior efficiency
compared to current video transformer-based approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ General Geometry-aware Weakly Supervised 3D Object Detection <span class="chip">ECCV24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13748v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13748v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guowen Zhang, Junsong Fan, Liyi Chen, Zhaoxiang Zhang, Zhen Lei, Lei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D object detection is an indispensable component for scene understanding.
However, the annotation of large-scale 3D datasets requires significant human
effort. To tackle this problem, many methods adopt weakly supervised 3D object
detection that estimates 3D boxes by leveraging 2D boxes and
scene/class-specific priors. However, these approaches generally depend on
sophisticated manual priors, which is hard to generalize to novel categories
and scenes. In this paper, we are motivated to propose a general approach,
which can be easily adapted to new scenes and/or classes. A unified framework
is developed for learning 3D object detectors from RGB images and associated 2D
boxes. In specific, we propose three general components: prior injection module
to obtain general object geometric priors from LLM model, 2D space projection
constraint to minimize the discrepancy between the boundaries of projected 3D
boxes and their corresponding 2D boxes on the image plane, and 3D space
geometry constraint to build a Point-to-Box alignment loss to further refine
the pose of estimated 3D boxes. Experiments on KITTI and SUN-RGBD datasets
demonstrate that our method yields surprisingly high-quality 3D bounding boxes
with only 2D annotation. The source code is available at
https://github.com/gwenzhang/GGA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MaRINeR: Enhancing Novel Views by Matching Rendered Images with Nearby
  References <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13745v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13745v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Bösiger, Mihai Dusmanu, Marc Pollefeys, Zuria Bauer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Rendering realistic images from 3D reconstruction is an essential task of
many Computer Vision and Robotics pipelines, notably for mixed-reality
applications as well as training autonomous agents in simulated environments.
However, the quality of novel views heavily depends of the source
reconstruction which is often imperfect due to noisy or missing geometry and
appearance. Inspired by the recent success of reference-based super-resolution
networks, we propose MaRINeR, a refinement method that leverages information of
a nearby mapping image to improve the rendering of a target viewpoint. We first
establish matches between the raw rendered image of the scene geometry from the
target viewpoint and the nearby reference based on deep features, followed by
hierarchical detail transfer. We show improved renderings in quantitative
metrics and qualitative examples from both explicit and implicit scene
representations. We further employ our method on the downstream tasks of
pseudo-ground-truth validation, synthetic data enhancement and detail recovery
for renderings of reduced 3D reconstructions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024; Project Page: see
  https://boelukas.github.io/mariner/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HazeCLIP: Towards Language Guided Real-World Image Dehazing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13719v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13719v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruiyi Wang, Wenhao Li, Xiaohong Liu, Chunyi Li, Zicheng Zhang, Xiongkuo Min, Guangtao Zhai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing methods have achieved remarkable performance in single image
dehazing, particularly on synthetic datasets. However, they often struggle with
real-world hazy images due to domain shift, limiting their practical
applicability. This paper introduces HazeCLIP, a language-guided adaptation
framework designed to enhance the real-world performance of pre-trained
dehazing networks. Inspired by the Contrastive Language-Image Pre-training
(CLIP) model's ability to distinguish between hazy and clean images, we utilize
it to evaluate dehazing results. Combined with a region-specific dehazing
technique and tailored prompt sets, CLIP model accurately identifies hazy
areas, providing a high-quality, human-like prior that guides the fine-tuning
process of pre-trained networks. Extensive experiments demonstrate that
HazeCLIP achieves the state-of-the-art performance in real-word image dehazing,
evaluated through both visual quality and no-reference quality assessments. The
code is available: https://github.com/Troivyn/HazeCLIP .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Attention Based Simple Primitives for Open World Compositional Zero-Shot
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13715v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13715v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ans Munir, Faisal Z. Qureshi, Muhammad Haris Khan, Mohsen Ali
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Compositional Zero-Shot Learning (CZSL) aims to predict unknown compositions
made up of attribute and object pairs. Predicting compositions unseen during
training is a challenging task. We are exploring Open World Compositional
Zero-Shot Learning (OW-CZSL) in this study, where our test space encompasses
all potential combinations of attributes and objects. Our approach involves
utilizing the self-attention mechanism between attributes and objects to
achieve better generalization from seen to unseen compositions. Utilizing a
self-attention mechanism facilitates the model's ability to identify
relationships between attribute and objects. The similarity between the
self-attended textual and visual features is subsequently calculated to
generate predictions during the inference phase. The potential test space may
encompass implausible object-attribute combinations arising from unrestricted
attribute-object pairings. To mitigate this issue, we leverage external
knowledge from ConceptNet to restrict the test space to realistic compositions.
Our proposed model, Attention-based Simple Primitives (ASP), demonstrates
competitive performance, achieving results comparable to the state-of-the-art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are We Ready for Out-of-Distribution Detection in Digital Pathology? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13708v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13708v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ji-Hun Oh, Kianoush Falahkheirkhah, Rohit Bhargava
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The detection of semantic and covariate out-of-distribution (OOD) examples is
a critical yet overlooked challenge in digital pathology (DP). Recently,
substantial insight and methods on OOD detection were presented by the ML
community, but how do they fare in DP applications? To this end, we establish a
benchmark study, our highlights being: 1) the adoption of proper evaluation
protocols, 2) the comparison of diverse detectors in both a single and
multi-model setting, and 3) the exploration into advanced ML settings like
transfer learning (ImageNet vs. DP pre-training) and choice of architecture
(CNNs vs. transformers). Through our comprehensive experiments, we contribute
new insights and guidelines, paving the way for future research and discussion.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cross-Task Attack: A Self-Supervision Generative Framework Based on
  Attention Shift <span class="chip">IJCNN2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13700v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13700v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qingyuan Zeng, Yunpeng Gong, Min Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Studying adversarial attacks on artificial intelligence (AI) systems helps
discover model shortcomings, enabling the construction of a more robust system.
Most existing adversarial attack methods only concentrate on single-task
single-model or single-task cross-model scenarios, overlooking the multi-task
characteristic of artificial intelligence systems. As a result, most of the
existing attacks do not pose a practical threat to a comprehensive and
collaborative AI system. However, implementing cross-task attacks is highly
demanding and challenging due to the difficulty in obtaining the real labels of
different tasks for the same picture and harmonizing the loss functions across
different tasks. To address this issue, we propose a self-supervised Cross-Task
Attack framework (CTA), which utilizes co-attention and anti-attention maps to
generate cross-task adversarial perturbation. Specifically, the co-attention
map reflects the area to which different visual task models pay attention,
while the anti-attention map reflects the area that different visual task
models neglect. CTA generates cross-task perturbations by shifting the
attention area of samples away from the co-attention map and closer to the
anti-attention map. We conduct extensive experiments on multiple vision tasks
and the experimental results confirm the effectiveness of the proposed design
for adversarial attacks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Has been accepted by IJCNN2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Shaded Route Planning Using Active Segmentation and Identification of
  Satellite Images <span class="chip">CIKM24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13689v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13689v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Longchao Da, Rohan Chhibba, Rushabh Jaiswal, Ariane Middel, Hua Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Heatwaves pose significant health risks, particularly due to prolonged
exposure to high summer temperatures. Vulnerable groups, especially pedestrians
and cyclists on sun-exposed sidewalks, motivate the development of a route
planning method that incorporates somatosensory temperature effects through
shade ratio consideration. This paper is the first to introduce a pipeline that
utilizes segmentation foundation models to extract shaded areas from
high-resolution satellite images. These areas are then integrated into a
multi-layered road map, enabling users to customize routes based on a balance
between distance and shade exposure, thereby enhancing comfort and health
during outdoor activities. Specifically, we construct a graph-based
representation of the road map, where links indicate connectivity and are
updated with shade ratio data for dynamic route planning. This system is
already implemented online, with a video demonstration, and will be
specifically adapted to assist travelers during the 2024 Olympic Games in
Paris.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper accepted to CIKM24 demo track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HPix: Generating Vector Maps from Satellite Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13680v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13680v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aditya Taparia, Keshab Nath
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vector maps find widespread utility across diverse domains due to their
capacity to not only store but also represent discrete data boundaries such as
building footprints, disaster impact analysis, digitization, urban planning,
location points, transport links, and more. Although extensive research exists
on identifying building footprints and road types from satellite imagery, the
generation of vector maps from such imagery remains an area with limited
exploration. Furthermore, conventional map generation techniques rely on
labor-intensive manual feature extraction or rule-based approaches, which
impose inherent limitations. To surmount these limitations, we propose a novel
method called HPix, which utilizes modified Generative Adversarial Networks
(GANs) to generate vector tile map from satellite images. HPix incorporates two
hierarchical frameworks: one operating at the global level and the other at the
local level, resulting in a comprehensive model. Through empirical evaluations,
our proposed approach showcases its effectiveness in producing highly accurate
and visually captivating vector tile maps derived from satellite images. We
further extend our study's application to include mapping of road intersections
and building footprints cluster based on their area.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PASTA: Controllable Part-Aware Shape Generation with Autoregressive
  <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13677v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13677v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Songlin Li, Despoina Paschalidou, Leonidas Guibas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increased demand for tools that automate the 3D content creation process
led to tremendous progress in deep generative models that can generate diverse
3D objects of high fidelity. In this paper, we present PASTA, an autoregressive
transformer architecture for generating high quality 3D shapes. PASTA comprises
two main components: An autoregressive transformer that generates objects as a
sequence of cuboidal primitives and a blending network, implemented with a
transformer decoder that composes the sequences of cuboids and synthesizes high
quality meshes for each object. Our model is trained in two stages: First we
train our autoregressive generative model using only annotated cuboidal parts
as supervision and next, we train our blending network using explicit 3D
supervision, in the form of watertight meshes. Evaluations on various ShapeNet
objects showcase the ability of our model to perform shape generation from
diverse inputs \eg from scratch, from a partial object, from text and images,
as well size-guided generation, by explicitly conditioning on a bounding box
that defines the object's boundaries. Moreover, as our model considers the
underlying part-based structure of a 3D object, we are able to select a
specific part and produce shapes with meaningful variations of this part. As
evidenced by our experiments, our model generates 3D shapes that are both more
realistic and diverse than existing part-based and non part-based methods,
while at the same time is simpler to implement and train.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Aligning Sight and Sound: Advanced Sound Source Localization Through
  Audio-Visual Alignment <span class="chip">ICCV 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13676v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13676v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arda Senocak, Hyeonggon Ryu, Junsik Kim, Tae-Hyun Oh, Hanspeter Pfister, Joon Son Chung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies on learning-based sound source localization have mainly
focused on the localization performance perspective. However, prior work and
existing benchmarks overlook a crucial aspect: cross-modal interaction, which
is essential for interactive sound source localization. Cross-modal interaction
is vital for understanding semantically matched or mismatched audio-visual
events, such as silent objects or off-screen sounds. In this paper, we first
comprehensively examine the cross-modal interaction of existing methods,
benchmarks, evaluation metrics, and cross-modal understanding tasks. Then, we
identify the limitations of previous studies and make several contributions to
overcome the limitations. First, we introduce a new synthetic benchmark for
interactive sound source localization. Second, we introduce new evaluation
metrics to rigorously assess sound source localization methods, focusing on
accurately evaluating both localization performance and cross-modal interaction
ability. Third, we propose a learning framework with a cross-modal alignment
strategy to enhance cross-modal interaction. Lastly, we evaluate both
interactive sound source localization and auxiliary cross-modal retrieval tasks
together to thoroughly assess cross-modal interaction capabilities and
benchmark competing methods. Our new benchmarks and evaluation metrics reveal
previously overlooked issues in sound source localization studies. Our proposed
novel method, with enhanced cross-modal alignment, shows superior sound source
localization performance. This work provides the most comprehensive analysis of
sound source localization to date, with extensive validation of competing
methods on both existing and new benchmarks using new and standard evaluation
metrics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Journal Extension of ICCV 2023 paper (arXiV:2309.10724). Code is
  available at https://github.com/kaistmm/SSLalignment</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MeshSegmenter: Zero-Shot Mesh Semantic Segmentation via Texture
  Synthesis <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13675v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13675v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziming Zhong, Yanxu Xu, Jing Li, Jiale Xu, Zhengxin Li, Chaohui Yu, Shenghua Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present MeshSegmenter, a simple yet effective framework designed for
zero-shot 3D semantic segmentation. This model successfully extends the
powerful capabilities of 2D segmentation models to 3D meshes, delivering
accurate 3D segmentation across diverse meshes and segment descriptions.
Specifically, our model leverages the Segment Anything Model (SAM) model to
segment the target regions from images rendered from the 3D shape. In light of
the importance of the texture for segmentation, we also leverage the pretrained
stable diffusion model to generate images with textures from 3D shape, and
leverage SAM to segment the target regions from images with textures. Textures
supplement the shape for segmentation and facilitate accurate 3D segmentation
even in geometrically non-prominent areas, such as segmenting a car door within
a car mesh. To achieve the 3D segments, we render 2D images from different
views and conduct segmentation for both textured and untextured images. Lastly,
we develop a multi-view revoting scheme that integrates 2D segmentation results
and confidence scores from various views onto the 3D mesh, ensuring the 3D
consistency of segmentation results and eliminating inaccuracies from specific
perspectives. Through these innovations, MeshSegmenter offers stable and
reliable 3D segmentation results both quantitatively and qualitatively,
highlighting its potential as a transformative tool in the field of 3D
zero-shot segmentation. The code is available at
\url{https://github.com/zimingzhong/MeshSegmenter}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The paper was accepted by ECCV2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Dropout: Robust Convolutional Neural Networks Based on Local
  Feature Masking <span class="chip">IJCNN 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13646v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13646v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunpeng Gong, Chuangliang Zhang, Yongjie Hou, Lifei Chen, Min Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the contemporary of deep learning, where models often grapple with the
challenge of simultaneously achieving robustness against adversarial attacks
and strong generalization capabilities, this study introduces an innovative
Local Feature Masking (LFM) strategy aimed at fortifying the performance of
Convolutional Neural Networks (CNNs) on both fronts. During the training phase,
we strategically incorporate random feature masking in the shallow layers of
CNNs, effectively alleviating overfitting issues, thereby enhancing the model's
generalization ability and bolstering its resilience to adversarial attacks.
LFM compels the network to adapt by leveraging remaining features to compensate
for the absence of certain semantic features, nurturing a more elastic feature
learning mechanism. The efficacy of LFM is substantiated through a series of
quantitative and qualitative assessments, collectively showcasing a consistent
and significant improvement in CNN's generalization ability and resistance
against adversarial attacks--a phenomenon not observed in current and prior
methodologies. The seamless integration of LFM into established CNN frameworks
underscores its potential to advance both generalization and adversarial
robustness within the deep learning paradigm. Through comprehensive
experiments, including robust person re-identification baseline generalization
experiments and adversarial attack experiments, we demonstrate the substantial
enhancements offered by LFM in addressing the aforementioned challenges. This
contribution represents a noteworthy stride in advancing robust neural network
architectures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>It has been accepted by IJCNN 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Open-Vocabulary 3D Semantic Segmentation with Text-to-Image Diffusion
  Models <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13642v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13642v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyu Zhu, Hao Zhou, Pengfei Xing, Long Zhao, Hao Xu, Junwei Liang, Alexander Hauptmann, Ting Liu, Andrew Gallagher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we investigate the use of diffusion models which are
pre-trained on large-scale image-caption pairs for open-vocabulary 3D semantic
understanding. We propose a novel method, namely Diff2Scene, which leverages
frozen representations from text-image generative models, along with
salient-aware and geometric-aware masks, for open-vocabulary 3D semantic
segmentation and visual grounding tasks. Diff2Scene gets rid of any labeled 3D
data and effectively identifies objects, appearances, materials, locations and
their compositions in 3D scenes. We show that it outperforms competitive
baselines and achieves significant improvements over state-of-the-art methods.
In particular, Diff2Scene improves the state-of-the-art method on ScanNet200 by
12%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Augmentation: Empowering Model Robustness under Extreme Capture
  Environments <span class="chip">IJCNN 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13640v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13640v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunpeng Gong, Yongjie Hou, Chuangliang Zhang, Min Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Person Re-identification (re-ID) in computer vision aims to recognize and
track individuals across different cameras. While previous research has mainly
focused on challenges like pose variations and lighting changes, the impact of
extreme capture conditions is often not adequately addressed. These extreme
conditions, including varied lighting, camera styles, angles, and image
distortions, can significantly affect data distribution and re-ID accuracy.
  Current research typically improves model generalization under normal
shooting conditions through data augmentation techniques such as adjusting
brightness and contrast. However, these methods pay less attention to the
robustness of models under extreme shooting conditions. To tackle this, we
propose a multi-mode synchronization learning (MMSL) strategy . This approach
involves dividing images into grids, randomly selecting grid blocks, and
applying data augmentation methods like contrast and brightness adjustments.
This process introduces diverse transformations without altering the original
image structure, helping the model adapt to extreme variations. This method
improves the model's generalization under extreme conditions and enables
learning diverse features, thus better addressing the challenges in re-ID.
Extensive experiments on a simulated test set under extreme conditions have
demonstrated the effectiveness of our method. This approach is crucial for
enhancing model robustness and adaptability in real-world scenarios, supporting
the future development of person re-identification technology.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>It has been accepted by IJCNN 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data Alchemy: Mitigating Cross-Site Model Variability Through Test Time
  Data Calibration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13632v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13632v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abhijeet Parida, Antonia Alomar, Zhifan Jiang, Pooneh Roshanitabrizi, Austin Tapp, Maria Ledesma-Carbayo, Ziyue Xu, Syed Muhammed Anwar, Marius George Linguraru, Holger R. Roth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deploying deep learning-based imaging tools across various clinical sites
poses significant challenges due to inherent domain shifts and regulatory
hurdles associated with site-specific fine-tuning. For histopathology, stain
normalization techniques can mitigate discrepancies, but they often fall short
of eliminating inter-site variations. Therefore, we present Data Alchemy, an
explainable stain normalization method combined with test time data calibration
via a template learning framework to overcome barriers in cross-site analysis.
Data Alchemy handles shifts inherent to multi-site data and minimizes them
without needing to change the weights of the normalization or classifier
networks. Our approach extends to unseen sites in various clinical settings
where data domain discrepancies are unknown. Extensive experiments highlight
the efficacy of our framework in tumor classification in hematoxylin and
eosin-stained patches. Our explainable normalization method boosts
classification tasks' area under the precision-recall curve(AUPR) by 0.165,
0.545 to 0.710. Additionally, Data Alchemy further reduces the multisite
classification domain gap, by improving the 0.710 AUPR an additional 0.142,
elevating classification performance further to 0.852, from 0.545. Our Data
Alchemy framework can popularize precision medicine with minimal operational
overhead by allowing for the seamless integration of pre-trained deep
learning-based clinical tools across multiple sites.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted to Machine Learning in Medical Imaging (MLMI 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Training-free Composite Scene Generation for Layout-to-Image Synthesis <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13609v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13609v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaqi Liu, Tao Huang, Chang Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent breakthroughs in text-to-image diffusion models have significantly
advanced the generation of high-fidelity, photo-realistic images from textual
descriptions. Yet, these models often struggle with interpreting spatial
arrangements from text, hindering their ability to produce images with precise
spatial configurations. To bridge this gap, layout-to-image generation has
emerged as a promising direction. However, training-based approaches are
limited by the need for extensively annotated datasets, leading to high data
acquisition costs and a constrained conceptual scope. Conversely, training-free
methods face challenges in accurately locating and generating semantically
similar objects within complex compositions. This paper introduces a novel
training-free approach designed to overcome adversarial semantic intersections
during the diffusion conditioning phase. By refining intra-token loss with
selective sampling and enhancing the diffusion process with attention
redistribution, we propose two innovative constraints: 1) an inter-token
constraint that resolves token conflicts to ensure accurate concept synthesis;
and 2) a self-attention constraint that improves pixel-to-pixel relationships.
Our evaluations confirm the effectiveness of leveraging layout information for
guiding the diffusion process, generating content-rich images with enhanced
fidelity and complexity. Code is available at
https://github.com/Papple-F/csg.git.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EarthMarker: A Visual <span class="highlight-title">Prompt</span> Learning Framework for Region-level and
  Point-level Remote Sensing Imagery Comprehension 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13596v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13596v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Zhang, Miaoxin Cai, Tong Zhang, Yin Zhuang, Xuerui Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in visual prompting in the natural image area have allowed
users to interact with artificial intelligence (AI) tools through various
visual marks such as box, point, and free-form shapes. However, due to the
significant difference between the natural and remote sensing (RS) images,
existing visual prompting models face challenges in RS scenarios. Moreover, RS
MLLMs mainly focus on interpreting image-level RS data and only support
interaction with language instruction, restricting flexibility applications in
the real world. To address those limitations, a novel visual prompting model
named EarthMarker is proposed, which excels in image-level, region-level, and
point-level RS imagery interpretation. Specifically, the visual prompts
alongside images and text instruction input into the large language model
(LLM), adapt models toward specific predictions and tasks. Subsequently, a
sharing visual encoding method is introduced to refine multi-scale image
features and visual prompt information uniformly. Furthermore, to endow the
EarthMarker with versatile multi-granularity visual perception abilities, the
cross-domain phased learning strategy is developed, and the disjoint parameters
are optimized in a lightweight manner by leveraging both the natural and RS
domain-specific knowledge. In addition, to tackle the lack of RS visual
prompting data, a dataset named RSVP featuring multi-modal fine-grained visual
prompting instruction is constructed. Extensive experiments are conducted to
demonstrate the proposed EarthMarker's competitive performance, representing a
significant advance in multi-granularity RS imagery interpretation under the
visual prompting learning framework.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MeshFeat: Multi-Resolution Features for Neural Fields on Meshes <span class="chip">ECCV</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13592v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13592v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mihir Mahajan, Florian Hofherr, Daniel Cremers
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parametric feature grid encodings have gained significant attention as an
encoding approach for neural fields since they allow for much smaller MLPs,
which significantly decreases the inference time of the models. In this work,
we propose MeshFeat, a parametric feature encoding tailored to meshes, for
which we adapt the idea of multi-resolution feature grids from Euclidean space.
We start from the structure provided by the given vertex topology and use a
mesh simplification algorithm to construct a multi-resolution feature
representation directly on the mesh. The approach allows the usage of small
MLPs for neural fields on meshes, and we show a significant speed-up compared
to previous representations while maintaining comparable reconstruction quality
for texture reconstruction and BRDF representation. Given its intrinsic
coupling to the vertices, the method is particularly well-suited for
representations on deforming meshes, making it a good fit for object animation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at European Conference on Computer Vision (ECCV), 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Calibration of Large Vision-Language Adapters <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13588v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13588v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Balamurali Murugesan, Julio Silva-Rodriguez, Ismail Ben Ayed, Jose Dolz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the critical issue of miscalibration in CLIP-based model
adaptation, particularly in the challenging scenario of out-of-distribution
(OOD) samples, which has been overlooked in the existing literature on CLIP
adaptation. We empirically demonstrate that popular CLIP adaptation approaches,
such as Adapters, Prompt Learning, and Test-Time Adaptation, substantially
degrade the calibration capabilities of the zero-shot baseline in the presence
of distributional drift. We identify the increase in logit ranges as the
underlying cause of miscalibration of CLIP adaptation methods, contrasting with
previous work on calibrating fully-supervised models. Motivated by these
observations, we present a simple and model-agnostic solution to mitigate
miscalibration, by scaling the logit range of each sample to its zero-shot
prediction logits. We explore three different alternatives to achieve this,
which can be either integrated during adaptation or directly used at inference
time. Comprehensive experiments on popular OOD classification benchmarks
demonstrate the effectiveness of the proposed approaches in mitigating
miscalibration while maintaining discriminative performance, whose improvements
are consistent across the three families of these increasingly popular
approaches. The code is publicly available at:
https://github.com/Bala93/CLIPCalib
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Connecting Consistency Distillation to Score Distillation for Text-to-3D
  Generation <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13584v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13584v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zongrui Li, Minghui Hu, Qian Zheng, Xudong Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although recent advancements in text-to-3D generation have significantly
improved generation quality, issues like limited level of detail and low
fidelity still persist, which requires further improvement. To understand the
essence of those issues, we thoroughly analyze current score distillation
methods by connecting theories of consistency distillation to score
distillation. Based on the insights acquired through analysis, we propose an
optimization framework, Guided Consistency Sampling (GCS), integrated with 3D
Gaussian Splatting (3DGS) to alleviate those issues. Additionally, we have
observed the persistent oversaturation in the rendered views of generated 3D
assets. From experiments, we find that it is caused by unwanted accumulated
brightness in 3DGS during optimization. To mitigate this issue, we introduce a
Brightness-Equalized Generation (BEG) scheme in 3DGS rendering. Experimental
results demonstrate that our approach generates 3D assets with more details and
higher fidelity than state-of-the-art methods. The codes are released at
https://github.com/LMozart/ECCV2024-GCS-BEG.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper accepted by ECCV2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ New Capability to Look Up an ASL Sign from a Video Example 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13571v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13571v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Carol Neidle, Augustine Opoku, Carey Ballard, Yang Zhou, Xiaoxiao He, Gregory Dimitriadis, Dimitris Metaxas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Looking up an unknown sign in an ASL dictionary can be difficult. Most ASL
dictionaries are organized based on English glosses, despite the fact that (1)
there is no convention for assigning English-based glosses to ASL signs; and
(2) there is no 1-1 correspondence between ASL signs and English words.
Furthermore, what if the user does not know either the meaning of the target
sign or its possible English translation(s)? Some ASL dictionaries enable
searching through specification of articulatory properties, such as handshapes,
locations, movement properties, etc. However, this is a cumbersome process and
does not always result in successful lookup. Here we describe a new system,
publicly shared on the Web, to enable lookup of a video of an ASL sign (e.g., a
webcam recording or a clip from a continuous signing video). The user submits a
video for analysis and is presented with the five most likely sign matches, in
decreasing order of likelihood, so that the user can confirm the selection and
then be taken to our ASLLRP Sign Bank entry for that sign. Furthermore, this
video lookup is also integrated into our newest version of SignStream(R)
software to facilitate linguistic annotation of ASL video data, enabling the
user to directly look up a sign in the video being annotated, and, upon
confirmation of the match, to directly enter into the annotation the gloss and
features of that sign, greatly increasing the efficiency and consistency of
linguistic annotations of ASL video data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hyp2Nav: Hyperbolic Planning and Curiosity for Crowd Navigation <span class="chip">IROS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13567v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13567v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alessandro Flaborea, Guido Maria D'Amely di Melendugno, Pascal Mettes, Fabio Galasso
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous robots are increasingly becoming a strong fixture in social
environments. Effective crowd navigation requires not only safe yet fast
planning, but should also enable interpretability and computational efficiency
for working in real-time on embedded devices. In this work, we advocate for
hyperbolic learning to enable crowd navigation and we introduce Hyp2Nav.
Different from conventional reinforcement learning-based crowd navigation
methods, Hyp2Nav leverages the intrinsic properties of hyperbolic geometry to
better encode the hierarchical nature of decision-making processes in
navigation tasks. We propose a hyperbolic policy model and a hyperbolic
curiosity module that results in effective social navigation, best success
rates, and returns across multiple simulation settings, using up to 6 times
fewer parameters than competitor state-of-the-art models. With our approach, it
becomes even possible to obtain policies that work in 2-dimensional embedding
spaces, opening up new possibilities for low-resource crowd navigation and
model interpretability. Insightfully, the internal hyperbolic representation of
Hyp2Nav correlates with how much attention the robot pays to the surrounding
crowds, e.g. due to multiple people occluding its pathway or to a few of them
showing colliding plans, rather than to its own planned route.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at IROS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Qalam : A Multimodal LLM for Arabic Optical Character and Handwriting
  Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13559v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13559v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gagan Bhatia, El Moatez Billah Nagoudi, Fakhraddin Alwajih, Muhammad Abdul-Mageed
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Arabic Optical Character Recognition (OCR) and Handwriting Recognition (HWR)
pose unique challenges due to the cursive and context-sensitive nature of the
Arabic script. This study introduces Qalam, a novel foundation model designed
for Arabic OCR and HWR, built on a SwinV2 encoder and RoBERTa decoder
architecture. Our model significantly outperforms existing methods, achieving a
Word Error Rate (WER) of just 0.80% in HWR tasks and 1.18% in OCR tasks. We
train Qalam on a diverse dataset, including over 4.5 million images from Arabic
manuscripts and a synthetic dataset comprising 60k image-text pairs. Notably,
Qalam demonstrates exceptional handling of Arabic diacritics, a critical
feature in Arabic scripts. Furthermore, it shows a remarkable ability to
process high-resolution inputs, addressing a common limitation in current OCR
systems. These advancements underscore Qalam's potential as a leading solution
for Arabic script recognition, offering a significant leap in accuracy and
efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PetFace: A Large-Scale <span class="highlight-title">Dataset</span> and Benchmark for Animal Identification <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13555v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13555v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Risa Shinoda, Kaede Shiohara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automated animal face identification plays a crucial role in the monitoring
of behaviors, conducting of surveys, and finding of lost animals. Despite the
advancements in human face identification, the lack of datasets and benchmarks
in the animal domain has impeded progress. In this paper, we introduce the
PetFace dataset, a comprehensive resource for animal face identification
encompassing 257,484 unique individuals across 13 animal families and 319 breed
categories, including both experimental and pet animals. This large-scale
collection of individuals facilitates the investigation of unseen animal face
verification, an area that has not been sufficiently explored in existing
datasets due to the limited number of individuals. Moreover, PetFace also has
fine-grained annotations such as sex, breed, color, and pattern. We provide
multiple benchmarks including re-identification for seen individuals and
verification for unseen individuals. The models trained on our dataset
outperform those trained on prior datasets, even for detailed breed variations
and unseen animal families. Our result also indicates that there is some room
to improve the performance of integrated identification on multiple animal
families. We hope the PetFace dataset will facilitate animal face
identification and encourage the development of non-invasive animal automatic
identification methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024. Dataset and code: https://dahlian00.github.io/PetFacePage/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SAM-Driven Weakly Supervised Nodule Segmentation with Uncertainty-Aware
  Cross Teaching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13553v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13553v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingyue Zhao, Peiqi Li, Xiangde Luo, Meng Yang, Shi Chang, Zhongyu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automated nodule segmentation is essential for computer-assisted diagnosis in
ultrasound images. Nevertheless, most existing methods depend on precise
pixel-level annotations by medical professionals, a process that is both costly
and labor-intensive. Recently, segmentation foundation models like SAM have
shown impressive generalizability on natural images, suggesting their potential
as pseudo-labelers. However, accurate prompts remain crucial for their success
in medical images. In this work, we devise a novel weakly supervised framework
that effectively utilizes the segmentation foundation model to generate
pseudo-labels from aspect ration annotations for automatic nodule segmentation.
Specifically, we develop three types of bounding box prompts based on scalable
shape priors, followed by an adaptive pseudo-label selection module to fully
exploit the prediction capabilities of the foundation model for nodules. We
also present a SAM-driven uncertainty-aware cross-teaching strategy. This
approach integrates SAM-based uncertainty estimation and label-space
perturbations into cross-teaching to mitigate the impact of pseudo-label
inaccuracies on model training. Extensive experiments on two clinically
collected ultrasound datasets demonstrate the superior performance of our
proposed method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ISBI 2024 Oral</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiffuX2CT: Diffusion Learning to Reconstruct CT Images from Biplanar
  X-Rays 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13545v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13545v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuhui Liu, Zhi Qiao, Runkun Liu, Hong Li, Juan Zhang, Xiantong Zhen, Zhen Qian, Baochang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computed tomography (CT) is widely utilized in clinical settings because it
delivers detailed 3D images of the human body. However, performing CT scans is
not always feasible due to radiation exposure and limitations in certain
surgical environments. As an alternative, reconstructing CT images from
ultra-sparse X-rays offers a valuable solution and has gained significant
interest in scientific research and medical applications. However, it presents
great challenges as it is inherently an ill-posed problem, often compromised by
artifacts resulting from overlapping structures in X-ray images. In this paper,
we propose DiffuX2CT, which models CT reconstruction from orthogonal biplanar
X-rays as a conditional diffusion process. DiffuX2CT is established with a 3D
global coherence denoising model with a new, implicit conditioning mechanism.
We realize the conditioning mechanism by a newly designed tri-plane decoupling
generator and an implicit neural decoder. By doing so, DiffuX2CT achieves
structure-controllable reconstruction, which enables 3D structural information
to be recovered from 2D X-rays, therefore producing faithful textures in CT
images. As an extra contribution, we collect a real-world lumbar CT dataset,
called LumbarV, as a new benchmark to verify the clinical significance and
performance of CT reconstruction from X-rays. Extensive experiments on this
dataset and three more publicly available datasets demonstrate the
effectiveness of our proposal.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Discriminability of <span class="highlight-title">Self-Supervised</span> Representation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13541v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13541v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeen Song, Wenwen Qiang, Changwen Zheng, Fuchun Sun, Hui Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervised learning (SSL) has recently achieved significant success in
downstream visual tasks. However, a notable gap still exists between SSL and
supervised learning (SL), especially in complex downstream tasks. In this
paper, we show that the features learned by SSL methods suffer from the
crowding problem, where features of different classes are not distinctly
separated, and features within the same class exhibit large intra-class
variance. In contrast, SL ensures a clear separation between classes. We
analyze this phenomenon and conclude that SSL objectives do not constrain the
relationships between different samples and their augmentations. Our
theoretical analysis delves into how SSL objectives fail to enforce the
necessary constraints between samples and their augmentations, leading to poor
performance in complex tasks. We provide a theoretical framework showing that
the performance gap between SSL and SL mainly stems from the inability of SSL
methods to capture the aggregation of similar augmentations and the separation
of dissimilar augmentations. To address this issue, we propose a learnable
regulator called Dynamic Semantic Adjuster (DSA). DSA aggregates and separates
samples in the feature space while being robust to outliers. Through extensive
empirical evaluations on multiple benchmark datasets, we demonstrate the
superiority of DSA in enhancing feature aggregation and separation, ultimately
closing the performance gap between SSL and SL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GlobalPointer: Large-Scale Plane Adjustment with Bi-Convex Relaxation <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13537v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13537v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bangyan Liao, Zhenjun Zhao, Lu Chen, Haoang Li, Daniel Cremers, Peidong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Plane adjustment (PA) is crucial for many 3D applications, involving
simultaneous pose estimation and plane recovery. Despite recent advancements,
it remains a challenging problem in the realm of multi-view point cloud
registration. Current state-of-the-art methods can achieve globally optimal
convergence only with good initialization. Furthermore, their high time
complexity renders them impractical for large-scale problems. To address these
challenges, we first exploit a novel optimization strategy termed
\textit{Bi-Convex Relaxation}, which decouples the original problem into two
simpler sub-problems, reformulates each sub-problem using a convex relaxation
technique, and alternately solves each one until the original problem
converges. Building on this strategy, we propose two algorithmic variants for
solving the plane adjustment problem, namely \textit{GlobalPointer} and
\textit{GlobalPointer++}, based on point-to-plane and plane-to-plane errors,
respectively. Extensive experiments on both synthetic and real datasets
demonstrate that our method can perform large-scale plane adjustment with
linear time complexity, larger convergence region, and robustness to poor
initialization, while achieving similar accuracy as prior methods. The code is
available at
\href{https://github.com/wu-cvgl/GlobalPointer}{github.com/wu-cvgl/GlobalPointer}
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024. The first two authors contributed equally to
  this work. Code: https://github.com/wu-cvgl/GlobalPointer</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Source-Free Domain Adaptive Object Detection with
  Low-confidence Pseudo Label Distillation <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13524v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13524v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ilhoon Yoon, Hyeongjun Kwon, Jin Kim, Junyoung Park, Hyunsung Jang, Kwanghoon Sohn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Source-Free domain adaptive Object Detection (SFOD) is a promising strategy
for deploying trained detectors to new, unlabeled domains without accessing
source data, addressing significant concerns around data privacy and
efficiency. Most SFOD methods leverage a Mean-Teacher (MT) self-training
paradigm relying heavily on High-confidence Pseudo Labels (HPL). However, these
HPL often overlook small instances that undergo significant appearance changes
with domain shifts. Additionally, HPL ignore instances with low confidence due
to the scarcity of training samples, resulting in biased adaptation toward
familiar instances from the source domain. To address this limitation, we
introduce the Low-confidence Pseudo Label Distillation (LPLD) loss within the
Mean-Teacher based SFOD framework. This novel approach is designed to leverage
the proposals from Region Proposal Network (RPN), which potentially encompasses
hard-to-detect objects in unfamiliar domains. Initially, we extract HPL using a
standard pseudo-labeling technique and mine a set of Low-confidence Pseudo
Labels (LPL) from proposals generated by RPN, leaving those that do not overlap
significantly with HPL. These LPL are further refined by leveraging
class-relation information and reducing the effect of inherent noise for the
LPLD loss calculation. Furthermore, we use feature distance to adaptively
weight the LPLD loss to focus on LPL containing a larger foreground area. Our
method outperforms previous SFOD methods on four cross-domain object detection
benchmarks. Extensive experiments demonstrate that our LPLD loss leads to
effective adaptation by reducing false negatives and facilitating the use of
domain-invariant knowledge from the source model. Code is available at
https://github.com/junia3/LPLD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EaDeblur-GS: Event assisted 3D Deblur Reconstruction with Gaussian
  Splatting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13520v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13520v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuchen Weng, Zhengwen Shen, Ruofan Chen, Qi Wang, Jun Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D deblurring reconstruction techniques have recently seen significant
advancements with the development of Neural Radiance Fields (NeRF) and 3D
Gaussian Splatting (3DGS). Although these techniques can recover relatively
clear 3D reconstructions from blurry image inputs, they still face limitations
in handling severe blurring and complex camera motion. To address these issues,
we propose Event-assisted 3D Deblur Reconstruction with Gaussian Splatting
(EaDeblur-GS), which integrates event camera data to enhance the robustness of
3DGS against motion blur. By employing an Adaptive Deviation Estimator (ADE)
network to estimate Gaussian center deviations and using novel loss functions,
EaDeblur-GS achieves sharp 3D reconstructions in real-time, demonstrating
performance comparable to state-of-the-art methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GPSFormer: A Global Perception and Local Structure Fitting-based
  <span class="highlight-title">Transformer</span> for Point Cloud Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13519v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13519v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Changshuo Wang, Meiqing Wu, Siew-Kei Lam, Xin Ning, Shangshu Yu, Ruiping Wang, Weijun Li, Thambipillai Srikanthan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the significant advancements in pre-training methods for point cloud
understanding, directly capturing intricate shape information from irregular
point clouds without reliance on external data remains a formidable challenge.
To address this problem, we propose GPSFormer, an innovative Global Perception
and Local Structure Fitting-based Transformer, which learns detailed shape
information from point clouds with remarkable precision. The core of GPSFormer
is the Global Perception Module (GPM) and the Local Structure Fitting
Convolution (LSFConv). Specifically, GPM utilizes Adaptive Deformable Graph
Convolution (ADGConv) to identify short-range dependencies among similar
features in the feature space and employs Multi-Head Attention (MHA) to learn
long-range dependencies across all positions within the feature space,
ultimately enabling flexible learning of contextual representations. Inspired
by Taylor series, we design LSFConv, which learns both low-order fundamental
and high-order refinement information from explicitly encoded local geometric
structures. Integrating the GPM and LSFConv as fundamental components, we
construct GPSFormer, a cutting-edge Transformer that effectively captures
global and local structures of point clouds. Extensive experiments validate
GPSFormer's effectiveness in three point cloud tasks: shape classification,
part segmentation, and few-shot learning. The code of GPSFormer is available at
\url{https://github.com/changshuowang/GPSFormer}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mask2Map: Vectorized HD Map Construction Using Bird's Eye View
  Segmentation Masks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13517v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13517v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sehwan Choi, Jungho Kim, Hongjae Shin, Jun Won Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce Mask2Map, a novel end-to-end online HD map
construction method designed for autonomous driving applications. Our approach
focuses on predicting the class and ordered point set of map instances within a
scene, represented in the bird's eye view (BEV). Mask2Map consists of two
primary components: the Instance-Level Mask Prediction Network (IMPNet) and the
Mask-Driven Map Prediction Network (MMPNet). IMPNet generates Mask-Aware
Queries and BEV Segmentation Masks to capture comprehensive semantic
information globally. Subsequently, MMPNet enhances these query features using
local contextual information through two submodules: the Positional Query
Generator (PQG) and the Geometric Feature Extractor (GFE). PQG extracts
instance-level positional queries by embedding BEV positional information into
Mask-Aware Queries, while GFE utilizes BEV Segmentation Masks to generate
point-level geometric features. However, we observed limited performance in
Mask2Map due to inter-network inconsistency stemming from different predictions
to Ground Truth (GT) matching between IMPNet and MMPNet. To tackle this
challenge, we propose the Inter-network Denoising Training method, which guides
the model to denoise the output affected by both noisy GT queries and perturbed
GT Segmentation Masks. Our evaluation conducted on nuScenes and Argoverse2
benchmarks demonstrates that Mask2Map achieves remarkable performance
improvements over previous state-of-the-art methods, with gains of 10.1% mAP
and 4.1 mAP, respectively. Our code can be found at
https://github.com/SehwanChoi0307/Mask2Map.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FADE: A Task-Agnostic Upsampling Operator for Encoder-Decoder
  Architectures <span class="chip">ECCV 2022</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13500v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13500v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Lu, Wenze Liu, Hongtao Fu, Zhiguo Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The goal of this work is to develop a task-agnostic feature upsampling
operator for dense prediction where the operator is required to facilitate not
only region-sensitive tasks like semantic segmentation but also
detail-sensitive tasks such as image matting. Prior upsampling operators often
can work well in either type of the tasks, but not both. We argue that
task-agnostic upsampling should dynamically trade off between semantic
preservation and detail delineation, instead of having a bias between the two
properties. In this paper, we present FADE, a novel, plug-and-play,
lightweight, and task-agnostic upsampling operator by fusing the assets of
decoder and encoder features at three levels: i) considering both the encoder
and decoder feature in upsampling kernel generation; ii) controlling the
per-point contribution of the encoder/decoder feature in upsampling kernels
with an efficient semi-shift convolutional operator; and iii) enabling the
selective pass of encoder features with a decoder-dependent gating mechanism
for compensating details. To improve the practicality of FADE, we additionally
study parameter- and memory-efficient implementations of semi-shift
convolution. We analyze the upsampling behavior of FADE on toy data and show
through large-scale experiments that FADE is task-agnostic with consistent
performance improvement on a number of dense prediction tasks with little extra
cost. For the first time, we demonstrate robust feature upsampling on both
region- and detail-sensitive tasks successfully. Code is made available at:
https://github.com/poppinace/fade
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to International Journal of Computer Vision. Extended
  version of ECCV 2022 paper at arXiv:2207.10392</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Similarity over Factuality: Are we making progress on multimodal
  out-of-context misinformation detection? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13488v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13488v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Stefanos-Iordanis Papadopoulos, Christos Koutlis, Symeon Papadopoulos, Panagiotis C. Petrantonakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Out-of-context (OOC) misinformation poses a significant challenge in
multimodal fact-checking, where images are paired with texts that misrepresent
their original context to support false narratives. Recent research in
evidence-based OOC detection has seen a trend towards increasingly complex
architectures, incorporating Transformers, foundation models, and large
language models. In this study, we introduce a simple yet robust baseline,
which assesses MUltimodal SimilaritiEs (MUSE), specifically the similarity
between image-text pairs and external image and text evidence. Our results
demonstrate that MUSE, when used with conventional classifiers like Decision
Tree, Random Forest, and Multilayer Perceptron, can compete with and even
surpass the state-of-the-art on the NewsCLIPpings and VERITE datasets.
Furthermore, integrating MUSE in our proposed "Attentive Intermediate
Transformer Representations" (AITR) significantly improved performance, by 3.3%
and 7.5% on NewsCLIPpings and VERITE, respectively. Nevertheless, the success
of MUSE, relying on surface-level patterns and shortcuts, without examining
factuality and logical inconsistencies, raises critical questions about how we
define the task, construct datasets, collect external evidence and overall, how
we assess progress in the field. We release our code at:
https://github.com/stevejpapad/outcontext-misinfo-progress
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SCAPE: A Simple and Strong Category-Agnostic Pose Estimator <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13483v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13483v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujia Liang, Zixuan Ye, Wenze Liu, Hao Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Category-Agnostic Pose Estimation (CAPE) aims to localize keypoints on an
object of any category given few exemplars in an in-context manner. Prior arts
involve sophisticated designs, e.g., sundry modules for similarity calculation
and a two-stage framework, or takes in extra heatmap generation and
supervision. We notice that CAPE is essentially a task about feature matching,
which can be solved within the attention process. Therefore we first streamline
the architecture into a simple baseline consisting of several pure
self-attention layers and an MLP regression head -- this simplification means
that one only needs to consider the attention quality to boost the performance
of CAPE. Towards an effective attention process for CAPE, we further introduce
two key modules: i) a global keypoint feature perceptor to inject global
semantic information into support keypoints, and ii) a keypoint attention
refiner to enhance inter-node correlation between keypoints. They jointly form
a Simple and strong Category-Agnostic Pose Estimator (SCAPE). Experimental
results show that SCAPE outperforms prior arts by 2.2 and 1.3 PCK under 1-shot
and 5-shot settings with faster inference speed and lighter model capacity,
excelling in both accuracy and efficiency. Code and models are available at
https://github.com/tiny-smart/SCAPE
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024. Code is available at
  https://github.com/tiny-smart/SCAPE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SA-DVAE: Improving Zero-Shot Skeleton-Based Action Recognition by
  Disentangled Variational Autoencoders <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13460v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13460v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sheng-Wei Li, Zi-Xiang Wei, Wei-Jie Chen, Yi-Hsin Yu, Chih-Yuan Yang, Jane Yung-jen Hsu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing zero-shot skeleton-based action recognition methods utilize
projection networks to learn a shared latent space of skeleton features and
semantic embeddings. The inherent imbalance in action recognition datasets,
characterized by variable skeleton sequences yet constant class labels,
presents significant challenges for alignment. To address the imbalance, we
propose SA-DVAE -- Semantic Alignment via Disentangled Variational
Autoencoders, a method that first adopts feature disentanglement to separate
skeleton features into two independent parts -- one is semantic-related and
another is irrelevant -- to better align skeleton and semantic features. We
implement this idea via a pair of modality-specific variational autoencoders
coupled with a total correction penalty. We conduct experiments on three
benchmark datasets: NTU RGB+D, NTU RGB+D 120 and PKU-MMD, and our experimental
results show that SA-DAVE produces improved performance over existing methods.
The code is available at https://github.com/pha123661/SA-DVAE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BEAF: Observing BEfore-AFter Changes to Evaluate Hallucination in
  Vision-language Models <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13442v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13442v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Moon Ye-Bin, Nam Hyeon-Woo, Wonseok Choi, Tae-Hyun Oh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision language models (VLMs) perceive the world through a combination of a
visual encoder and a large language model (LLM). The visual encoder,
pre-trained on large-scale vision-text datasets, provides zero-shot
generalization to visual data, and the LLM endows its high reasoning ability to
VLMs. It leads VLMs to achieve high performance on wide benchmarks without
fine-tuning, exhibiting zero or few-shot capability. However, recent studies
show that VLMs are vulnerable to hallucination. This undesirable behavior
degrades reliability and credibility, thereby making users unable to fully
trust the output from VLMs. To enhance trustworthiness and better tackle the
hallucination of VLMs, we curate a new evaluation dataset, called the
BEfore-AFter hallucination dataset (BEAF), and introduce new metrics: True
Understanding (TU), IGnorance (IG), StuBbornness (SB), and InDecision (ID).
Unlike prior works that focus only on constructing questions and answers, the
key idea of our benchmark is to manipulate visual scene information by image
editing models and to design the metrics based on scene changes. This allows us
to clearly assess whether VLMs correctly understand a given scene by observing
the ability to perceive changes. We also visualize image-wise object
relationship by virtue of our two-axis view: vision and text. Upon evaluating
VLMs with our dataset, we observed that our metrics reveal different aspects of
VLM hallucination that have not been reported before. Project page:
\url{https://beafbench.github.io/}
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ECCV 2024. [Project Pages] https://beafbench.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FREST: Feature RESToration for Semantic Segmentation under Multiple
  Adverse Conditions <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13437v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13437v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sohyun Lee, Namyup Kim, Sungyeon Kim, Suha Kwak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Robust semantic segmentation under adverse conditions is crucial in
real-world applications. To address this challenging task in practical
scenarios where labeled normal condition images are not accessible in training,
we propose FREST, a novel feature restoration framework for source-free domain
adaptation (SFDA) of semantic segmentation to adverse conditions. FREST
alternates two steps: (1) learning the condition embedding space that only
separates the condition information from the features and (2) restoring
features of adverse condition images on the learned condition embedding space.
By alternating these two steps, FREST gradually restores features where the
effect of adverse conditions is reduced. FREST achieved a state of the art on
two public benchmarks (i.e., ACDC and RobotCar) for SFDA to adverse conditions.
Moreover, it shows superior generalization ability on unseen datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ WiNet: Wavelet-based Incremental Learning for Efficient Medical Image
  Registration <span class="chip">MICCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13426v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13426v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinxing Cheng, Xi Jia, Wenqi Lu, Qiufu Li, Linlin Shen, Alexander Krull, Jinming Duan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep image registration has demonstrated exceptional accuracy and fast
inference. Recent advances have adopted either multiple cascades or pyramid
architectures to estimate dense deformation fields in a coarse-to-fine manner.
However, due to the cascaded nature and repeated composition/warping operations
on feature maps, these methods negatively increase memory usage during training
and testing. Moreover, such approaches lack explicit constraints on the
learning process of small deformations at different scales, thus lacking
explainability. In this study, we introduce a model-driven WiNet that
incrementally estimates scale-wise wavelet coefficients for the
displacement/velocity field across various scales, utilizing the wavelet
coefficients derived from the original input image pair. By exploiting the
properties of the wavelet transform, these estimated coefficients facilitate
the seamless reconstruction of a full-resolution displacement/velocity field
via our devised inverse discrete wavelet transform (IDWT) layer. This approach
avoids the complexities of cascading networks or composition operations, making
our WiNet an explainable and efficient competitor with other coarse-to-fine
methods. Extensive experimental results from two 3D datasets show that our
WiNet is accurate and GPU efficient. The code is available at
https://github.com/x-xc/WiNet .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by MICCAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CycleMix: Mixing Source Domains for Domain Generalization in
  Style-Dependent Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13421v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13421v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aristotelis Ballas, Christos Diou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As deep learning-based systems have become an integral part of everyday life,
limitations in their generalization ability have begun to emerge. Machine
learning algorithms typically rely on the i.i.d. assumption, meaning that their
training and validation data are expected to follow the same distribution,
which does not necessarily hold in practice. In the case of image
classification, one frequent reason that algorithms fail to generalize is that
they rely on spurious correlations present in training data, such as
associating image styles with target classes. These associations may not be
present in the unseen test data, leading to significant degradation of their
effectiveness. In this work, we attempt to mitigate this Domain Generalization
(DG) problem by training a robust feature extractor which disregards features
attributed to image-style but infers based on style-invariant image
representations. To achieve this, we train CycleGAN models to learn the
different styles present in the training data and randomly mix them together to
create samples with novel style attributes to improve generalization.
Experimental results on the PACS DG benchmark validate the proposed method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GDDS: A Single Domain Generalized Defect Detection Frame of Open World
  Scenario using Gather and Distribute Domain-shift Suppression Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13417v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13417v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haiyong Chen, Yaxiu Zhang, Yan Zhang, Xin Zhang, Xingwei Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Efficient and intelligent surface defect detection of photovoltaic modules is
crucial for improving the quality of photovoltaic modules and ensuring the
reliable operation of large-scale infrastructure. However, the scenario
characteristics of data distribution deviation make the construction of defect
detection models for open world scenarios such as photovoltaic manufacturing
and power plant inspections a challenge. Therefore, we propose the Gather and
Distribute Domain shift Suppression Network (GDDS). It adopts a single domain
generalized method that is completely independent of the test samples to
address the problem of distribution shift. Using a one-stage network as the
baseline network breaks through the limitations of traditional domain
generalization methods that typically use two-stage networks. It not only
balances detection accuracy and speed but also simplifies the model deployment
and application process. The GDDS includes two modules: DeepSpine Module and
Gather and Distribute Module. Specifically, the DeepSpine Module applies a
wider range of contextual information and suppresses background style shift by
acquiring and concatenating multi-scale features. The Gather and Distribute
Module collects and distributes global information to achieve cross layer
interactive learning of multi-scale channel features and suppress defect
instance shift. Furthermore, the GDDS utilizes normalized Wasserstein distance
for similarity measurement, reducing measurement errors caused by bounding box
position deviations. We conducted a comprehensive evaluation of GDDS on the EL
endogenous shift dataset and Photovoltaic inspection infrared image dataset.
The experimental results showed that GDDS can adapt to defect detection in open
world scenarios faster and better than other state-of-the-art methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 images</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PICASSO: A Feed-Forward Framework for Parametric Inference of CAD
  Sketches via Rendering Self-Supervision 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13394v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13394v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahmet Serdar Karadeniz, Dimitrios Mallis, Nesryne Mejri, Kseniya Cherenkova, Anis Kacem, Djamila Aouada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose PICASSO, a novel framework CAD sketch parameterization from
hand-drawn or precise sketch images via rendering self-supervision. Given a
drawing of a CAD sketch, the proposed framework turns it into parametric
primitives that can be imported into CAD software. Compared to existing
methods, PICASSO enables the learning of parametric CAD sketches from either
precise or hand-drawn sketch images, even in cases where annotations at the
parameter level are scarce or unavailable. This is achieved by leveraging the
geometric characteristics of sketches as a learning cue to pre-train a CAD
parameterization network. Specifically, PICASSO comprises two primary
components: (1) a Sketch Parameterization Network (SPN) that predicts a series
of parametric primitives from CAD sketch images, and (2) a Sketch Rendering
Network (SRN) that renders parametric CAD sketches in a differentiable manner.
SRN facilitates the computation of a image-to-image loss, which can be utilized
to pre-train SPN, thereby enabling zero- and few-shot learning scenarios for
the parameterization of hand-drawn sketches. Extensive evaluation on the widely
used SketchGraphs dataset validates the effectiveness of the proposed
framework.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Lightweight Uncertainty Quantification with Simplex Semantic
  Segmentation for Terrain Traversability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13392v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13392v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Judith Dijk, Gertjan Burghouts, Kapil D. Katyal, Bryanna Y. Yeh, Craig T. Knuth, Ella Fokkinga, Tejaswi Kasarla, Pascal Mettes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For navigation of robots, image segmentation is an important component to
determining a terrain's traversability. For safe and efficient navigation, it
is key to assess the uncertainty of the predicted segments. Current uncertainty
estimation methods are limited to a specific choice of model architecture, are
costly in terms of training time, require large memory for inference
(ensembles), or involve complex model architectures (energy-based, hyperbolic,
masking). In this paper, we propose a simple, light-weight module that can be
connected to any pretrained image segmentation model, regardless of its
architecture, with marginal additional computation cost because it reuses the
model's backbone. Our module is based on maximum separation of the segmentation
classes by respective prototype vectors. This optimizes the probability that
out-of-distribution segments are projected in between the prototype vectors.
The uncertainty value in the classification label is obtained from the distance
to the nearest prototype. We demonstrate the effectiveness of our module for
terrain segmentation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GeometrySticker: Enabling Ownership Claim of Recolorized Neural Radiance
  Fields 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13390v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13390v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiufeng Huang, Ka Chun Cheung, Simon See, Renjie Wan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remarkable advancements in the recolorization of Neural Radiance Fields
(NeRF) have simplified the process of modifying NeRF's color attributes. Yet,
with the potential of NeRF to serve as shareable digital assets, there's a
concern that malicious users might alter the color of NeRF models and falsely
claim the recolorized version as their own. To safeguard against such breaches
of ownership, enabling original NeRF creators to establish rights over
recolorized NeRF is crucial. While approaches like CopyRNeRF have been
introduced to embed binary messages into NeRF models as digital signatures for
copyright protection, the process of recolorization can remove these binary
messages. In our paper, we present GeometrySticker, a method for seamlessly
integrating binary messages into the geometry components of radiance fields,
akin to applying a sticker. GeometrySticker can embed binary messages into NeRF
models while preserving the effectiveness of these messages against
recolorization. Our comprehensive studies demonstrate that GeometrySticker is
adaptable to prevalent NeRF architectures and maintains a commendable level of
robustness against various distortions. Project page:
https://kevinhuangxf.github.io/GeometrySticker/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Removing cloud shadows from ground-based solar imagery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13379v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13379v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amal Chaoui, Jay Paul Morgan, Adeline Paiement, Jean Aboudarham
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The study and prediction of space weather entails the analysis of solar
images showing structures of the Sun's atmosphere. When imaged from the Earth's
ground, images may be polluted by terrestrial clouds which hinder the detection
of solar structures. We propose a new method to remove cloud shadows, based on
a U-Net architecture, and compare classical supervision with conditional GAN.
We evaluate our method on two different imaging modalities, using both real
images and a new dataset of synthetic clouds. Quantitative assessments are
obtained through image quality indices (RMSE, PSNR, SSIM, and FID). We
demonstrate improved results with regards to the traditional cloud removal
technique and a sparse coding baseline, on different cloud types and textures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Any Image Restoration with Efficient Automatic Degradation Adaptation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13372v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13372v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bin Ren, Eduard Zamfir, Yawei Li, Zongwei Wu, Danda Pani Paudel, Radu Timofte, Nicu Sebe, Luc Van Gool
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the emergence of mobile devices, there is a growing demand for an
efficient model to restore any degraded image for better perceptual quality.
However, existing models often require specific learning modules tailored for
each degradation, resulting in complex architectures and high computation
costs. Different from previous work, in this paper, we propose a unified manner
to achieve joint embedding by leveraging the inherent similarities across
various degradations for efficient and comprehensive restoration. Specifically,
we first dig into the sub-latent space of each input to analyze the key
components and reweight their contributions in a gated manner. The intrinsic
awareness is further integrated with contextualized attention in an X-shaped
scheme, maximizing local-global intertwining. Extensive comparison on
benchmarking all-in-one restoration setting validates our efficiency and
effectiveness, i.e., our network sets new SOTA records while reducing model
complexity by approximately -82% in trainable parameters and -85\% in FLOPs.
Our code will be made publicly available
at:https://github.com/Amazingren/AnyIR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Efficient Any Image Restoration</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Affordance Perception by a Knowledge-Guided Vision-Language Model with
  Efficient Error Correction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13368v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13368v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gertjan Burghouts, Marianne Schaaphok, Michael van Bekkum, Wouter Meijer, Fieke Hillerström, Jelle van Mil
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mobile robot platforms will increasingly be tasked with activities that
involve grasping and manipulating objects in open world environments.
Affordance understanding provides a robot with means to realise its goals and
execute its tasks, e.g. to achieve autonomous navigation in unknown buildings
where it has to find doors and ways to open these. In order to get actionable
suggestions, robots need to be able to distinguish subtle differences between
objects, as they may result in different action sequences: doorknobs require
grasp and twist, while handlebars require grasp and push. In this paper, we
improve affordance perception for a robot in an open-world setting. Our
contribution is threefold: (1) We provide an affordance representation with
precise, actionable affordances; (2) We connect this knowledge base to a
foundational vision-language models (VLM) and prompt the VLM for a wider
variety of new and unseen objects; (3) We apply a human-in-the-loop for
corrections on the output of the VLM. The mix of affordance representation,
image detection and a human-in-the-loop is effective for a robot to search for
objects to achieve its goals. We have demonstrated this in a scenario of
finding various doors and the many different ways to open them.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning from the Web: Language Drives Weakly-Supervised Incremental
  Learning for Semantic Segmentation <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13363v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13363v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chang Liu, Giulia Rizzoli, Pietro Zanuttigh, Fu Li, Yi Niu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current weakly-supervised incremental learning for semantic segmentation
(WILSS) approaches only consider replacing pixel-level annotations with
image-level labels, while the training images are still from well-designed
datasets. In this work, we argue that widely available web images can also be
considered for the learning of new classes. To achieve this, firstly we
introduce a strategy to select web images which are similar to previously seen
examples in the latent space using a Fourier-based domain discriminator. Then,
an effective caption-driven reharsal strategy is proposed to preserve
previously learnt classes. To our knowledge, this is the first work to rely
solely on web images for both the learning of new concepts and the preservation
of the already learned ones in WILSS. Experimental results show that the
proposed approach can reach state-of-the-art performances without using
manually selected and annotated data in the incremental steps.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Open Vocabulary 3D Scene Understanding via Geometry Guided
  Self-Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13362v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13362v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengfei Wang, Yuxi Wang, Shuai Li, Zhaoxiang Zhang, Zhen Lei, Lei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The scarcity of large-scale 3D-text paired data poses a great challenge on
open vocabulary 3D scene understanding, and hence it is popular to leverage
internet-scale 2D data and transfer their open vocabulary capabilities to 3D
models through knowledge distillation. However, the existing distillation-based
3D scene understanding approaches rely on the representation capacity of 2D
models, disregarding the exploration of geometric priors and inherent
representational advantages offered by 3D data. In this paper, we propose an
effective approach, namely Geometry Guided Self-Distillation (GGSD), to learn
superior 3D representations from 2D pre-trained models. Specifically, we first
design a geometry guided distillation module to distill knowledge from 2D
models, and then leverage the 3D geometric priors to alleviate the inherent
noise in 2D models and enhance the representation learning process. Due to the
advantages of 3D representation, the performance of the distilled 3D student
model can significantly surpass that of the 2D teacher model. This motivates us
to further leverage the representation advantages of 3D data through
self-distillation. As a result, our proposed GGSD approach outperforms the
existing open vocabulary 3D scene understanding methods by a large margin, as
demonstrated by our experiments on both indoor and outdoor benchmark datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Implicit Filtering for Learning Neural Signed Distance Functions from 3D
  Point Clouds <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13342v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13342v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengtao Li, Ge Gao, Yudong Liu, Ming Gu, Yu-Shen Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural signed distance functions (SDFs) have shown powerful ability in
fitting the shape geometry. However, inferring continuous signed distance
fields from discrete unoriented point clouds still remains a challenge. The
neural network typically fits the shape with a rough surface and omits
fine-grained geometric details such as shape edges and corners. In this paper,
we propose a novel non-linear implicit filter to smooth the implicit field
while preserving high-frequency geometry details. Our novelty lies in that we
can filter the surface (zero level set) by the neighbor input points with
gradients of the signed distance field. By moving the input raw point clouds
along the gradient, our proposed implicit filtering can be extended to non-zero
level sets to keep the promise consistency between different level sets, which
consequently results in a better regularization of the zero level set. We
conduct comprehensive experiments in surface reconstruction from objects and
complex scene point clouds, the numerical and visual comparisons demonstrate
our improvements over the state-of-the-art methods under the widely used
benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV 2024. Project page:
  https://list17.github.io/ImplicitFilter</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hybrid Deep Learning-Based for Enhanced Occlusion Segmentation in PICU
  Patient Monitoring 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13341v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13341v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mario Francisco Munoz, Hoang Vu Huy, Thanh-Dung Le
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remote patient monitoring has emerged as a prominent non-invasive method,
using digital technologies and computer vision (CV) to replace traditional
invasive monitoring. While neonatal and pediatric departments embrace this
approach, Pediatric Intensive Care Units (PICUs) face the challenge of
occlusions hindering accurate image analysis and interpretation.
\textit{Objective}: In this study, we propose a hybrid approach to effectively
segment common occlusions encountered in remote monitoring applications within
PICUs. Our approach centers on creating a deep-learning pipeline for limited
training data scenarios. \textit{Methods}: First, a combination of the
well-established Google DeepLabV3+ segmentation model with the
transformer-based Segment Anything Model (SAM) is devised for occlusion
segmentation mask proposal and refinement. We then train and validate this
pipeline using a small dataset acquired from real-world PICU settings with a
Microsoft Kinect camera, achieving an Intersection-over-Union (IoU) metric of
85\%. \textit{Results}: Both quantitative and qualitative analyses underscore
the effectiveness of our proposed method. The proposed framework yields an
overall classification performance with 92.5\% accuracy, 93.8\% recall, 90.3\%
precision, and 92.0\% F1-score. Consequently, the proposed method consistently
improves the predictions across all metrics, with an average of 2.75\% gain in
performance compared to the baseline CNN-based framework. \textit{Conclusions}:
Our proposed hybrid approach significantly enhances the segmentation of
occlusions in remote patient monitoring within PICU settings. This advancement
contributes to improving the quality of care for pediatric patients, addressing
a critical need in clinical practice by ensuring more accurate and reliable
remote monitoring.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under revision</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learn to Memorize and to Forget: A Continual Learning Perspective of
  Dynamic SLAM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13338v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13338v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Baicheng Li, Zike Yan, Dong Wu, Hanqing Jiang, Hongbin Zha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Simultaneous localization and mapping (SLAM) with implicit neural
representations has received extensive attention due to the expressive
representation power and the innovative paradigm of continual learning.
However, deploying such a system within a dynamic environment has not been
well-studied. Such challenges are intractable even for conventional algorithms
since observations from different views with dynamic objects involved break the
geometric and photometric consistency, whereas the consistency lays the
foundation for joint optimizing the camera pose and the map parameters. In this
paper, we best exploit the characteristics of continual learning and propose a
novel SLAM framework for dynamic environments. While past efforts have been
made to avoid catastrophic forgetting by exploiting an experience replay
strategy, we view forgetting as a desirable characteristic. By adaptively
controlling the replayed buffer, the ambiguity caused by moving objects can be
easily alleviated through forgetting. We restrain the replay of the dynamic
objects by introducing a continually-learned classifier for dynamic object
identification. The iterative optimization of the neural map and the classifier
notably improves the robustness of the SLAM system under a dynamic environment.
Experiments on challenging datasets verify the effectiveness of the proposed
framework.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Long-Term 3D Point Tracking By Cost Volume Fusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13337v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13337v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hung Nguyen, Chanho Kim, Rigved Naukarkar, Li Fuxin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-term point tracking is essential to understand non-rigid motion in the
physical world better. Deep learning approaches have recently been incorporated
into long-term point tracking, but most prior work predominantly functions in
2D. Although these methods benefit from the well-established backbones and
matching frameworks, the motions they produce do not always make sense in the
3D physical world. In this paper, we propose the first deep learning framework
for long-term point tracking in 3D that generalizes to new points and videos
without requiring test-time fine-tuning. Our model contains a cost volume
fusion module that effectively integrates multiple past appearances and motion
information via a transformer architecture, significantly enhancing overall
tracking performance. In terms of 3D tracking performance, our model
significantly outperforms simple scene flow chaining and previous 2D point
tracking methods, even if one uses ground truth depth and camera pose to
backproject 2D point tracks in a synthetic scenario.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OAT: Object-Level Attention <span class="highlight-title">Transformer</span> for Gaze Scanpath Prediction <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13335v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13335v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yini Fang, Jingling Yu, Haozheng Zhang, Ralf van der Lans, Bertram Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual search is important in our daily life. The efficient allocation of
visual attention is critical to effectively complete visual search tasks. Prior
research has predominantly modelled the spatial allocation of visual attention
in images at the pixel level, e.g. using a saliency map. However, emerging
evidence shows that visual attention is guided by objects rather than pixel
intensities. This paper introduces the Object-level Attention Transformer
(OAT), which predicts human scanpaths as they search for a target object within
a cluttered scene of distractors. OAT uses an encoder-decoder architecture. The
encoder captures information about the position and appearance of the objects
within an image and about the target. The decoder predicts the gaze scanpath as
a sequence of object fixations, by integrating output features from both the
encoder and decoder. We also propose a new positional encoding that better
reflects spatial relationships between objects. We evaluated OAT on the Amazon
book cover dataset and a new dataset for visual search that we collected. OAT's
predicted gaze scanpaths align more closely with human gaze patterns, compared
to predictions by algorithms based on spatial attention on both established
metrics and a novel behavioural-based metric. Our results demonstrate the
generalization ability of OAT, as it accurately predicts human scanpaths for
unseen layouts and target objects.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unsupervised Domain Adaptive Lane Detection via Contextual Contrast and
  Aggregation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13328v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13328v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kunyang Zhou, Yunjian Feng, Jun Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper focuses on two crucial issues in domain-adaptive lane detection,
i.e., how to effectively learn discriminative features and transfer knowledge
across domains. Existing lane detection methods usually exploit a pixel-wise
cross-entropy loss to train detection models. However, the loss ignores the
difference in feature representation among lanes, which leads to inefficient
feature learning. On the other hand, cross-domain context dependency crucial
for transferring knowledge across domains remains unexplored in existing lane
detection methods. This paper proposes a method of Domain-Adaptive lane
detection via Contextual Contrast and Aggregation (DACCA), consisting of two
key components, i.e., cross-domain contrastive loss and domain-level feature
aggregation, to realize domain-adaptive lane detection. The former can
effectively differentiate feature representations among categories by taking
domain-level features as positive samples. The latter fuses the domain-level
and pixel-level features to strengthen cross-domain context dependency.
Extensive experiments show that DACCA significantly improves the detection
model's performance and outperforms existing unsupervised domain adaptive lane
detection methods on six datasets, especially achieving the best performance
when transferring from CULane to Tusimple (92.10% accuracy), Tusimple to CULane
(41.9% F1 score), OpenLane to CULane (43.0% F1 score), and CULane to OpenLane
(27.6% F1 score).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fully Test-Time rPPG Estimation via Synthetic Signal-Guided Feature
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13322v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13322v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pei-Kai Huang, Tzu-Hsien Chen, Ya-Ting Chan, Kuan-Wen Chen, Chiou-Ting Hsu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many remote photoplethysmography (rPPG) estimation models have achieved
promising performance on the training domain but often fail to measure the
physiological signals or heart rates (HR) on test domains. Domain
generalization (DG) or domain adaptation (DA) techniques are therefore adopted
in the offline training stage to adapt the model to the unobserved or observed
test domain by referring to all the available source domain data. However, in
rPPG estimation problems, the adapted model usually confronts challenges of
estimating target data with various domain information, such as different video
capturing settings, individuals of different age ranges, or of different HR
distributions. In contrast, Test-Time Adaptation (TTA), by online adapting to
unlabeled target data without referring to any source data, enables the model
to adaptively estimate rPPG signals of various unseen domains. In this paper,
we first propose a novel TTA-rPPG benchmark, which encompasses various domain
information and HR distributions, to simulate the challenges encountered in
rPPG estimation. Next, we propose a novel synthetic signal-guided rPPG
estimation framework with a two-fold purpose. First, we design an effective
spectral-based entropy minimization to enforce the rPPG model to learn new
target domain information. Second, we develop a synthetic signal-guided feature
learning, by synthesizing pseudo rPPG signals as pseudo ground-truths to guide
a conditional generator to generate latent rPPG features. The synthesized rPPG
signals and the generated rPPG features are used to guide the rPPG model to
broadly cover various HR distributions. Our extensive experiments on the
TTA-rPPG benchmark show that the proposed method achieves superior performance
and outperforms previous DG and DA methods across most protocols of the
proposed TTA-rPPG benchmark.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ General Vision Encoder Features as Guidance in Medical Image
  Registration <span class="chip">MICCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13311v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13311v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fryderyk Kögl, Anna Reithmeir, Vasiliki Sideri-Lampretsa, Ines Machado, Rickmer Braren, Daniel Rückert, Julia A. Schnabel, Veronika A. Zimmer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  General vision encoders like DINOv2 and SAM have recently transformed
computer vision. Even though they are trained on natural images, such encoder
models have excelled in medical imaging, e.g., in classification, segmentation,
and registration. However, no in-depth comparison of different state-of-the-art
general vision encoders for medical registration is available. In this work, we
investigate how well general vision encoder features can be used in the
dissimilarity metrics for medical image registration. We explore two encoders
that were trained on natural images as well as one that was fine-tuned on
medical data. We apply the features within the well-established B-spline FFD
registration framework. In extensive experiments on cardiac cine MRI data, we
find that using features as additional guidance for conventional metrics
improves the registration quality. The code is available at
github.com/compai-lab/2024-miccai-koegl.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at WBIR MICCAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exposure Completing for Temporally Consistent Neural High Dynamic Range
  Video Rendering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13309v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13309v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Cui, Wei Jiang, Zhan Peng, Zhiyu Pan, Zhiguo Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High dynamic range (HDR) video rendering from low dynamic range (LDR) videos
where frames are of alternate exposure encounters significant challenges, due
to the exposure change and absence at each time stamp. The exposure change and
absence make existing methods generate flickering HDR results. In this paper,
we propose a novel paradigm to render HDR frames via completing the absent
exposure information, hence the exposure information is complete and
consistent. Our approach involves interpolating neighbor LDR frames in the time
dimension to reconstruct LDR frames for the absent exposures. Combining the
interpolated and given LDR frames, the complete set of exposure information is
available at each time stamp. This benefits the fusing process for HDR results,
reducing noise and ghosting artifacts therefore improving temporal consistency.
Extensive experimental evaluations on standard benchmarks demonstrate that our
method achieves state-of-the-art performance, highlighting the importance of
absent exposure completing in HDR video rendering. The code is available at
https://github.com/cuijiahao666/NECHDR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 6 figures, accepted by ACM-MM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Conformal Performance Range Prediction for Segmentation Output Quality
  Control <span class="chip">MICCAI</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13307v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13307v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anna M. Wundram, Paul Fischer, Michael Muehlebach, Lisa M. Koch, Christian F. Baumgartner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent works have introduced methods to estimate segmentation performance
without ground truth, relying solely on neural network softmax outputs. These
techniques hold potential for intuitive output quality control. However, such
performance estimates rely on calibrated softmax outputs, which is often not
the case in modern neural networks. Moreover, the estimates do not take into
account inherent uncertainty in segmentation tasks. These limitations may
render precise performance predictions unattainable, restricting the practical
applicability of performance estimation methods. To address these challenges,
we develop a novel approach for predicting performance ranges with statistical
guarantees of containing the ground truth with a user specified probability.
Our method leverages sampling-based segmentation uncertainty estimation to
derive heuristic performance ranges, and applies split conformal prediction to
transform these estimates into rigorous prediction ranges that meet the desired
guarantees. We demonstrate our approach on the FIVES retinal vessel
segmentation dataset and compare five commonly used sampling-based uncertainty
estimation techniques. Our results show that it is possible to achieve the
desired coverage with small prediction ranges, highlighting the potential of
performance range prediction as a valuable tool for output quality control.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as an oral presentation at MICCAI UNSURE 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Dataset</span> and Benchmark for Shape Completion of Fruits for Agricultural
  Robotics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13304v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13304v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Federico Magistri, Thomas Läbe, Elias Marks, Sumanth Nagulavancha, Yue Pan, Claus Smitt, Lasse Klingbeil, Michael Halstead, Heiner Kuhlmann, Chris McCool, Jens Behley, Cyrill Stachniss
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the population is expected to reach 10 billion by 2050, our agricultural
production system needs to double its productivity despite a decline of human
workforce in the agricultural sector. Autonomous robotic systems are one
promising pathway to increase productivity by taking over labor-intensive
manual tasks like fruit picking. To be effective, such systems need to monitor
and interact with plants and fruits precisely, which is challenging due to the
cluttered nature of agricultural environments causing, for example, strong
occlusions. Thus, being able to estimate the complete 3D shapes of objects in
presence of occlusions is crucial for automating operations such as fruit
harvesting. In this paper, we propose the first publicly available 3D shape
completion dataset for agricultural vision systems. We provide an RGB-D dataset
for estimating the 3D shape of fruits. Specifically, our dataset contains RGB-D
frames of single sweet peppers in lab conditions but also in a commercial
greenhouse. For each fruit, we additionally collected high-precision point
clouds that we use as ground truth. For acquiring the ground truth shape, we
developed a measuring process that allows us to record data of real sweet
pepper plants, both in the lab and in the greenhouse with high precision, and
determine the shape of the sensed fruits. We release our dataset, consisting of
almost 7000 RGB-D frames belonging to more than 100 different fruits. We
provide segmented RGB-D frames, with camera instrinsics to easily obtain
colored point clouds, together with the corresponding high-precision,
occlusion-free point clouds obtained with a high-precision laser scanner. We
additionally enable evaluation ofshape completion approaches on a hidden test
set through a public challenge on a benchmark server.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Collaborative real-time vision-based device for olive oil production
  monitoring 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13285v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13285v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matija Šuković, Igor Jovančević
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes an innovative approach to improving quality control of
olive oil manufacturing and preventing damage to the machinery caused by
foreign objects. We developed a computer-vision-based system that monitors the
input of an olive grinder and promptly alerts operators if a foreign object is
detected, indicating it by using guided lasers, audio, and visual cues.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ URCDM: Ultra-Resolution Image Synthesis in Histopathology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13277v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13277v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sarah Cechnicka, James Ball, Matthew Baugh, Hadrien Reynaud, Naomi Simmonds, Andrew P. T. Smith, Catherine Horsfield, Candice Roufosse, Bernhard Kainz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diagnosing medical conditions from histopathology data requires a thorough
analysis across the various resolutions of Whole Slide Images (WSI). However,
existing generative methods fail to consistently represent the hierarchical
structure of WSIs due to a focus on high-fidelity patches. To tackle this, we
propose Ultra-Resolution Cascaded Diffusion Models (URCDMs) which are capable
of synthesising entire histopathology images at high resolutions whilst
authentically capturing the details of both the underlying anatomy and
pathology at all magnification levels. We evaluate our method on three separate
datasets, consisting of brain, breast and kidney tissue, and surpass existing
state-of-the-art multi-resolution models. Furthermore, an expert evaluation
study was conducted, demonstrating that URCDMs consistently generate outputs
across various resolutions that trained evaluators cannot distinguish from real
images. All code and additional examples can be found on GitHub.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2312.01152</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Make a Strong Teacher with Label Assistance: A Novel Knowledge
  Distillation Approach for Semantic Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13254v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13254v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shoumeng Qiu, Jie Chen, Xinrun Li, Ru Wan, Xiangyang Xue, Jian Pu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce a novel knowledge distillation approach for the
semantic segmentation task. Unlike previous methods that rely on power-trained
teachers or other modalities to provide additional knowledge, our approach does
not require complex teacher models or information from extra sensors.
Specifically, for the teacher model training, we propose to noise the label and
then incorporate it into input to effectively boost the lightweight teacher
performance. To ensure the robustness of the teacher model against the
introduced noise, we propose a dual-path consistency training strategy
featuring a distance loss between the outputs of two paths. For the student
model training, we keep it consistent with the standard distillation for
simplicity. Our approach not only boosts the efficacy of knowledge distillation
but also increases the flexibility in selecting teacher and student models. To
demonstrate the advantages of our Label Assisted Distillation (LAD) method, we
conduct extensive experiments on five challenging datasets including
Cityscapes, ADE20K, PASCAL-VOC, COCO-Stuff 10K, and COCO-Stuff 164K, five
popular models: FCN, PSPNet, DeepLabV3, STDC, and OCRNet, and results show the
effectiveness and generalization of our approach. We posit that incorporating
labels into the input, as demonstrated in our work, will provide valuable
insights into related fields. Code is available at
https://github.com/skyshoumeng/Label_Assisted_Distillation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unveiling Structural Memorization: Structural Membership Inference
  Attack for Text-to-Image Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13252v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13252v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiao Li, Xiaomeng Fu, Xi Wang, Jin Liu, Xingyu Gao, Jiao Dai, Jizhong Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid advancements of large-scale text-to-image diffusion models,
various practical applications have emerged, bringing significant convenience
to society. However, model developers may misuse the unauthorized data to train
diffusion models. These data are at risk of being memorized by the models, thus
potentially violating citizens' privacy rights. Therefore, in order to judge
whether a specific image is utilized as a member of a model's training set,
Membership Inference Attack (MIA) is proposed to serve as a tool for privacy
protection. Current MIA methods predominantly utilize pixel-wise comparisons as
distinguishing clues, considering the pixel-level memorization characteristic
of diffusion models. However, it is practically impossible for text-to-image
models to memorize all the pixel-level information in massive training sets.
Therefore, we move to the more advanced structure-level memorization.
Observations on the diffusion process show that the structures of members are
better preserved compared to those of nonmembers, indicating that diffusion
models possess the capability to remember the structures of member images from
training sets. Drawing on these insights, we propose a simple yet effective MIA
method tailored for text-to-image diffusion models. Extensive experimental
results validate the efficacy of our approach. Compared to current pixel-level
baselines, our approach not only achieves state-of-the-art performance but also
demonstrates remarkable robustness against various distortions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ STS MICCAI 2023 Challenge: Grand challenge on 2D and 3D semi-supervised
  tooth segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13246v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13246v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaqi Wang, Yifan Zhang, Xiaodiao Chen, Shuai Wang, Dahong Qian, Fan Ye, Feng Xu, Hongyuan Zhang, Qianni Zhang, Chengyu Wu, Yunxiang Li, Weiwei Cui, Shan Luo, Chengkai Wang, Tianhao Li, Yi Liu, Xiang Feng, Huiyu Zhou, Dongyun Liu, Qixuan Wang, Zhouhao Lin, Wei Song, Yuanlin Li, Bing Wang, Chunshi Wang, Qiupu Chen, Mingqian Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computer-aided design (CAD) tools are increasingly popular in modern dental
practice, particularly for treatment planning or comprehensive prognosis
evaluation. In particular, the 2D panoramic X-ray image efficiently detects
invisible caries, impacted teeth and supernumerary teeth in children, while the
3D dental cone beam computed tomography (CBCT) is widely used in orthodontics
and endodontics due to its low radiation dose. However, there is no open-access
2D public dataset for children's teeth and no open 3D dental CBCT dataset,
which limits the development of automatic algorithms for segmenting teeth and
analyzing diseases. The Semi-supervised Teeth Segmentation (STS) Challenge, a
pioneering event in tooth segmentation, was held as a part of the MICCAI 2023
ToothFairy Workshop on the Alibaba Tianchi platform. This challenge aims to
investigate effective semi-supervised tooth segmentation algorithms to advance
the field of dentistry. In this challenge, we provide two modalities including
the 2D panoramic X-ray images and the 3D CBCT tooth volumes. In Task 1, the
goal was to segment tooth regions in panoramic X-ray images of both adult and
pediatric teeth. Task 2 involved segmenting tooth sections using CBCT volumes.
Limited labelled images with mostly unlabelled ones were provided in this
challenge prompt using semi-supervised algorithms for training. In the
preliminary round, the challenge received registration and result submission by
434 teams, with 64 advancing to the final round. This paper summarizes the
diverse methods employed by the top-ranking teams in the STS MICCAI 2023
Challenge.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NODER: Image Sequence Regression Based on Neural Ordinary Differential
  Equations <span class="chip">MICCAI2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13241v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13241v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Bai, Yi Hong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Regression on medical image sequences can capture temporal image pattern
changes and predict images at missing or future time points. However, existing
geodesic regression methods limit their regression performance by a strong
underlying assumption of linear dynamics, while diffusion-based methods have
high computational costs and lack constraints to preserve image topology. In
this paper, we propose an optimization-based new framework called NODER, which
leverages neural ordinary differential equations to capture complex underlying
dynamics and reduces its high computational cost of handling high-dimensional
image volumes by introducing the latent space. We compare our NODER with two
recent regression methods, and the experimental results on ADNI and ACDC
datasets demonstrate that our method achieves the state-of-the-art performance
in 3D image regression. Our model needs only a couple of images in a sequence
for prediction, which is practical, especially for clinical situations where
extremely limited image time series are available for analysis. Our source code
is available at https://github.com/ZedKing12138/NODER-pytorch.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>MICCAI2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multimodal Label Relevance Ranking via Reinforcement Learning <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13221v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13221v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taian Guo, Taolin Zhang, Haoqian Wu, Hanjun Li, Ruizhi Qiao, Xing Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conventional multi-label recognition methods often focus on label confidence,
frequently overlooking the pivotal role of partial order relations consistent
with human preference. To resolve these issues, we introduce a novel method for
multimodal label relevance ranking, named Label Relevance Ranking with Proximal
Policy Optimization (LR\textsuperscript{2}PPO), which effectively discerns
partial order relations among labels. LR\textsuperscript{2}PPO first utilizes
partial order pairs in the target domain to train a reward model, which aims to
capture human preference intrinsic to the specific scenario. Furthermore, we
meticulously design state representation and a policy loss tailored for ranking
tasks, enabling LR\textsuperscript{2}PPO to boost the performance of label
relevance ranking model and largely reduce the requirement of partial order
annotation for transferring to new scenes. To assist in the evaluation of our
approach and similar methods, we further propose a novel benchmark dataset,
LRMovieNet, featuring multimodal labels and their corresponding partial order
data. Extensive experiments demonstrate that our LR\textsuperscript{2}PPO
algorithm achieves state-of-the-art performance, proving its effectiveness in
addressing the multimodal label relevance ranking problem. Codes and the
proposed LRMovieNet dataset are publicly available at
\url{https://github.com/ChazzyGordon/LR2PPO}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NeRF-MAE: Masked AutoEncoders for <span class="highlight-title">Self-Supervised</span> 3D Representation
  Learning for Neural Radiance Fields <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.01300v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.01300v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Zubair Irshad, Sergey Zakharov, Vitor Guizilini, Adrien Gaidon, Zsolt Kira, Rares Ambrus
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural fields excel in computer vision and robotics due to their ability to
understand the 3D visual world such as inferring semantics, geometry, and
dynamics. Given the capabilities of neural fields in densely representing a 3D
scene from 2D images, we ask the question: Can we scale their self-supervised
pretraining, specifically using masked autoencoders, to generate effective 3D
representations from posed RGB images. Owing to the astounding success of
extending transformers to novel data modalities, we employ standard 3D Vision
Transformers to suit the unique formulation of NeRFs. We leverage NeRF's
volumetric grid as a dense input to the transformer, contrasting it with other
3D representations such as pointclouds where the information density can be
uneven, and the representation is irregular. Due to the difficulty of applying
masked autoencoders to an implicit representation, such as NeRF, we opt for
extracting an explicit representation that canonicalizes scenes across domains
by employing the camera trajectory for sampling. Our goal is made possible by
masking random patches from NeRF's radiance and density grid and employing a
standard 3D Swin Transformer to reconstruct the masked patches. In doing so,
the model can learn the semantic and spatial structure of complete scenes. We
pretrain this representation at scale on our proposed curated posed-RGB data,
totaling over 1.8 million images. Once pretrained, the encoder is used for
effective 3D transfer learning. Our novel self-supervised pretraining for
NeRFs, NeRF-MAE, scales remarkably well and improves performance on various
challenging 3D tasks. Utilizing unlabeled posed 2D data for pretraining,
NeRF-MAE significantly outperforms self-supervised 3D pretraining and NeRF
scene understanding baselines on Front3D and ScanNet datasets with an absolute
performance improvement of over 20% AP50 and 8% AP25 for 3D object detection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024. Project Page: https://nerf-mae.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Transformer</span>s Get Stable: An End-to-End Signal Propagation Theory for
  Language Models <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.09635v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.09635v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akhil Kedia, Mohd Abbas Zaidi, Sushil Khyalia, Jungho Jung, Harshith Goka, Haejun Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In spite of their huge success, transformer models remain difficult to scale
in depth. In this work, we develop a unified signal propagation theory and
provide formulae that govern the moments of the forward and backward signal
through the transformer model. Our framework can be used to understand and
mitigate vanishing/exploding gradients, rank collapse, and instability
associated with high attention scores. We also propose DeepScaleLM, an
initialization and scaling scheme that conserves unit output/gradient moments
throughout the model, enabling the training of very deep models with 1000
layers. We find that transformer models could be much deeper - our deep models
with fewer parameters outperform shallow models in Language Modeling, Speech
Translation, and Image Classification, across encoder-only, decoder-only and
encoder-decoder variants, for both Pre-LN and Post-LN transformers, for
multiple datasets and model sizes. These improvements also translate into
improved performance on downstream Question Answering tasks and improved
robustness for Image Classification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICML 2024. Source code is available at
  https://github.com/akhilkedia/TranformersGetStable. Akhil Kedia, Mohd Abbas
  Zaidi, Sushil Khyalia equal contribution</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Benchmarking Vision Language Models for Cultural Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10920v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10920v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shravan Nayak, Kanishk Jain, Rabiul Awal, Siva Reddy, Sjoerd van Steenkiste, Lisa Anne Hendricks, Karolina Stańczak, Aishwarya Agrawal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation models and vision-language pre-training have notably advanced
Vision Language Models (VLMs), enabling multimodal processing of visual and
linguistic data. However, their performance has been typically assessed on
general scene understanding - recognizing objects, attributes, and actions -
rather than cultural comprehension. This study introduces CulturalVQA, a visual
question-answering benchmark aimed at assessing VLM's geo-diverse cultural
understanding. We curate a collection of 2,378 image-question pairs with 1-5
answers per question representing cultures from 11 countries across 5
continents. The questions probe understanding of various facets of culture such
as clothing, food, drinks, rituals, and traditions. Benchmarking VLMs on
CulturalVQA, including GPT-4V and Gemini, reveals disparity in their level of
cultural understanding across regions, with strong cultural understanding
capabilities for North America while significantly lower performance for
Africa. We observe disparity in their performance across cultural facets too,
with clothing, rituals, and traditions seeing higher performances than food and
drink. These disparities help us identify areas where VLMs lack cultural
understanding and demonstrate the potential of CulturalVQA as a comprehensive
evaluation set for gauging VLM progress in understanding diverse cultures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Framework for Efficient Model Evaluation through Stratification,
  Sampling, and Estimation <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.07320v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.07320v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Riccardo Fogliato, Pratik Patil, Mathew Monfort, Pietro Perona
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model performance evaluation is a critical and expensive task in machine
learning and computer vision. Without clear guidelines, practitioners often
estimate model accuracy using a one-time completely random selection of the
data. However, by employing tailored sampling and estimation strategies, one
can obtain more precise estimates and reduce annotation costs. In this paper,
we propose a statistical framework for model evaluation that includes
stratification, sampling, and estimation components. We examine the statistical
properties of each component and evaluate their efficiency (precision). One key
result of our work is that stratification via k-means clustering based on
accurate predictions of model performance yields efficient estimators. Our
experiments on computer vision datasets show that this method consistently
provides more precise accuracy estimates than the traditional simple random
sampling, even with substantial efficiency gains of 10x. We also find that
model-assisted estimators, which leverage predictions of model accuracy on the
unlabeled portion of the dataset, are generally more efficient than the
traditional estimates based solely on the labeled data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Intrinsic Vector Heat Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09648v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09648v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Gao, Maurice Chu, Mubbasir Kapadia, Ming C. Lin, Hsueh-Ti Derek Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vector fields are widely used to represent and model flows for many science
and engineering applications. This paper introduces a novel neural network
architecture for learning tangent vector fields that are intrinsically defined
on manifold surfaces embedded in 3D. Previous approaches to learning vector
fields on surfaces treat vectors as multi-dimensional scalar fields, using
traditional scalar-valued architectures to process channels individually, thus
fail to preserve fundamental intrinsic properties of the vector field. The core
idea of this work is to introduce a trainable vector heat diffusion module to
spatially propagate vector-valued feature data across the surface, which we
incorporate into our proposed architecture that consists of vector-valued
neurons. Our architecture is invariant to rigid motion of the input, isometric
deformation, and choice of local tangent bases, and is robust to
discretizations of the surface. We evaluate our Vector Heat Network on triangle
meshes, and empirically validate its invariant properties. We also demonstrate
the effectiveness of our method on the useful industrial application of
quadrilateral mesh generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Localizing Anomalies via Multiscale Score Matching Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.00148v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.00148v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahsan Mahmood, Junier Oliva, Martin Styner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anomaly detection and localization in medical imaging remain critical
challenges in healthcare. This paper introduces Spatial-MSMA (Multiscale Score
Matching Analysis), a novel unsupervised method for anomaly localization in
volumetric brain MRIs. Building upon the MSMA framework, our approach
incorporates spatial information and conditional likelihoods to enhance anomaly
detection capabilities. We employ a flexible normalizing flow model conditioned
on patch positions and global image features to estimate patch-wise anomaly
scores. The method is evaluated on a dataset of 1,650 T1- and T2-weighted brain
MRIs from typically developing children, with simulated lesions added to the
test set. Spatial-MSMA significantly outperforms existing methods, including
reconstruction-based, generative-based, and interpretation-based approaches, in
lesion detection and segmentation tasks. Our model achieves superior
performance in both distance-based metrics (99th percentile Hausdorff Distance:
$7.05 \pm 0.61$, Mean Surface Distance: $2.10 \pm 0.43$) and component-wise
metrics (True Positive Rate: $0.83 \pm 0.01$, Positive Predictive Value: $0.96
\pm 0.01$). These results demonstrate Spatial-MSMA's potential for accurate and
interpretable anomaly localization in medical imaging, with implications for
improved diagnosis and treatment planning in clinical settings. Our code is
available at~\url{https://github.com/ahsanMah/sade/}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Diffusion-Refined VQA Annotations for Semi-Supervised Gaze Following <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.02774v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.02774v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiaomu Miao, Alexandros Graikos, Jingwei Zhang, Sounak Mondal, Minh Hoai, Dimitris Samaras
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training gaze following models requires a large number of images with gaze
target coordinates annotated by human annotators, which is a laborious and
inherently ambiguous process. We propose the first semi-supervised method for
gaze following by introducing two novel priors to the task. We obtain the first
prior using a large pretrained Visual Question Answering (VQA) model, where we
compute Grad-CAM heatmaps by `prompting' the VQA model with a gaze following
question. These heatmaps can be noisy and not suited for use in training. The
need to refine these noisy annotations leads us to incorporate a second prior.
We utilize a diffusion model trained on limited human annotations and modify
the reverse sampling process to refine the Grad-CAM heatmaps. By tuning the
diffusion process we achieve a trade-off between the human annotation prior and
the VQA heatmap prior, which retains the useful VQA prior information while
exhibiting similar properties to the training data distribution. Our method
outperforms simple pseudo-annotation generation baselines on the GazeFollow
image dataset. More importantly, our pseudo-annotation strategy, applied to a
widely used supervised gaze following model (VAT), reduces the annotation need
by 50%. Our method also performs the best on the VideoAttentionTarget dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ I Can't Believe It's Not Scene Flow! <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.04739v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.04739v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ishan Khatri, Kyle Vedder, Neehar Peri, Deva Ramanan, James Hays
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current scene flow methods broadly fail to describe motion on small objects,
and current scene flow evaluation protocols hide this failure by averaging over
many points, with most drawn larger objects. To fix this evaluation failure, we
propose a new evaluation protocol, Bucket Normalized EPE, which is class-aware
and speed-normalized, enabling contextualized error comparisons between object
types that move at vastly different speeds. To highlight current method
failures, we propose a frustratingly simple supervised scene flow baseline,
TrackFlow, built by bolting a high-quality pretrained detector (trained using
many class rebalancing techniques) onto a simple tracker, that produces
state-of-the-art performance on current standard evaluations and large
improvements over prior art on our new evaluation. Our results make it clear
that all scene flow evaluations must be class and speed aware, and supervised
scene flow methods must address point class imbalances. We release the
evaluation code publicly at
https://github.com/kylevedder/BucketedSceneFlowEval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024. Project page at https://vedder.io/trackflow</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Probabilistic Image-Driven Traffic Modeling via Remote Sensing <span class="chip">ECCV</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.05521v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.05521v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Scott Workman, Armin Hadzic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work addresses the task of modeling spatiotemporal traffic patterns
directly from overhead imagery, which we refer to as image-driven traffic
modeling. We extend this line of work and introduce a multi-modal, multi-task
transformer-based segmentation architecture that can be used to create dense
city-scale traffic models. Our approach includes a geo-temporal positional
encoding module for integrating geo-temporal context and a probabilistic
objective function for estimating traffic speeds that naturally models temporal
variations. We evaluate our method extensively using the Dynamic Traffic Speeds
(DTS) benchmark dataset and significantly improve the state-of-the-art.
Finally, we introduce the DTS++ dataset to support mobility-related location
adaptation experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>European Conference on Computer Vision (ECCV) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MVSBoost: An Efficient Point Cloud-based 3D Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13515v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13515v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Umair Haroon, Ahmad AlMughrabi, Ricardo Marques, Petia Radeva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Efficient and accurate 3D reconstruction is crucial for various applications,
including augmented and virtual reality, medical imaging, and cinematic special
effects. While traditional Multi-View Stereo (MVS) systems have been
fundamental in these applications, using neural implicit fields in implicit 3D
scene modeling has introduced new possibilities for handling complex topologies
and continuous surfaces. However, neural implicit fields often suffer from
computational inefficiencies, overfitting, and heavy reliance on data quality,
limiting their practical use. This paper presents an enhanced MVS framework
that integrates multi-view 360-degree imagery with robust camera pose
estimation via Structure from Motion (SfM) and advanced image processing for
point cloud densification, mesh reconstruction, and texturing. Our approach
significantly improves upon traditional MVS methods, offering superior accuracy
and precision as validated using Chamfer distance metrics on the Realistic
Synthetic 360 dataset. The developed MVS technique enhances the detail and
clarity of 3D reconstructions and demonstrates superior computational
efficiency and robustness in complex scene reconstruction, effectively handling
occlusions and varying viewpoints. These improvements suggest that our MVS
framework can compete with and potentially exceed current state-of-the-art
neural implicit field methods, especially in scenarios requiring real-time
processing and scalability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The work is under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MinD-3D: Reconstruct High-quality 3D objects in Human Brain <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.07485v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.07485v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianxiong Gao, Yuqian Fu, Yun Wang, Xuelin Qian, Jianfeng Feng, Yanwei Fu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce Recon3DMind, an innovative task aimed at
reconstructing 3D visuals from Functional Magnetic Resonance Imaging (fMRI)
signals, marking a significant advancement in the fields of cognitive
neuroscience and computer vision. To support this pioneering task, we present
the fMRI-Shape dataset, which includes data from 14 participants and features
360-degree videos of 3D objects to enable comprehensive fMRI signal capture
across various settings, thereby laying a foundation for future research.
Furthermore, we propose MinD-3D, a novel and effective three-stage framework
specifically designed to decode the brain's 3D visual information from fMRI
signals, demonstrating the feasibility of this challenging task. The framework
begins by extracting and aggregating features from fMRI frames through a
neuro-fusion encoder, subsequently employs a feature bridge diffusion model to
generate visual features, and ultimately recovers the 3D object via a
generative transformer decoder. We assess the performance of MinD-3D using a
suite of semantic and structural metrics and analyze the correlation between
the features extracted by our model and the visual regions of interest (ROIs)
in fMRI signals. Our findings indicate that MinD-3D not only reconstructs 3D
objects with high semantic relevance and spatial similarity but also
significantly enhances our understanding of the human brain's capabilities in
processing 3D visual information. Project page at:
https://jianxgao.github.io/MinD-3D.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ IPA-NeRF: Illusory Poisoning Attack Against Neural Radiance Fields 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11921v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11921v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenxiang Jiang, Hanwei Zhang, Shuo Zhao, Zhongwen Guo, Hao Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural Radiance Field (NeRF) represents a significant advancement in computer
vision, offering implicit neural network-based scene representation and novel
view synthesis capabilities. Its applications span diverse fields including
robotics, urban mapping, autonomous navigation, virtual reality/augmented
reality, etc., some of which are considered high-risk AI applications. However,
despite its widespread adoption, the robustness and security of NeRF remain
largely unexplored. In this study, we contribute to this area by introducing
the Illusory Poisoning Attack against Neural Radiance Fields (IPA-NeRF). This
attack involves embedding a hidden backdoor view into NeRF, allowing it to
produce predetermined outputs, i.e. illusory, when presented with the specified
backdoor view while maintaining normal performance with standard inputs. Our
attack is specifically designed to deceive users or downstream models at a
particular position while ensuring that any abnormalities in NeRF remain
undetectable from other viewpoints. Experimental results demonstrate the
effectiveness of our Illusory Poisoning Attack, successfully presenting the
desired illusory on the specified viewpoint without impacting other views.
Notably, we achieve this attack by introducing small perturbations solely to
the training set. The code can be found at
https://github.com/jiang-wenxiang/IPA-NeRF.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Not Just Change the Labels, Learn the Features: Watermarking Deep Neural
  Networks with Multi-View Data <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.10663v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.10663v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Li, Sarthak Kumar Maharana, Yunhui Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the increasing prevalence of Machine Learning as a Service (MLaaS)
platforms, there is a growing focus on deep neural network (DNN) watermarking
techniques. These methods are used to facilitate the verification of ownership
for a target DNN model to protect intellectual property. One of the most widely
employed watermarking techniques involves embedding a trigger set into the
source model. Unfortunately, existing methodologies based on trigger sets are
still susceptible to functionality-stealing attacks, potentially enabling
adversaries to steal the functionality of the source model without a reliable
means of verifying ownership. In this paper, we first introduce a novel
perspective on trigger set-based watermarking methods from a feature learning
perspective. Specifically, we demonstrate that by selecting data exhibiting
multiple features, also referred to as \emph{multi-view data}, it becomes
feasible to effectively defend functionality stealing attacks. Based on this
perspective, we introduce a novel watermarking technique based on Multi-view
dATa, called MAT, for efficiently embedding watermarks within DNNs. This
approach involves constructing a trigger set with multi-view data and
incorporating a simple feature-based regularization method for training the
source model. We validate our method across various benchmarks and demonstrate
its efficacy in defending against model extraction attacks, surpassing relevant
baselines by a significant margin. The code is available at:
\href{https://github.com/liyuxuan-github/MAT}{https://github.com/liyuxuan-github/MAT}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Per-Gaussian Embedding-Based Deformation for Deformable 3D Gaussian
  Splatting <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.03613v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.03613v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jeongmin Bae, Seoha Kim, Youngsik Yun, Hahyun Lee, Gun Bang, Youngjung Uh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As 3D Gaussian Splatting (3DGS) provides fast and high-quality novel view
synthesis, it is a natural extension to deform a canonical 3DGS to multiple
frames for representing a dynamic scene. However, previous works fail to
accurately reconstruct complex dynamic scenes. We attribute the failure to the
design of the deformation field, which is built as a coordinate-based function.
This approach is problematic because 3DGS is a mixture of multiple fields
centered at the Gaussians, not just a single coordinate-based framework. To
resolve this problem, we define the deformation as a function of per-Gaussian
embeddings and temporal embeddings. Moreover, we decompose deformations as
coarse and fine deformations to model slow and fast movements, respectively.
Also, we introduce a local smoothness regularization for per-Gaussian embedding
to improve the details in dynamic regions. Project page:
https://jeongminb.github.io/e-d3dgs/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024. Project page: https://jeongminb.github.io/e-d3dgs/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sparse Beats Dense: Rethinking Supervision in Radar-Camera Depth
  Completion <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.00844v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.00844v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huadong Li, Minhao Jing, Jiajun Liang, Haoqiang Fan, Renhe Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  It is widely believed that sparse supervision is worse than dense supervision
in the field of depth completion, but the underlying reasons for this are
rarely discussed. To this end, we revisit the task of radar-camera depth
completion and present a new method with sparse LiDAR supervision to outperform
previous dense LiDAR supervision methods in both accuracy and speed.
Specifically, when trained by sparse LiDAR supervision, depth completion models
usually output depth maps containing significant stripe-like artifacts. We find
that such a phenomenon is caused by the implicitly learned positional
distribution pattern from sparse LiDAR supervision, termed as LiDAR
Distribution Leakage (LDL) in this paper. Based on such understanding, we
present a novel Disruption-Compensation radar-camera depth completion framework
to address this issue. The Disruption part aims to deliberately disrupt the
learning of LiDAR distribution from sparse supervision, while the Compensation
part aims to leverage 3D spatial and 2D semantic information to compensate for
the information loss of previous disruptions. Extensive experimental results
demonstrate that by reducing the impact of LDL, our framework with sparse
supervision outperforms the state-of-the-art dense supervision methods with
11.6% improvement in Mean Absolute Error (MAE)} and 1.6x speedup in Frame Per
Second (FPS)}. The code is available at
https://github.com/megvii-research/Sparse-Beats-Dense.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Pyramid Diffusion for Fine 3D Large Scene Generation <span class="chip">ECCV 24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12085v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12085v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuheng Liu, Xinke Li, Xueting Li, Lu Qi, Chongshou Li, Ming-Hsuan Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models have shown remarkable results in generating 2D images and
small-scale 3D objects. However, their application to the synthesis of
large-scale 3D scenes has been rarely explored. This is mainly due to the
inherent complexity and bulky size of 3D scenery data, particularly outdoor
scenes, and the limited availability of comprehensive real-world datasets,
which makes training a stable scene diffusion model challenging. In this work,
we explore how to effectively generate large-scale 3D scenes using the
coarse-to-fine paradigm. We introduce a framework, the Pyramid Discrete
Diffusion model (PDD), which employs scale-varied diffusion models to
progressively generate high-quality outdoor scenes. Experimental results of PDD
demonstrate our successful exploration in generating 3D scenes both
unconditionally and conditionally. We further showcase the data compatibility
of the PDD model, due to its multi-scale architecture: a PDD model trained on
one dataset can be easily fine-tuned with another dataset. Code is available at
https://github.com/yuhengliu02/pyramid-discrete-diffusion.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV 24. Project page:
  https://yuheng.ink/project-page/pyramid-discrete-diffusion</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Explicit-NeRF-QA: A Quality Assessment Database for Explicit NeRF Model
  Compression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.08165v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.08165v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuke Xing, Qi Yang, Kaifa Yang, Yilin Xu, Zhu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, Neural Radiance Fields (NeRF) have demonstrated significant
advantages in representing and synthesizing 3D scenes. Explicit NeRF models
facilitate the practical NeRF applications with faster rendering speed, and
also attract considerable attention in NeRF compression due to its huge storage
cost. To address the challenge of the NeRF compression study, in this paper, we
construct a new dataset, called Explicit-NeRF-QA. We use 22 3D objects with
diverse geometries, textures, and material complexities to train four typical
explicit NeRF models across five parameter levels. Lossy compression is
introduced during the model generation, pivoting the selection of key
parameters such as hash table size for InstantNGP and voxel grid resolution for
Plenoxels. By rendering NeRF samples to processed video sequences (PVS), a
large scale subjective experiment with lab environment is conducted to collect
subjective scores from 21 viewers. The diversity of content, accuracy of mean
opinion scores (MOS), and characteristics of NeRF distortion are
comprehensively presented, establishing the heterogeneity of the proposed
dataset. The state-of-the-art objective metrics are tested in the new dataset.
Best Person correlation, which is around 0.85, is collected from the
full-reference objective metric. All tested no-reference metrics report very
poor results with 0.4 to 0.6 correlations, demonstrating the need for further
development of more robust no-reference metrics. The dataset, including NeRF
samples, source 3D objects, multiview images for NeRF generation, PVSs, MOS, is
made publicly available at the following location:
https://github.com/LittlericeChloe/Explicit_NeRF_QA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 4 figures, 2 tables, conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Image Denoising by Low-Rank Singular Vector Approximations of
  Geodesics' Gramian Matrix 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2209.13094v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2209.13094v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kelum Gajamannage, Yonggi Park, S. M. Mallikarjunaiah, Sunil Mathur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the advent of sophisticated cameras, the urge to capture high-quality
images has grown enormous. However, the noise contamination of the images
results in substandard expectations among the people; thus, image denoising is
an essential pre-processing step. While the algebraic image processing
frameworks are sometimes inefficient for this denoising task as they may
require processing of matrices of order equivalent to some power of the order
of the original image, the neural network image processing frameworks are
sometimes not robust as they require a lot of similar training samples. Thus,
here we present a manifold-based noise filtering method that mainly exploits a
few prominent singular vectors of the geodesics' Gramian matrix. Especially,
the framework partitions an image, say that of size $n \times n$, into $n^2$
overlapping patches of known size such that one patch is centered at each
pixel. Then, the prominent singular vectors, of the Gramian matrix of size $n^2
\times n^2$ of the geodesic distances computed over the patch space, are
utilized to denoise the image. Here, the prominent singular vectors are
revealed by efficient, but diverse, approximation techniques, rather than
explicitly computing them using frameworks like Singular Value Decomposition
(SVD) which encounters $\mathcal{O}(n^6)$ operations. Finally, we compare both
computational time and the noise filtration performance of the proposed
denoising algorithm with and without singular vector approximation techniques.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 3 figures, submitted to ACM Transactions on Architecture
  and Code Optimization</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Powerful and Flexible: Personalized Text-to-Image Generation via
  Reinforcement Learning <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06642v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06642v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fanyue Wei, Wei Zeng, Zhenyang Li, Dawei Yin, Lixin Duan, Wen Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Personalized text-to-image models allow users to generate varied styles of
images (specified with a sentence) for an object (specified with a set of
reference images). While remarkable results have been achieved using
diffusion-based generation models, the visual structure and details of the
object are often unexpectedly changed during the diffusion process. One major
reason is that these diffusion-based approaches typically adopt a simple
reconstruction objective during training, which can hardly enforce appropriate
structural consistency between the generated and the reference images. To this
end, in this paper, we design a novel reinforcement learning framework by
utilizing the deterministic policy gradient method for personalized
text-to-image generation, with which various objectives, differential or even
non-differential, can be easily incorporated to supervise the diffusion models
to improve the quality of the generated images. Experimental results on
personalized text-to-image generation benchmark datasets demonstrate that our
proposed approach outperforms existing state-of-the-art methods by a large
margin on visual fidelity while maintaining text-alignment. Our code is
available at: \url{https://github.com/wfanyue/DPG-T2I-Personalization}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Training for Multilingual Visual Speech Recognition:
  <span class="highlight-title">Pre-train</span>ing with Discretized Visual Speech Representation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.09802v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.09802v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minsu Kim, Jeong Hun Yeo, Se Jin Park, Hyeongseop Rha, Yong Man Ro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores sentence-level multilingual Visual Speech Recognition
(VSR) that can recognize different languages with a single trained model. As
the massive multilingual modeling of visual data requires huge computational
costs, we propose a novel training strategy, processing with visual speech
units. Motivated by the recent success of the audio speech unit, we propose to
use a visual speech unit that can be obtained by discretizing the visual speech
features extracted from the self-supervised visual speech model. Through
analysis, we verify that the visual speech units mainly contain viseme
information while suppressing non-linguistic information. By using the visual
speech units as the inputs of our system, we propose to pre-train a VSR model
to predict corresponding text outputs on multilingual data constructed by
merging several VSR databases. As both the inputs (i.e., visual speech units)
and outputs (i.e., text) are discrete, we can greatly improve the training
efficiency compared to the standard VSR training. Specifically, the input data
size is reduced to 0.016% of the original video inputs. In order to complement
the insufficient visual information in speech recognition, we apply curriculum
learning where the inputs of the system begin with audio-visual speech units
and gradually change to visual speech units. After pre-training, the model is
finetuned on continuous features. We set new state-of-the-art multilingual VSR
performances by achieving comparable performances to the previous
language-specific VSR models, with a single trained model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACMMM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Real-time 3D-aware Portrait Editing from a Single Image <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.14000v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.14000v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qingyan Bai, Zifan Shi, Yinghao Xu, Hao Ouyang, Qiuyu Wang, Ceyuan Yang, Xuan Wang, Gordon Wetzstein, Yujun Shen, Qifeng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work presents 3DPE, a practical method that can efficiently edit a face
image following given prompts, like reference images or text descriptions, in a
3D-aware manner. To this end, a lightweight module is distilled from a 3D
portrait generator and a text-to-image model, which provide prior knowledge of
face geometry and superior editing capability, respectively. Such a design
brings two compelling advantages over existing approaches. First, our method
achieves real-time editing with a feedforward network (i.e., ~0.04s per image),
over 100x faster than the second competitor. Second, thanks to the powerful
priors, our module could focus on the learning of editing-related variations,
such that it manages to handle various types of editing simultaneously in the
training phase and further supports fast adaptation to user-specified
customized types of editing during inference (e.g., with ~5min fine-tuning per
style).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024 camera-ready version. Project page:
  https://github.com/EzioBy/3dpe</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Which Model Generated This Image? A Model-Agnostic Approach for Origin
  Attribution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.02697v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.02697v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fengyuan Liu, Haochen Luo, Yiming Li, Philip Torr, Jindong Gu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent progress in visual generative models enables the generation of
high-quality images. To prevent the misuse of generated images, it is important
to identify the origin model that generates them. In this work, we study the
origin attribution of generated images in a practical setting where only a few
images generated by a source model are available and the source model cannot be
accessed. The goal is to check if a given image is generated by the source
model. We first formulate this problem as a few-shot one-class classification
task. To solve the task, we propose OCC-CLIP, a CLIP-based framework for
few-shot one-class classification, enabling the identification of an image's
source model, even among multiple candidates. Extensive experiments
corresponding to various generative models verify the effectiveness of our
OCC-CLIP framework. Furthermore, an experiment based on the recently released
DALL-E 3 API verifies the real-world applicability of our solution.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.14627v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.14627v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuedong Chen, Haofei Xu, Chuanxia Zheng, Bohan Zhuang, Marc Pollefeys, Andreas Geiger, Tat-Jen Cham, Jianfei Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce MVSplat, an efficient model that, given sparse multi-view images
as input, predicts clean feed-forward 3D Gaussians. To accurately localize the
Gaussian centers, we build a cost volume representation via plane sweeping,
where the cross-view feature similarities stored in the cost volume can provide
valuable geometry cues to the estimation of depth. We also learn other Gaussian
primitives' parameters jointly with the Gaussian centers while only relying on
photometric supervision. We demonstrate the importance of the cost volume
representation in learning feed-forward Gaussians via extensive experimental
evaluations. On the large-scale RealEstate10K and ACID benchmarks, MVSplat
achieves state-of-the-art performance with the fastest feed-forward inference
speed (22~fps). More impressively, compared to the latest state-of-the-art
method pixelSplat, MVSplat uses $10\times$ fewer parameters and infers more
than $2\times$ faster while providing higher appearance and geometry quality as
well as better cross-dataset generalization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV2024, Project page: https://donydchen.github.io/mvsplat, Code:
  https://github.com/donydchen/mvsplat</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-Label Continual Learning for the Medical Domain: A Novel Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.06859v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.06859v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marina Ceccon, Davide Dalle Pezze, Alessandro Fabris, Gian Antonio Susto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the critical importance of the medical domain in Deep Learning, most
of the research in this area solely focuses on training models in static
environments. It is only in recent years that research has begun to address
dynamic environments and tackle the Catastrophic Forgetting problem through
Continual Learning (CL) techniques. Previous studies have primarily focused on
scenarios such as Domain Incremental Learning and Class Incremental Learning,
which do not fully capture the complexity of real-world applications.
Therefore, in this work, we propose a novel benchmark combining the challenges
of new class arrivals and domain shifts in a single framework, by considering
the New Instances and New Classes (NIC) scenario. This benchmark aims to model
a realistic CL setting for the multi-label classification problem in medical
imaging. Additionally, it encompasses a greater number of tasks compared to
previously tested scenarios. Specifically, our benchmark consists of two
datasets (NIH and CXP), nineteen classes, and seven tasks, a stream longer than
the previously tested ones. To solve common challenges (e.g., the task
inference problem) found in the CIL and NIC scenarios, we propose a novel
approach called Replay Consolidation with Label Propagation (RCLP). Our method
surpasses existing approaches, exhibiting superior performance with minimal
forgetting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SPAMming Labels: Efficient Annotations for the Trackers of Tomorrow <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.11426v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.11426v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Orcun Cetintas, Tim Meinhardt, Guillem Brasó, Laura Leal-Taixé
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Increasing the annotation efficiency of trajectory annotations from videos
has the potential to enable the next generation of data-hungry tracking
algorithms to thrive on large-scale datasets. Despite the importance of this
task, there are currently very few works exploring how to efficiently label
tracking datasets comprehensively. In this work, we introduce SPAM, a video
label engine that provides high-quality labels with minimal human intervention.
SPAM is built around two key insights: i) most tracking scenarios can be easily
resolved. To take advantage of this, we utilize a pre-trained model to generate
high-quality pseudo-labels, reserving human involvement for a smaller subset of
more difficult instances; ii) handling the spatiotemporal dependencies of track
annotations across time can be elegantly and efficiently formulated through
graphs. Therefore, we use a unified graph formulation to address the annotation
of both detections and identity association for tracks across time. Based on
these insights, SPAM produces high-quality annotations with a fraction of
ground truth labeling cost. We demonstrate that trackers trained on SPAM labels
achieve comparable performance to those trained on human annotations while
requiring only $3-20\%$ of the human labeling effort. Hence, SPAM paves the way
towards highly efficient labeling of large-scale tracking datasets. We release
all models and code.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UMBRAE: Unified Multimodal Brain Decoding <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.07202v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.07202v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weihao Xia, Raoul de Charette, Cengiz Öztireli, Jing-Hao Xue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address prevailing challenges of the brain-powered research, departing
from the observation that the literature hardly recover accurate spatial
information and require subject-specific models. To address these challenges,
we propose UMBRAE, a unified multimodal decoding of brain signals. First, to
extract instance-level conceptual and spatial details from neural signals, we
introduce an efficient universal brain encoder for multimodal-brain alignment
and recover object descriptions at multiple levels of granularity from
subsequent multimodal large language model (MLLM). Second, we introduce a
cross-subject training strategy mapping subject-specific features to a common
feature space. This allows a model to be trained on multiple subjects without
extra resources, even yielding superior results compared to subject-specific
models. Further, we demonstrate this supports weakly-supervised adaptation to
new subjects, with only a fraction of the total training data. Experiments
demonstrate that UMBRAE not only achieves superior results in the newly
introduced tasks but also outperforms methods in well established tasks. To
assess our method, we construct and share with the community a comprehensive
brain understanding benchmark BrainHub. Our code and benchmark are available at
https://weihaox.github.io/UMBRAE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024. Project: https://weihaox.github.io/UMBRAE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Omni-Recon: Harnessing Image-based Rendering for General-Purpose Neural
  Radiance Fields <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.11131v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.11131v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yonggan Fu, Huaizhi Qu, Zhifan Ye, Chaojian Li, Kevin Zhao, Yingyan Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent breakthroughs in Neural Radiance Fields (NeRFs) have sparked
significant demand for their integration into real-world 3D applications.
However, the varied functionalities required by different 3D applications often
necessitate diverse NeRF models with various pipelines, leading to tedious NeRF
training for each target task and cumbersome trial-and-error experiments.
Drawing inspiration from the generalization capability and adaptability of
emerging foundation models, our work aims to develop one general-purpose NeRF
for handling diverse 3D tasks. We achieve this by proposing a framework called
Omni-Recon, which is capable of (1) generalizable 3D reconstruction and
zero-shot multitask scene understanding, and (2) adaptability to diverse
downstream 3D applications such as real-time rendering and scene editing. Our
key insight is that an image-based rendering pipeline, with accurate geometry
and appearance estimation, can lift 2D image features into their 3D
counterparts, thus extending widely explored 2D tasks to the 3D world in a
generalizable manner. Specifically, our Omni-Recon features a general-purpose
NeRF model using image-based rendering with two decoupled branches: one complex
transformer-based branch that progressively fuses geometry and appearance
features for accurate geometry estimation, and one lightweight branch for
predicting blending weights of source views. This design achieves
state-of-the-art (SOTA) generalizable 3D surface reconstruction quality with
blending weights reusable across diverse tasks for zero-shot multitask scene
understanding. In addition, it can enable real-time rendering after baking the
complex geometry branch into meshes, swift adaptation to achieve SOTA
generalizable 3D understanding performance, and seamless integration with 2D
diffusion models for text-guided 3D editing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Memory-Efficient Fine-Tuning for Quantized Diffusion Model <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.04339v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.04339v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyogon Ryu, Seohyun Lim, Hyunjung Shim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The emergence of billion-parameter diffusion models such as Stable Diffusion
XL, Imagen, and DALL-E 3 has significantly propelled the domain of generative
AI. However, their large-scale architecture presents challenges in fine-tuning
and deployment due to high resource demands and slow inference speed. This
paper explores the relatively unexplored yet promising realm of fine-tuning
quantized diffusion models. Our analysis revealed that the baseline neglects
the distinct patterns in model weights and the different roles throughout time
steps when finetuning the diffusion model. To address these limitations, we
introduce a novel memory-efficient fine-tuning method specifically designed for
quantized diffusion models, dubbed TuneQDM. Our approach introduces
quantization scales as separable functions to consider inter-channel weight
patterns. Then, it optimizes these scales in a timestep-specific manner for
effective reflection of the role of each time step. TuneQDM achieves
performance on par with its full-precision counterpart while simultaneously
offering significant memory efficiency. Experimental results demonstrate that
our method consistently outperforms the baseline in both single-/multi-subject
generations, exhibiting high subject fidelity and prompt fidelity comparable to
the full precision model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV2024. Code will be released at
  https://github.com/ugonfor/TuneQDM</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RingID: Rethinking Tree-Ring Watermarking for Enhanced Multi-Key
  Identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.14055v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.14055v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hai Ci, Pei Yang, Yiren Song, Mike Zheng Shou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We revisit Tree-Ring Watermarking, a recent diffusion model watermarking
method that demonstrates great robustness to various attacks. We conduct an
in-depth study on it and reveal that the distribution shift unintentionally
introduced by the watermarking process, apart from watermark pattern matching,
contributes to its exceptional robustness. Our investigation further exposes
inherent flaws in its original design, particularly in its ability to identify
multiple distinct keys, where distribution shift offers no assistance. Based on
these findings and analysis, we present RingID for enhanced multi-key
identification. It consists of a novel multi-channel heterogeneous watermarking
approach designed to seamlessly amalgamate distinctive advantages from diverse
watermarks. Coupled with a series of suggested enhancements, RingID exhibits
substantial advancements in multi-key identification. Github Page:
https://github.com/showlab/RingID
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Open-Canopy: A Country-Scale Benchmark for Canopy Height Estimation at
  Very High Resolution <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09392v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09392v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fajwel Fogel, Yohann Perron, Nikola Besic, Laurent Saint-André, Agnès Pellissier-Tanon, Martin Schwartz, Thomas Boudras, Ibrahim Fayad, Alexandre d'Aspremont, Loic Landrieu, Philippe Ciais
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating canopy height and canopy height change at meter resolution from
satellite imagery has numerous applications, such as monitoring forest health,
logging activities, wood resources, and carbon stocks. However, many existing
forest datasets are based on commercial or closed data sources, restricting the
reproducibility and evaluation of new approaches. To address this gap, we
introduce Open-Canopy, the first open-access and country-scale benchmark for
very high resolution (1.5 m) canopy height estimation. Covering more than
87,000 km$^2$ across France, Open-Canopy combines SPOT satellite imagery with
high resolution aerial LiDAR data. We also propose Open-Canopy-$\Delta$, the
first benchmark for canopy height change detection between two images taken at
different years, a particularly challenging task even for recent models. To
establish a robust foundation for these benchmarks, we evaluate a comprehensive
list of state-of-the-art computer vision models for canopy height estimation.
The dataset and associated codes can be accessed at
https://github.com/fajwel/Open-Canopy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 8 figures, Submitted to NeurIPS 2024 Datasets and
  Benchmarks Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BAM-DETR: Boundary-Aligned Moment Detection <span class="highlight-title">Transformer</span> for Temporal
  Sentence Grounding in Videos <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.00083v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.00083v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pilhyeon Lee, Hyeran Byun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Temporal sentence grounding aims to localize moments relevant to a language
description. Recently, DETR-like approaches achieved notable progress by
predicting the center and length of a target moment. However, they suffer from
the issue of center misalignment raised by the inherent ambiguity of moment
centers, leading to inaccurate predictions. To remedy this problem, we propose
a novel boundary-oriented moment formulation. In our paradigm, the model no
longer needs to find the precise center but instead suffices to predict any
anchor point within the interval, from which the boundaries are directly
estimated. Based on this idea, we design a boundary-aligned moment detection
transformer, equipped with a dual-pathway decoding process. Specifically, it
refines the anchor and boundaries within parallel pathways using global and
boundary-focused attention, respectively. This separate design allows the model
to focus on desirable regions, enabling precise refinement of moment
predictions. Further, we propose a quality-based ranking method, ensuring that
proposals with high localization qualities are prioritized over incomplete
ones. Experiments on three benchmarks validate the effectiveness of the
proposed methods. The code is available at
https://github.com/Pilhyeon/BAM-DETR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Audio-driven Talking Face Generation with Stabilized Synchronization
  Loss <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.09368v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.09368v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dogucan Yaman, Fevziye Irem Eyiokur, Leonard Bärmann, Hazim Kemal Ekenel, Alexander Waibel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Talking face generation aims to create realistic videos with accurate lip
synchronization and high visual quality, using given audio and reference video
while preserving identity and visual characteristics. In this paper, we start
by identifying several issues with existing synchronization learning methods.
These involve unstable training, lip synchronization, and visual quality issues
caused by lip-sync loss, SyncNet, and lip leaking from the identity reference.
To address these issues, we first tackle the lip leaking problem by introducing
a silent-lip generator, which changes the lips of the identity reference to
alleviate leakage. We then introduce stabilized synchronization loss and
AVSyncNet to overcome problems caused by lip-sync loss and SyncNet. Experiments
show that our model outperforms state-of-the-art methods in both visual quality
and lip synchronization. Comprehensive ablation studies further validate our
individual contributions and their cohesive effects.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FreeStyle: Free Lunch for Text-guided Style Transfer using Diffusion
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.15636v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.15636v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Feihong He, Gang Li, Mengyuan Zhang, Leilei Yan, Lingyu Si, Fanzhang Li, Li Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid development of generative diffusion models has significantly
advanced the field of style transfer. However, most current style transfer
methods based on diffusion models typically involve a slow iterative
optimization process, e.g., model fine-tuning and textual inversion of style
concept. In this paper, we introduce FreeStyle, an innovative style transfer
method built upon a pre-trained large diffusion model, requiring no further
optimization. Besides, our method enables style transfer only through a text
description of the desired style, eliminating the necessity of style images.
Specifically, we propose a dual-stream encoder and single-stream decoder
architecture, replacing the conventional U-Net in diffusion models. In the
dual-stream encoder, two distinct branches take the content image and style
text prompt as inputs, achieving content and style decoupling. In the decoder,
we further modulate features from the dual streams based on a given content
image and the corresponding style text prompt for precise style transfer. Our
experimental results demonstrate high-quality synthesis and fidelity of our
method across various content images and style text prompts. Compared with
state-of-the-art methods that require training, our FreeStyle approach notably
reduces the computational burden by thousands of iterations, while achieving
comparable or superior performance across multiple evaluation metrics including
CLIP Aesthetic Score, CLIP Score, and Preference. We have released the code
anonymously at:
\href{https://anonymous.4open.science/r/FreeStyleAnonymous-0F9B}
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cracking the neural code for word recognition in convolutional neural
  networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.06159v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.06159v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aakash Agrawal, Stanislas Dehaene
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning to read places a strong challenge on the visual system. Years of
expertise lead to a remarkable capacity to separate highly similar letters and
encode their relative positions, thus distinguishing words such as FORM and
FROM, invariantly over a large range of sizes and absolute positions. How
neural circuits achieve invariant word recognition remains unknown. Here, we
address this issue by training deep neural network models to recognize written
words and then analyzing how reading-specialized units emerge and operate
across different layers of the network. With literacy, a small subset of units
becomes specialized for word recognition in the learned script, similar to the
"visual word form area" of the human brain. We show that these units are
sensitive to specific letter identities and their distance from the blank space
at the left or right of a word, thus acting as "space bigrams". These units
specifically encode ordinal positions and operate by pooling across low and
high-frequency detector units from early layers of the network. The proposed
neural code provides a mechanistic insight into how information on letter
identity and position is extracted and allow for invariant word recognition,
and leads to predictions for reading behavior, error patterns, and the
neurophysiology of reading.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>33 pages, 6 main figures, 4 supplementary figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PALM: Predicting Actions through Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.17944v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.17944v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sanghwan Kim, Daoji Huang, Yongqin Xian, Otmar Hilliges, Luc Van Gool, Xi Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding human activity is a crucial yet intricate task in egocentric
vision, a field that focuses on capturing visual perspectives from the camera
wearer's viewpoint. Traditional methods heavily rely on representation learning
that is trained on a large amount of video data. However, a major challenge
arises from the difficulty of obtaining effective video representation. This
difficulty stems from the complex and variable nature of human activities,
which contrasts with the limited availability of data. In this study, we
introduce PALM, an approach that tackles the task of long-term action
anticipation, which aims to forecast forthcoming sequences of actions over an
extended period. Our method PALM incorporates an action recognition model to
track previous action sequences and a vision-language model to articulate
relevant environmental details. By leveraging the context provided by these
past events, we devise a prompting strategy for action anticipation using large
language models (LLMs). Moreover, we implement maximal marginal relevance for
example selection to facilitate in-context learning of the LLMs. Our
experimental results demonstrate that PALM surpasses the state-of-the-art
methods in the task of long-term action anticipation on the Ego4D benchmark. We
further validate PALM on two additional benchmarks, affirming its capacity for
generalization across intricate activities with different sets of taxonomies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TransCAD: A Hierarchical <span class="highlight-title">Transformer</span> for CAD Sequence Inference from
  Point Clouds 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12702v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12702v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elona Dupont, Kseniya Cherenkova, Dimitrios Mallis, Gleb Gusev, Anis Kacem, Djamila Aouada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D reverse engineering, in which a CAD model is inferred given a 3D scan of a
physical object, is a research direction that offers many promising practical
applications. This paper proposes TransCAD, an end-to-end transformer-based
architecture that predicts the CAD sequence from a point cloud. TransCAD
leverages the structure of CAD sequences by using a hierarchical learning
strategy. A loop refiner is also introduced to regress sketch primitive
parameters. Rigorous experimentation on the DeepCAD and Fusion360 datasets show
that TransCAD achieves state-of-the-art results. The result analysis is
supported with a proposed metric for CAD sequence, the mean Average Precision
of CAD Sequence, that addresses the limitations of existing metrics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SynthCLIP: Are We Ready for a Fully Synthetic CLIP Training? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.01832v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.01832v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hasan Abed Al Kader Hammoud, Hani Itani, Fabio Pizzati, Philip Torr, Adel Bibi, Bernard Ghanem
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present SynthCLIP, a CLIP model trained on entirely synthetic text-image
pairs. Leveraging recent text-to-image (TTI) networks and large language models
(LLM), we generate synthetic datasets of images and corresponding captions at
scale, with no human intervention. In this work, we provide an analysis on CLIP
models trained on synthetic data. We provide insights on the data generation
strategy, number of samples required, scaling trends, and resulting properties.
We also introduce SynthCI-30M, a purely synthetic dataset comprising 30 million
captioned images. Our code, trained models, and data, are released as open
source at https://github.com/hammoudhasan/SynthCLIP
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SWinGS: Sliding Windows for Dynamic 3D Gaussian Splatting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.13308v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.13308v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Richard Shaw, Michal Nazarczuk, Jifei Song, Arthur Moreau, Sibi Catley-Chandar, Helisa Dhamo, Eduardo Perez-Pellitero
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Novel view synthesis has shown rapid progress recently, with methods capable
of producing increasingly photorealistic results. 3D Gaussian Splatting has
emerged as a promising method, producing high-quality renderings of scenes and
enabling interactive viewing at real-time frame rates. However, it is limited
to static scenes. In this work, we extend 3D Gaussian Splatting to reconstruct
dynamic scenes. We model a scene's dynamics using dynamic MLPs, learning
deformations from temporally-local canonical representations to per-frame 3D
Gaussians. To disentangle static and dynamic regions, tuneable parameters weigh
each Gaussian's respective MLP parameters, improving the dynamics modelling of
imbalanced scenes. We introduce a sliding window training strategy that
partitions the sequence into smaller manageable windows to handle arbitrary
length scenes while maintaining high rendering quality. We propose an adaptive
sampling strategy to determine appropriate window size hyperparameters based on
the scene's motion, balancing training overhead with visual quality. Training a
separate dynamic 3D Gaussian model for each sliding window allows the canonical
representation to change, enabling the reconstruction of scenes with
significant geometric changes. Temporal consistency is enforced using a
fine-tuning step with self-supervising consistency loss on randomly sampled
novel views. As a result, our method produces high-quality renderings of
general dynamic scenes with competitive quantitative performance, which can be
viewed in real-time in our dynamic interactive viewer.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SkipcrossNets: Adaptive Skip-cross Fusion for Road Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.12863v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.12863v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Gong, Xinyu Zhang, Hao Liu, Xinmin Jiang, Zhiwei Li, Xin Gao, Lei Lin, Dafeng Jin, Jun Li, Huaping Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-modal fusion is increasingly being used for autonomous driving tasks,
as different modalities provide unique information for feature extraction.
However, the existing two-stream networks are only fused at a specific network
layer, which requires a lot of manual attempts to set up. As the CNN goes
deeper, the two modal features become more and more advanced and abstract, and
the fusion occurs at the feature level with a large gap, which can easily hurt
the performance. To reduce the loss of height and depth information during the
process of projecting point clouds into 2D space, we utilize calibration
parameters to project the point cloud into Altitude Difference Images (ADIs),
which exhibit more distinct road features. In this study, we propose a novel
fusion architecture called Skip-cross Networks (SkipcrossNets), which combine
adaptively ADIs and camera images without being bound to a certain fusion
epoch. Specifically, skip-cross fusion strategy connects each layer to each
layer in a feed-forward manner, and for each layer, the feature maps of all
previous layers are used as input and its own feature maps are used as input to
all subsequent layers for the other modality, enhancing feature propagation and
multi-modal features fusion. This strategy facilitates selection of the most
similar feature layers from two modalities, enhancing feature reuse and
providing complementary effects for sparse point cloud features. The advantages
of skip-cross fusion strategy is demonstrated through application to the KITTI
and A2D2 datasets, achieving a MaxF score of 96.85% on KITTI and an F1 score of
84.84% on A2D2. The model parameters require only 2.33 MB of memory at a speed
of 68.24 FPS, which can be viable for mobile terminals and embedded devices.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Point-JEPA: A Joint Embedding Predictive Architecture for
  <span class="highlight-title">Self-Supervised</span> Learning on Point Cloud 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.16432v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.16432v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayumu Saito, Jiju Poovvancheri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in self-supervised learning in the point cloud domain
have demonstrated significant potential. However, these methods often suffer
from drawbacks, including lengthy pre-training time, the necessity of
reconstruction in the input space, or the necessity of additional modalities.
In order to address these issues, we introduce Point-JEPA, a joint embedding
predictive architecture designed specifically for point cloud data. To this
end, we introduce a sequencer that orders point cloud tokens to efficiently
compute and utilize tokens proximity based on their indices during target and
context selection. The sequencer also allows shared computations of the tokens
proximity between context and target selection, further improving the
efficiency. Experimentally, our method achieves competitive results with
state-of-the-art methods while avoiding the reconstruction in the input space
or additional modality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Self-Supervised</span> Learning with Generative Adversarial Networks for
  Electron Microscopy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.18286v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.18286v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bashir Kazimi, Karina Ruzaeva, Stefan Sandfeld
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we explore the potential of self-supervised learning with
Generative Adversarial Networks (GANs) for electron microscopy datasets. We
show how self-supervised pretraining facilitates efficient fine-tuning for a
spectrum of downstream tasks, including semantic segmentation, denoising, noise
\& background removal, and super-resolution. Experimentation with varying model
complexities and receptive field sizes reveals the remarkable phenomenon that
fine-tuned models of lower complexity consistently outperform more complex
models with random weight initialization. We demonstrate the versatility of
self-supervised pretraining across various downstream tasks in the context of
electron microscopy, allowing faster convergence and better performance. We
conclude that self-supervised pretraining serves as a powerful catalyst, being
especially advantageous when limited annotated data are available and efficient
scaling of computational cost is important.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PYRA: Parallel Yielding Re-Activation for Training-Inference Efficient
  Task Adaptation <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.09192v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.09192v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yizhe Xiong, Hui Chen, Tianxiang Hao, Zijia Lin, Jungong Han, Yuesong Zhang, Guoxin Wang, Yongjun Bao, Guiguang Ding
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, the scale of transformers has grown rapidly, which introduces
considerable challenges in terms of training overhead and inference efficiency
in the scope of task adaptation. Existing works, namely Parameter-Efficient
Fine-Tuning (PEFT) and model compression, have separately investigated the
challenges. However, PEFT cannot guarantee the inference efficiency of the
original backbone, especially for large-scale models. Model compression
requires significant training costs for structure searching and re-training.
Consequently, a simple combination of them cannot guarantee accomplishing both
training efficiency and inference efficiency with minimal costs. In this paper,
we propose a novel Parallel Yielding Re-Activation (PYRA) method for such a
challenge of training-inference efficient task adaptation. PYRA first utilizes
parallel yielding adaptive weights to comprehensively perceive the data
distribution in downstream tasks. A re-activation strategy for token modulation
is then applied for tokens to be merged, leading to calibrated token features.
Extensive experiments demonstrate that PYRA outperforms all competing methods
under both low compression rate and high compression rate, demonstrating its
effectiveness and superiority in maintaining both training efficiency and
inference efficiency for large-scale foundation models. Our code is available
at https://github.com/THU-MIG/PYRA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 4 figures, Accepted by ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Labeled Data Selection for Category Discovery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04898v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04898v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bingchen Zhao, Nico Lang, Serge Belongie, Oisin Mac Aodha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Category discovery methods aim to find novel categories in unlabeled visual
data. At training time, a set of labeled and unlabeled images are provided,
where the labels correspond to the categories present in the images. The
labeled data provides guidance during training by indicating what types of
visual properties and features are relevant for performing discovery in the
unlabeled data. As a result, changing the categories present in the labeled set
can have a large impact on what is ultimately discovered in the unlabeled set.
Despite its importance, the impact of labeled data selection has not been
explored in the category discovery literature to date. We show that changing
the labeled data can significantly impact discovery performance. Motivated by
this, we propose two new approaches for automatically selecting the most
suitable labeled data based on the similarity between the labeled and unlabeled
data. Our observation is that, unlike in conventional supervised transfer
learning, the best labeled is neither too similar, nor too dissimilar, to the
unlabeled categories. Our resulting approaches obtains state-of-the-art
discovery performance across a range of challenging fine-grained benchmark
datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Continual Forgetting for <span class="highlight-title">Pre-train</span>ed Vision Models <span class="chip">CVPR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.11530v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.11530v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongbo Zhao, Bolin Ni, Haochen Wang, Junsong Fan, Fei Zhu, Yuxi Wang, Yuntao Chen, Gaofeng Meng, Zhaoxiang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For privacy and security concerns, the need to erase unwanted information
from pre-trained vision models is becoming evident nowadays. In real-world
scenarios, erasure requests originate at any time from both users and model
owners. These requests usually form a sequence. Therefore, under such a
setting, selective information is expected to be continuously removed from a
pre-trained model while maintaining the rest. We define this problem as
continual forgetting and identify two key challenges. (i) For unwanted
knowledge, efficient and effective deleting is crucial. (ii) For remaining
knowledge, the impact brought by the forgetting procedure should be minimal. To
address them, we propose Group Sparse LoRA (GS-LoRA). Specifically, towards
(i), we use LoRA modules to fine-tune the FFN layers in Transformer blocks for
each forgetting task independently, and towards (ii), a simple group sparse
regularization is adopted, enabling automatic selection of specific LoRA groups
and zeroing out the others. GS-LoRA is effective, parameter-efficient,
data-efficient, and easy to implement. We conduct extensive experiments on face
recognition, object detection and image classification and demonstrate that
GS-LoRA manages to forget specific classes with minimal impact on other
classes. Codes will be released on \url{https://github.com/bjzhb666/GS-LoRA}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2024, latest version ahead of carema ready version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On <span class="highlight-title">Pretrain</span>ing Data Diversity for <span class="highlight-title">Self-Supervised</span> Learning <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.13808v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.13808v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hasan Abed Al Kader Hammoud, Tuhin Das, Fabio Pizzati, Philip Torr, Adel Bibi, Bernard Ghanem
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We explore the impact of training with more diverse datasets, characterized
by the number of unique samples, on the performance of self-supervised learning
(SSL) under a fixed computational budget. Our findings consistently demonstrate
that increasing pretraining data diversity enhances SSL performance, albeit
only when the distribution distance to the downstream data is minimal. Notably,
even with an exceptionally large pretraining data diversity achieved through
methods like web crawling or diffusion-generated data, among other ways, the
distribution shift remains a challenge. Our experiments are comprehensive with
seven SSL methods using large-scale datasets such as ImageNet and YFCC100M
amounting to over 200 GPU days. Code and trained models are available at
https://github.com/hammoudhasan/DiversitySSL
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Realistic Unsupervised CLIP Fine-tuning with Universal Entropy
  Optimization <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.12919v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.12919v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian Liang, Lijun Sheng, Zhengbo Wang, Ran He, Tieniu Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The emergence of vision-language models, such as CLIP, has spurred a
significant research effort towards their application for downstream supervised
learning tasks. Although some previous studies have explored the unsupervised
fine-tuning of CLIP, they often rely on prior knowledge in the form of class
names associated with ground truth labels. This paper explores a realistic
unsupervised fine-tuning scenario, considering the presence of
out-of-distribution samples from unknown classes within the unlabeled data. In
particular, we focus on simultaneously enhancing out-of-distribution detection
and the recognition of instances associated with known classes. To tackle this
problem, we present a simple, efficient, and effective approach called
Universal Entropy Optimization (UEO). UEO leverages sample-level confidence to
approximately minimize the conditional entropy of confident instances and
maximize the marginal entropy of less confident instances. Apart from
optimizing the textual prompt, UEO incorporates optimization of channel-wise
affine transformations within the visual branch of CLIP. Extensive experiments
across 15 domains and 4 different types of prior knowledge validate the
effectiveness of UEO compared to baseline methods. The code is publicly
available at \url{https://github.com/tim-learn/UEO}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024 Highlight</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> of Artificial Intelligence in Gait-Based Neurodegenerative
  Disease Diagnosis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.13082v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.13082v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haocong Rao, Minlin Zeng, Xuejiao Zhao, Chunyan Miao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent years have witnessed an increasing global population affected by
neurodegenerative diseases (NDs), which traditionally require extensive
healthcare resources and human effort for medical diagnosis and monitoring. As
a crucial disease-related motor symptom, human gait can be exploited to
characterize different NDs. The current advances in artificial intelligence
(AI) models enable automatic gait analysis for NDs identification and
classification, opening a new avenue to facilitate faster and more
cost-effective diagnosis of NDs. In this paper, we provide a comprehensive
survey on recent progress of machine learning and deep learning based AI
techniques applied to diagnosis of five typical NDs through gait. We provide an
overview of the process of AI-assisted NDs diagnosis, and present a systematic
taxonomy of existing gait data and AI models. Meanwhile, a novel quality
evaluation criterion is proposed to quantitatively assess the quality of
existing studies. Through an extensive review and analysis of 164 studies, we
identify and discuss the challenges, potential solutions, and future directions
in this field. Finally, we envision the prospective utilization of 3D skeleton
data for human gait representation and the development of more efficient AI
models for NDs diagnosis. We provide a public resource repository to track and
facilitate developments in this emerging field:
https://github.com/Kali-Hac/AI4NDD-Survey.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Article: 46 pages, 9 figures, 7 tables, citing 274 papers. Appendix:
  29 pages, 1 figure, 5 tables. A up-to-date resource (papers, data, etc.) of
  this survey (AI4NDD) is provided at https://github.com/Kali-Hac/AI4NDD-Survey</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multiscale Feature Learning Using Co-Tuplet Loss for Offline Handwritten
  Signature Verification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.00428v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.00428v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fu-Hsien Huang, Hsin-Min Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Handwritten signature verification, crucial for legal and financial
institutions, faces challenges including inter-writer similarity, intra-writer
variations, and limited signature samples. To address these, we introduce a
MultiScale Signature feature learning Network (MS-SigNet) with a novel metric
learning loss called the co-tuplet loss, designed for offline handwritten
signature verification. MS-SigNet learns both global and regional signature
features from multiple spatial scales, enhancing feature discrimination. This
approach effectively distinguishes genuine signatures from skilled forgeries by
capturing overall strokes and detailed local differences. The co-tuplet loss,
focusing on multiple positive and negative examples, overcomes the limitations
of typical metric learning losses by addressing inter-writer similarity and
intra-writer variations and emphasizing informative examples. We also present
HanSig, a large-scale Chinese signature dataset (available at
https://github.com/hsinmin/HanSig) to support robust system development.
Experimental results on four benchmark datasets in different languages
demonstrate the promising performance of our method in comparison to
state-of-the-art approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-modal vision-language model for generalizable annotation-free
  pathology localization and clinical diagnosis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.02044v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.02044v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Yang, Hong-Yu Zhou, Zhihuan Li, Yuanxu Gao, Cheng Li, Weijian Huang, Jiarun Liu, Hairong Zheng, Kang Zhang, Shanshan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Defining pathologies automatically from medical images aids the understanding
of the emergence and progression of diseases, and such an ability is crucial in
clinical diagnostics. However, existing deep learning models heavily rely on
expert annotations and lack generalization capabilities in open clinical
environments. In this study, we present a generalizable vision-language model
for Annotation-Free pathology Localization (AFLoc). The core strength of AFLoc
lies in its extensive multi-level semantic structure-based contrastive
learning, which comprehensively aligns multi-granularity medical concepts from
reports with abundant image features, to adapt to the diverse expressions of
pathologies and unseen pathologies without the reliance on image annotations
from experts. We demonstrate the proof of concept on Chest X-ray images, with
extensive experimental validation across 6 distinct external datasets,
encompassing 13 types of chest pathologies. The results demonstrate that AFLoc
surpasses state-of-the-art methods in pathology localization and
classification, and even outperforms the human benchmark in locating 5
different pathologies. Additionally, we further verify its generalization
ability by applying it to retinal fundus images. Our approach showcases AFLoc's
versatilities and underscores its suitability for clinical diagnosis in complex
clinical environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> of Multimodal Large Language Model from A Data-centric
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16640v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16640v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyi Bai, Hao Liang, Binwang Wan, Yanran Xu, Xi Li, Shiyu Li, Ling Yang, Bozhou Li, Yifan Wang, Bin Cui, Ping Huang, Jiulong Shan, Conghui He, Binhang Yuan, Wentao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal large language models (MLLMs) enhance the capabilities of standard
large language models by integrating and processing data from multiple
modalities, including text, vision, audio, video, and 3D environments. Data
plays a pivotal role in the development and refinement of these models. In this
survey, we comprehensively review the literature on MLLMs from a data-centric
perspective. Specifically, we explore methods for preparing multimodal data
during the pretraining and adaptation phases of MLLMs. Additionally, we analyze
the evaluation methods for the datasets and review the benchmarks for
evaluating MLLMs. Our survey also outlines potential future research
directions. This work aims to provide researchers with a detailed understanding
of the data-driven aspects of MLLMs, fostering further exploration and
innovation in this field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TP2O: Creative Text Pair-to-Object Generation using Balance
  Swap-Sampling <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.01819v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.01819v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Li, Zedong Zhang, Jian Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating creative combinatorial objects from two seemingly unrelated object
texts is a challenging task in text-to-image synthesis, often hindered by a
focus on emulating existing data distributions. In this paper, we develop a
straightforward yet highly effective method, called \textbf{balance
swap-sampling}. First, we propose a swapping mechanism that generates a novel
combinatorial object image set by randomly exchanging intrinsic elements of two
text embeddings through a cutting-edge diffusion model. Second, we introduce a
balance swapping region to efficiently sample a small subset from the newly
generated image set by balancing CLIP distances between the new images and
their original generations, increasing the likelihood of accepting the
high-quality combinations. Last, we employ a segmentation method to compare
CLIP distances among the segmented components, ultimately selecting the most
promising object from the sampled subset. Extensive experiments demonstrate
that our approach outperforms recent SOTA T2I methods. Surprisingly, our
results even rival those of human artists, such as frog-broccoli.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV2024, Project page:
  https://njustzandyz.github.io/tp2o/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Image <span class="highlight-title">Pre-Train</span>ing with Siamese Cropped Masked Autoencoders <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.17823v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.17823v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexandre Eymaël, Renaud Vandeghen, Anthony Cioppa, Silvio Giancola, Bernard Ghanem, Marc Van Droogenbroeck
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervised pre-training of image encoders is omnipresent in the
literature, particularly following the introduction of Masked autoencoders
(MAE). Current efforts attempt to learn object-centric representations from
motion in videos. In particular, SiamMAE recently introduced a Siamese network,
training a shared-weight encoder from two frames of a video with a high
asymmetric masking ratio (95%). In this work, we propose CropMAE, an
alternative approach to the Siamese pre-training introduced by SiamMAE. Our
method specifically differs by exclusively considering pairs of cropped images
sourced from the same image but cropped differently, deviating from the
conventional pairs of frames extracted from a video. CropMAE therefore
alleviates the need for video datasets, while maintaining competitive
performances and drastically reducing pre-training and learning time.
Furthermore, we demonstrate that CropMAE learns similar object-centric
representations without explicit motion, showing that current self-supervised
learning methods do not learn such representations from explicit object motion,
but rather thanks to the implicit image transformations that occur between the
two views. Finally, CropMAE achieves the highest masking ratio to date (98.5%),
enabling the reconstruction of images using only two visible patches. Our code
is available at https://github.com/alexandre-eymael/CropMAE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 7 figures, 5 tables, 3 pages of supplementary material.
  Paper accepted at ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Thermal Infrared Tracking with Natural Language Modeling and
  Coordinate Sequence Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.08265v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.08265v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Miao Yan, Ping Zhang, Haofei Zhang, Ruqian Hao, Juanxiu Liu, Xiaoyang Wang, Lin Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Thermal infrared tracking is an essential topic in computer vision tasks
because of its advantage of all-weather imaging. However, most conventional
methods utilize only hand-crafted features, while deep learning-based
correlation filtering methods are limited by simple correlation operations.
Transformer-based methods ignore temporal and coordinate information, which is
critical for TIR tracking that lacks texture and color information. In this
paper, to address these issues, we apply natural language modeling to TIR
tracking and propose a novel model called NLMTrack, which enhances the
utilization of coordinate and temporal information. NLMTrack applies an encoder
that unifies feature extraction and feature fusion, which simplifies the TIR
tracking pipeline. To address the challenge of low detail and low contrast in
TIR images, on the one hand, we design a multi-level progressive fusion module
that enhances the semantic representation and incorporates multi-scale
features. On the other hand, the decoder combines the TIR features and the
coordinate sequence features using a causal transformer to generate the target
sequence step by step. Moreover, we explore an adaptive loss aimed at elevating
tracking accuracy and a simple template update strategy to accommodate the
target's appearance variations. Experiments show that NLMTrack achieves
state-of-the-art performance on multiple benchmarks. The Code is publicly
available at \url{https://github.com/ELOESZHANG/NLMTrack}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PoseCrafter: One-Shot Personalized Video Synthesis Following Flexible
  Pose Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14582v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14582v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yong Zhong, Min Zhao, Zebin You, Xiaofeng Yu, Changwang Zhang, Chongxuan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce PoseCrafter, a one-shot method for personalized
video generation following the control of flexible poses. Built upon Stable
Diffusion and ControlNet, we carefully design an inference process to produce
high-quality videos without the corresponding ground-truth frames. First, we
select an appropriate reference frame from the training video and invert it to
initialize all latent variables for generation. Then, we insert the
corresponding training pose into the target pose sequences to enhance
faithfulness through a trained temporal attention module. Furthermore, to
alleviate the face and hand degradation resulting from discrepancies between
poses of training videos and inference poses, we implement simple latent
editing through an affine transformation matrix involving facial and hand
landmarks. Extensive experiments on several datasets demonstrate that
PoseCrafter achieves superior results to baselines pre-trained on a vast
collection of videos under 8 commonly used metrics. Besides, PoseCrafter can
follow poses from different individuals or artificial edits and simultaneously
retain the human identity in an open-domain training video. Our project page is
available at https://ml-gsai.github.io/PoseCrafter-demo/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bridging Sensor Gaps via Attention Gated Tuning for Hyperspectral Image
  Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.12865v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.12865v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xizhe Xue, Haokui Zhang, Rong Xiao, Ying Li, Zongwen Bai, Mike Zheng Shou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data-hungry HSI classification methods require high-quality labeled HSIs,
which are often costly to obtain. This characteristic limits the performance
potential of data-driven methods when dealing with limited annotated samples.
Bridging the domain gap between data acquired from different sensors allows us
to utilize abundant labeled data across sensors to break this bottleneck. In
this paper, we propose a novel Attention-Gated Tuning (AGT) strategy and a
triplet-structured transformer model, Tri-Former, to address this issue. The
AGT strategy serves as a bridge, allowing us to leverage existing labeled HSI
datasets, even RGB datasets to enhance the performance on new HSI datasets with
limited samples. Instead of inserting additional parameters inside the basic
model, we train a lightweight auxiliary branch that takes intermediate features
as input from the basic model and makes predictions. The proposed AGT resolves
conflicts between heterogeneous and even cross-modal data by suppressing the
disturbing information and enhances the useful information through a soft gate.
Additionally, we introduce Tri-Former, a triplet-structured transformer with a
spectral-spatial separation design that enhances parameter utilization and
computational efficiency, enabling easier and flexible fine-tuning. Comparison
experiments conducted on three representative HSI datasets captured by
different sensors demonstrate the proposed Tri-Former achieves better
performance compared to several state-of-the-art methods. Homologous,
heterologous and cross-modal tuning experiments verified the effectiveness of
the proposed AGT. Code has been released at:
\href{https://github.com/Cecilia-xue/AGT}{https://github.com/Cecilia-xue/AGT}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Motion-Oriented Compositional Neural Radiance Fields for Monocular
  Dynamic Human Modeling <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11962v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11962v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaehyeok Kim, Dongyoon Wee, Dan Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces Motion-oriented Compositional Neural Radiance Fields
(MoCo-NeRF), a framework designed to perform free-viewpoint rendering of
monocular human videos via novel non-rigid motion modeling approach. In the
context of dynamic clothed humans, complex cloth dynamics generate non-rigid
motions that are intrinsically distinct from skeletal articulations and
critically important for the rendering quality. The conventional approach
models non-rigid motions as spatial (3D) deviations in addition to skeletal
transformations. However, it is either time-consuming or challenging to achieve
optimal quality due to its high learning complexity without a direct
supervision. To target this problem, we propose a novel approach of modeling
non-rigid motions as radiance residual fields to benefit from more direct color
supervision in the rendering and utilize the rigid radiance fields as a prior
to reduce the complexity of the learning process. Our approach utilizes a
single multiresolution hash encoding (MHE) to concurrently learn the canonical
T-pose representation from rigid skeletal motions and the radiance residual
field for non-rigid motions. Additionally, to further improve both training
efficiency and usability, we extend MoCo-NeRF to support simultaneous training
of multiple subjects within a single framework, thanks to our effective design
for modeling non-rigid motions. This scalability is achieved through the
integration of a global MHE and learnable identity codes in addition to
multiple local MHEs. We present extensive results on ZJU-MoCap and MonoCap,
clearly demonstrating state-of-the-art performance in both single- and
multi-subject settings. The code and model will be made publicly available at
the project page: https://stevejaehyeok.github.io/publications/moco-nerf.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Overcoming Distribution Mismatch in Quantizing Image Super-Resolution
  Networks <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.13337v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.13337v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cheeun Hong, Kyoung Mu Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although quantization has emerged as a promising approach to reducing
computational complexity across various high-level vision tasks, it inevitably
leads to accuracy loss in image super-resolution (SR) networks. This is due to
the significantly divergent feature distributions across different channels and
input images of the SR networks, which complicates the selection of a fixed
quantization range. Existing works address this distribution mismatch problem
by dynamically adapting quantization ranges to the varying distributions during
test time. However, such a dynamic adaptation incurs additional computational
costs during inference. In contrast, we propose a new quantization-aware
training scheme that effectively Overcomes the Distribution Mismatch problem in
SR networks without the need for dynamic adaptation. Intuitively, this mismatch
can be mitigated by regularizing the distance between the feature and a fixed
quantization range. However, we observe that such regularization can conflict
with the reconstruction loss during training, negatively impacting SR accuracy.
Therefore, we opt to regularize the mismatch only when the gradients of the
regularization are aligned with those of the reconstruction loss. Additionally,
we introduce a layer-wise weight clipping correction scheme to determine a more
suitable quantization range for layer-wise weights. Experimental results
demonstrate that our framework effectively reduces the distribution mismatch
and achieves state-of-the-art performance with minimal computational overhead.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BEVWorld: A Multimodal World Model for Autonomous Driving via Unified
  BEV Latent Space 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.05679v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.05679v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yumeng Zhang, Shi Gong, Kaixin Xiong, Xiaoqing Ye, Xiao Tan, Fan Wang, Jizhou Huang, Hua Wu, Haifeng Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  World models are receiving increasing attention in autonomous driving for
their ability to predict potential future scenarios. In this paper, we present
BEVWorld, a novel approach that tokenizes multimodal sensor inputs into a
unified and compact Bird's Eye View (BEV) latent space for environment
modeling. The world model consists of two parts: the multi-modal tokenizer and
the latent BEV sequence diffusion model. The multi-modal tokenizer first
encodes multi-modality information and the decoder is able to reconstruct the
latent BEV tokens into LiDAR and image observations by ray-casting rendering in
a self-supervised manner. Then the latent BEV sequence diffusion model predicts
future scenarios given action tokens as conditions. Experiments demonstrate the
effectiveness of BEVWorld in autonomous driving tasks, showcasing its
capability in generating future scenes and benefiting downstream tasks such as
perception and motion prediction. Code will be available at
https://github.com/zympsyche/BevWorld.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Recent Advances of Continual Learning in Computer Vision: An <span class="highlight-title">Overview</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2109.11369v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2109.11369v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoxuan Qu, Hossein Rahmani, Li Xu, Bryan Williams, Jun Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In contrast to batch learning where all training data is available at once,
continual learning represents a family of methods that accumulate knowledge and
learn continuously with data available in sequential order. Similar to the
human learning process with the ability of learning, fusing, and accumulating
new knowledge coming at different time steps, continual learning is considered
to have high practical significance. Hence, continual learning has been studied
in various artificial intelligence tasks. In this paper, we present a
comprehensive review of the recent progress of continual learning in computer
vision. In particular, the works are grouped by their representative
techniques, including regularization, knowledge distillation, memory,
generative replay, parameter isolation, and a combination of the above
techniques. For each category of these techniques, both its characteristics and
applications in computer vision are presented. At the end of this overview,
several subareas, where continuous knowledge accumulation is potentially
helpful while continual learning has not been well studied, are discussed.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>June 2024 Version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Power Variable Projection for Initialization-Free Large-Scale Bundle
  Adjustment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.05079v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.05079v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simon Weber, Je Hyeong Hong, Daniel Cremers
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most Bundle Adjustment (BA) solvers like the Levenberg-Marquard algorithm
require a good initialization. Instead, initialization-free BA remains a
largely uncharted territory. The under-explored Variable Projection algorithm
(VarPro) exhibits a wide convergence basin even without initialization. Coupled
with object space error formulation, recent works have shown its ability to
solve small-scale initialization-free bundle adjustment problem. To make such
initialization-free BA approaches scalable, we introduce Power Variable
Projection (PoVar), extending a recent inverse expansion method based on power
series. Importantly, we link the power series expansion to Riemannian manifold
optimization. This projective framework is crucial to solve large-scale bundle
adjustment problems without initialization. Using the real-world BAL dataset,
we experimentally demonstrate that our solver achieves state-of-the-art results
in terms of speed and accuracy. To our knowledge, this work is the first to
address the scalability of BA without initialization opening new venues for
initialization-free structure-from-motion.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ V-IRL: Grounding Virtual Intelligence in Real Life 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.03310v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.03310v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihan Yang, Runyu Ding, Ellis Brown, Xiaojuan Qi, Saining Xie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There is a sensory gulf between the Earth that humans inhabit and the digital
realms in which modern AI agents are created. To develop AI agents that can
sense, think, and act as flexibly as humans in real-world settings, it is
imperative to bridge the realism gap between the digital and physical worlds.
How can we embody agents in an environment as rich and diverse as the one we
inhabit, without the constraints imposed by real hardware and control? Towards
this end, we introduce V-IRL: a platform that enables agents to scalably
interact with the real world in a virtual yet realistic environment. Our
platform serves as a playground for developing agents that can accomplish
various practical tasks and as a vast testbed for measuring progress in
capabilities spanning perception, decision-making, and interaction with
real-world data across the entire globe.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://virl-platform.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Common Sense Reasoning for Deepfake Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.00126v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.00126v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yue Zhang, Ben Colman, Xiao Guo, Ali Shahriyari, Gaurav Bharaj
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State-of-the-art deepfake detection approaches rely on image-based features
extracted via neural networks. While these approaches trained in a supervised
manner extract likely fake features, they may fall short in representing
unnatural `non-physical' semantic facial attributes -- blurry hairlines, double
eyebrows, rigid eye pupils, or unnatural skin shading. However, such facial
attributes are easily perceived by humans and used to discern the authenticity
of an image based on human common sense. Furthermore, image-based feature
extraction methods that provide visual explanations via saliency maps can be
hard to interpret for humans. To address these challenges, we frame deepfake
detection as a Deepfake Detection VQA (DD-VQA) task and model human intuition
by providing textual explanations that describe common sense reasons for
labeling an image as real or fake. We introduce a new annotated dataset and
propose a Vision and Language Transformer-based framework for the DD-VQA task.
We also incorporate text and image-aware feature alignment formulation to
enhance multi-modal representation learning. As a result, we improve upon
existing deepfake detection models by integrating our learned vision
representations, which reason over common sense knowledge from the DD-VQA task.
We provide extensive empirical results demonstrating that our method enhances
detection performance, generalization ability, and language-based
interpretability in the deepfake detection task.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ProtoSAM: One-Shot Medical Image Segmentation With Foundational Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07042v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07042v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lev Ayzenberg, Raja Giryes, Hayit Greenspan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work introduces a new framework, ProtoSAM, for one-shot medical image
segmentation. It combines the use of prototypical networks, known for few-shot
segmentation, with SAM - a natural image foundation model. The method proposed
creates an initial coarse segmentation mask using the ALPnet prototypical
network, augmented with a DINOv2 encoder. Following the extraction of an
initial mask, prompts are extracted, such as points and bounding boxes, which
are then input into the Segment Anything Model (SAM). State-of-the-art results
are shown on several medical image datasets and demonstrate automated
segmentation capabilities using a single image example (one shot) with no need
for fine-tuning of the foundation model. Our code is available at:
https://github.com/levayz/ProtoSAM
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 3 figures, 4 tables, code:
  https://github.com/levayz/ProtoSAM</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LaMI-DETR: Open-Vocabulary Detection with Language Model Instruction <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11335v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11335v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Penghui Du, Yu Wang, Yifan Sun, Luting Wang, Yue Liao, Gang Zhang, Errui Ding, Yan Wang, Jingdong Wang, Si Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing methods enhance open-vocabulary object detection by leveraging the
robust open-vocabulary recognition capabilities of Vision-Language Models
(VLMs), such as CLIP.However, two main challenges emerge:(1) A deficiency in
concept representation, where the category names in CLIP's text space lack
textual and visual knowledge.(2) An overfitting tendency towards base
categories, with the open vocabulary knowledge biased towards base categories
during the transfer from VLMs to detectors.To address these challenges, we
propose the Language Model Instruction (LaMI) strategy, which leverages the
relationships between visual concepts and applies them within a simple yet
effective DETR-like detector, termed LaMI-DETR.LaMI utilizes GPT to construct
visual concepts and employs T5 to investigate visual similarities across
categories.These inter-category relationships refine concept representation and
avoid overfitting to base categories.Comprehensive experiments validate our
approach's superior performance over existing methods in the same rigorous
setting without reliance on external training resources.LaMI-DETR achieves a
rare box AP of 43.4 on OV-LVIS, surpassing the previous best by 7.8 rare box
AP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Context-Guided Spatial Feature Reconstruction for Efficient Semantic
  Segmentation <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.06228v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.06228v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenliang Ni, Xinghao Chen, Yingjie Zhai, Yehui Tang, Yunhe Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semantic segmentation is an important task for numerous applications but it
is still quite challenging to achieve advanced performance with limited
computational costs. In this paper, we present CGRSeg, an efficient yet
competitive segmentation framework based on context-guided spatial feature
reconstruction. A Rectangular Self-Calibration Module is carefully designed for
spatial feature reconstruction and pyramid context extraction. It captures the
axial global context in both horizontal and vertical directions to explicitly
model rectangular key areas. A shape self-calibration function is designed to
make the key areas closer to foreground objects. Besides, a lightweight Dynamic
Prototype Guided head is proposed to improve the classification of foreground
objects by explicit class embedding. Our CGRSeg is extensively evaluated on
ADE20K, COCO-Stuff, and Pascal Context benchmarks, and achieves
state-of-the-art semantic performance. Specifically, it achieves $43.6\%$ mIoU
on ADE20K with only $4.0$ GFLOPs, which is $0.9\%$ and $2.5\%$ mIoU better than
SeaFormer and SegNeXt but with about $38.0\%$ fewer GFLOPs. Code is available
at https://github.com/nizhenliang/CGRSeg.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards AI-Architecture Li<span class="highlight-title">bert</span>y: A Comprehensive <span class="highlight-title">Survey</span> on Design and
  Generation of Virtual Architecture by Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.00510v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.00510v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anqi Wang, Jiahua Dong, Lik-Hang Lee, Jiachuan Shen, Pan Hui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D shape generation techniques leveraging deep learning have garnered
significant interest from both the computer vision and architectural design
communities, promising to enrich the content in the virtual environment.
However, research on virtual architectural design remains limited, particularly
regarding designer-AI collaboration and deep learning-assisted design. In our
survey, we reviewed 149 related articles (81.2% of articles published between
2019 and 2023) covering architectural design, 3D shape techniques, and virtual
environments. Through scrutinizing the literature, we first identify the
principles of virtual architecture and illuminate its current production
challenges, including datasets, multimodality, design intuition, and generative
frameworks. We then introduce the latest approaches to designing and generating
virtual buildings leveraging 3D shape generation and summarize four
characteristics of various approaches to virtual architecture. Based on our
analysis, we expound on four research agendas, including agency, communication,
user consideration, and integrating tools. Additionally, we highlight four
important enablers of ubiquitous interaction with immersive systems in deep
learning-assisted architectural generation. Our work contributes to fostering
understanding between designers and deep learning techniques, broadening access
to designer-AI collaboration. We advocate for interdisciplinary efforts to
address this timely research topic, facilitating content designing and
generation in the virtual environment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>36 pages, 9 figures, and 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MoLA: Motion Generation and Editing with Latent Diffusion Enhanced by
  Adversarial Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.01867v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.01867v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kengo Uchida, Takashi Shibuya, Yuhta Takida, Naoki Murata, Shusuke Takahashi, Yuki Mitsufuji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In motion generation, controllability as well as generation quality and speed
is becoming more and more important. There are various motion editing tasks,
such as in-betweening, upper body editing, and path-following, but existing
methods perform motion editing with a data-space diffusion model, which is slow
in inference compared to a latent diffusion model. In this paper, we propose
MoLA, which provides fast and high-quality motion generation and also can deal
with multiple editing tasks in a single framework. For high-quality and fast
generation, we employ a variational autoencoder and latent diffusion model, and
improve the performance with adversarial training. In addition, we apply a
training-free guided generation framework to achieve various editing tasks with
motion control inputs. We quantitatively show the effectiveness of adversarial
learning in text-to-motion generation, and demonstrate the applicability of our
editing framework to multiple editing tasks in the motion domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Aligning Cyber Space with Physical World: A Comprehensive <span class="highlight-title">Survey</span> on
  Embodied AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06886v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06886v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Liu, Weixing Chen, Yongjie Bai, Jingzhou Luo, Xinshuai Song, Kaixuan Jiang, Zhida Li, Ganlong Zhao, Junyi Lin, Guanbin Li, Wen Gao, Liang Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embodied Artificial Intelligence (Embodied AI) is crucial for achieving
Artificial General Intelligence (AGI) and serves as a foundation for various
applications that bridge cyberspace and the physical world. Recently, the
emergence of Multi-modal Large Models (MLMs) and World Models (WMs) have
attracted significant attention due to their remarkable perception,
interaction, and reasoning capabilities, making them a promising architecture
for the brain of embodied agents. However, there is no comprehensive survey for
Embodied AI in the era of MLMs. In this survey, we give a comprehensive
exploration of the latest advancements in Embodied AI. Our analysis firstly
navigates through the forefront of representative works of embodied robots and
simulators, to fully understand the research focuses and their limitations.
Then, we analyze four main research targets: 1) embodied perception, 2)
embodied interaction, 3) embodied agent, and 4) sim-to-real adaptation,
covering the state-of-the-art methods, essential paradigms, and comprehensive
datasets. Additionally, we explore the complexities of MLMs in virtual and real
embodied agents, highlighting their significance in facilitating interactions
in dynamic digital and physical environments. Finally, we summarize the
challenges and limitations of embodied AI and discuss their potential future
directions. We hope this survey will serve as a foundational reference for the
research community and inspire continued innovation. The associated project can
be found at https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first comprehensive review of Embodied AI in the era of MLMs, 37
  pages. We also provide the paper list for Embodied AI:
  https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Energy-Calibrated VAE with Test Time Free Lunch <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.04071v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.04071v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yihong Luo, Siya Qiu, Xingjian Tao, Yujun Cai, Jing Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a novel generative model that utilizes a
conditional Energy-Based Model (EBM) for enhancing Variational Autoencoder
(VAE), termed Energy-Calibrated VAE (EC-VAE). Specifically, VAEs often suffer
from blurry generated samples due to the lack of a tailored training on the
samples generated in the generative direction. On the other hand, EBMs can
generate high-quality samples but require expensive Markov Chain Monte Carlo
(MCMC) sampling. To address these issues, we introduce a conditional EBM for
calibrating the generative direction of VAE during training, without requiring
it for the generation at test time. In particular, we train EC-VAE upon both
the input data and the calibrated samples with adaptive weight to enhance
efficacy while avoiding MCMC sampling at test time. Furthermore, we extend the
calibration idea of EC-VAE to variational learning and normalizing flows, and
apply EC-VAE to an additional application of zero-shot image restoration via
neural transport prior and range-null theory. We evaluate the proposed method
with two applications, including image generation and zero-shot image
restoration, and the experimental results show that our method achieves
competitive performance over single-step non-adversarial generation. Our code
is available at https://github.com/DJ-LYH/EC-VAE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024. Code is available at https://github.com/DJ-LYH/EC-VAE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Receler: Reliable Concept Erasing of Text-to-Image Diffusion Models via
  Lightweight Erasers <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.17717v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.17717v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chi-Pin Huang, Kai-Po Chang, Chung-Ting Tsai, Yung-Hsuan Lai, Fu-En Yang, Yu-Chiang Frank Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Concept erasure in text-to-image diffusion models aims to disable pre-trained
diffusion models from generating images related to a target concept. To perform
reliable concept erasure, the properties of robustness and locality are
desirable. The former refrains the model from producing images associated with
the target concept for any paraphrased or learned prompts, while the latter
preserves its ability in generating images with non-target concepts. In this
paper, we propose Reliable Concept Erasing via Lightweight Erasers (Receler).
It learns a lightweight Eraser to perform concept erasing while satisfying the
above desirable properties through the proposed concept-localized
regularization and adversarial prompt learning scheme. Experiments with various
concepts verify the superiority of Receler over previous methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024. Project page:
  https://jasper0314-huang.github.io/receler-concept-erasing/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PixelLM: Pixel Reasoning with Large Multimodal Model <span class="chip">CVPR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.02228v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.02228v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhongwei Ren, Zhicheng Huang, Yunchao Wei, Yao Zhao, Dongmei Fu, Jiashi Feng, Xiaojie Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While large multimodal models (LMMs) have achieved remarkable progress,
generating pixel-level masks for image reasoning tasks involving multiple
open-world targets remains a challenge. To bridge this gap, we introduce
PixelLM, an effective and efficient LMM for pixel-level reasoning and
understanding. Central to PixelLM is a novel, lightweight pixel decoder and a
comprehensive segmentation codebook. The decoder efficiently produces masks
from the hidden embeddings of the codebook tokens, which encode detailed
target-relevant information. With this design, PixelLM harmonizes with the
structure of popular LMMs and avoids the need for additional costly
segmentation models. Furthermore, we propose a target refinement loss to
enhance the model's ability to differentiate between multiple targets, leading
to substantially improved mask quality. To advance research in this area, we
construct MUSE, a high-quality multi-target reasoning segmentation benchmark.
PixelLM excels across various pixel-level image reasoning and understanding
tasks, outperforming well-established methods in multiple benchmarks, including
MUSE, single- and multi-referring segmentation. Comprehensive ablations confirm
the efficacy of each proposed component. All code, models, and datasets will be
publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>(Accepted by CVPR 2024) Code and models are released at:
  https://pixellm.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards AI-Powered Video Assistant Referee System (VARS) for Association
  Football 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12483v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12483v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jan Held, Anthony Cioppa, Silvio Giancola, Abdullah Hamdi, Christel Devue, Bernard Ghanem, Marc Van Droogenbroeck
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over the past decade, the technology used by referees in football has
improved substantially, enhancing the fairness and accuracy of decisions. This
progress has culminated in the implementation of the Video Assistant Referee
(VAR), an innovation that enables backstage referees to review incidents on the
pitch from multiple points of view. However, the VAR is currently limited to
professional leagues due to its expensive infrastructure and the lack of
referees worldwide. In this paper, we present the semi-automated Video
Assistant Referee System (VARS) that leverages the latest findings in
multi-view video analysis. VARS sets a new state-of-the-art on the
SoccerNet-MVFoul dataset, a multi-view video dataset of football fouls. Our
VARS achieves a new state-of-the-art on the SoccerNet-MVFoul dataset by
recognizing the type of foul in 50% of instances and the appropriate sanction
in 46% of cases. Finally, we conducted a comparative study to investigate human
performance in classifying fouls and their corresponding severity and compared
these findings to our VARS. The results of our study highlight the potential of
our VARS to reach human performance and support football refereeing across all
levels of professional and amateur federations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The paper is subject to the peer review process of Sports Engineering</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Attention-based Class-Conditioned Alignment for Multi-Source Domain
  Adaptation of Object Detectors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.09918v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.09918v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Atif Belal, Akhil Meethal, Francisco Perdigon Romero, Marco Pedersoli, Eric Granger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Domain adaptation methods for object detection (OD) strive to mitigate the
impact of distribution shifts by promoting feature alignment across source and
target domains. Multi-source domain adaptation (MSDA) allows leveraging
multiple annotated source datasets and unlabeled target data to improve the
accuracy and robustness of the detection model. Most state-of-the-art MSDA
methods for OD perform feature alignment in a class-agnostic manner. This is
challenging since the objects have unique modal information due to variations
in object appearance across domains. A recent prototype-based approach proposed
a class-wise alignment, yet it suffers from error accumulation due to noisy
pseudo-labels that can negatively affect adaptation with imbalanced data. To
overcome these limitations, we propose an attention-based class-conditioned
alignment method for MSDA that aligns instances of each object category across
domains. In particular, an attention module coupled with an adversarial domain
classifier allows learning domain-invariant and class-specific instance
representations. Experimental results on multiple benchmarking MSDA datasets
indicate that our method outperforms the state-of-the-art methods and is robust
to class imbalance using a conceptually simple class-conditioning method. Our
code is available at https://github.com/imatif17/ACIA.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">17</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CellularLint: A Systematic Approach to Identify Inconsistent Behavior in
  Cellular Network Specifications <span class="chip">USENIX Security 24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13742v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13742v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mirza Masfiqur Rahman, Imtiaz Karim, Elisa Bertino
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, there has been a growing focus on scrutinizing the security
of cellular networks, often attributing security vulnerabilities to issues in
the underlying protocol design descriptions. These protocol design
specifications, typically extensive documents that are thousands of pages long,
can harbor inaccuracies, underspecifications, implicit assumptions, and
internal inconsistencies. In light of the evolving landscape, we introduce
CellularLint--a semi-automatic framework for inconsistency detection within the
standards of 4G and 5G, capitalizing on a suite of natural language processing
techniques. Our proposed method uses a revamped few-shot learning mechanism on
domain-adapted large language models. Pre-trained on a vast corpus of cellular
network protocols, this method enables CellularLint to simultaneously detect
inconsistencies at various levels of semantics and practical use cases. In
doing so, CellularLint significantly advances the automated analysis of
protocol specifications in a scalable fashion. In our investigation, we focused
on the Non-Access Stratum (NAS) and the security specifications of 4G and 5G
networks, ultimately uncovering 157 inconsistencies with 82.67% accuracy. After
verification of these inconsistencies on open-source implementations and 17
commercial devices, we confirm that they indeed have a substantial impact on
design decisions, potentially leading to concerns related to privacy,
integrity, availability, and interoperability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at USENIX Security 24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Comprehensive <span class="highlight-title">Review</span> of Recommender Systems: Transitioning from Theory
  to Practice 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13699v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13699v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaina Raza, Mizanur Rahman, Safiullah Kamawal, Armin Toroghi, Ananya Raval, Farshad Navah, Amirmohammad Kazemeini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender Systems (RS) play an integral role in enhancing user experiences
by providing personalized item suggestions. This survey reviews the progress in
RS inclusively from 2017 to 2024, effectively connecting theoretical advances
with practical applications. We explore the development from traditional RS
techniques like content-based and collaborative filtering to advanced methods
involving deep learning, graph-based models, reinforcement learning, and large
language models. We also discuss specialized systems such as context-aware,
review-based, and fairness-aware RS. The primary goal of this survey is to
bridge theory with practice. It addresses challenges across various sectors,
including e-commerce, healthcare, and finance, emphasizing the need for
scalable, real-time, and trustworthy solutions. Through this survey, we promote
stronger partnerships between academic research and industry practices. The
insights offered by this survey aim to guide industry professionals in
optimizing RS deployment and to inspire future research directions, especially
in addressing emerging technological and societal trends
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>we quarterly update of this literature</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Language of Infographics: Toward Understanding Conceptual Metaphor
  Use in Scientific Storytelling <span class="chip">IEEE VIS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13416v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13416v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hana Pokojná, Tobias Isenberg, Stefan Bruckner, Barbora Kozlíková, Laura Garrison
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We apply an approach from cognitive linguistics by mapping Conceptual
Metaphor Theory (CMT) to the visualization domain to address patterns of visual
conceptual metaphors that are often used in science infographics. Metaphors
play an essential part in visual communication and are frequently employed to
explain complex concepts. However, their use is often based on intuition,
rather than following a formal process. At present, we lack tools and language
for understanding and describing metaphor use in visualization to the extent
where taxonomy and grammar could guide the creation of visual components, e.g.,
infographics. Our classification of the visual conceptual mappings within
scientific representations is based on the breakdown of visual components in
existing scientific infographics. We demonstrate the development of this
mapping through a detailed analysis of data collected from four domains
(biomedicine, climate, space, and anthropology) that represent a diverse range
of visual conceptual metaphors used in the visual communication of science.
This work allows us to identify patterns of visual conceptual metaphor use
within the domains, resolve ambiguities about why specific conceptual metaphors
are used, and develop a better overall understanding of visual metaphor use in
scientific infographics. Our analysis shows that ontological and orientational
conceptual metaphors are the most widely applied to translate complex
scientific concepts. To support our findings we developed a visual exploratory
tool based on the collected database that places the individual infographics on
a spatio-temporal scale and illustrates the breakdown of visual conceptual
metaphors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 8 figures, 1 table, accepted to IEEE VIS 2024 Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DCNv3: Towards Next Generation Deep Cross Network for CTR Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13349v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13349v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Honghao Li, Yiwen Zhang, Yi Zhang, Hanwei Li, Lei Sang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep & Cross Network and its derivative models have become an important
paradigm in click-through rate (CTR) prediction due to their effective balance
between computational cost and performance. However, these models face four
major limitations: (1) while most models claim to capture high-order feature
interactions, they often do so implicitly and non-interpretably through deep
neural networks (DNN), which limits the trustworthiness of the model's
predictions; (2) the performance of existing explicit feature interaction
methods is often weaker than that of implicit DNN, undermining their necessity;
(3) many models fail to adaptively filter noise while enhancing the order of
feature interactions; (4) the fusion methods of most models cannot provide
suitable supervision signals for their different interaction methods.
  To address the identified limitations, this paper proposes the next
generation Deep Cross Network (DCNv3) and Shallow & Deep Cross Network
(SDCNv3). These models ensure interpretability in feature interaction modeling
while exponentially increasing the order of feature interactions to achieve
genuine Deep Crossing rather than just Deep & Cross. Additionally, we employ a
Self-Mask operation to filter noise and reduce the number of parameters in the
cross network by half. In the fusion layer, we use a simple yet effective loss
weight calculation method called Tri-BCE to provide appropriate supervision
signals. Comprehensive experiments on six datasets demonstrate the
effectiveness, efficiency, and interpretability of DCNv3 and SDCNv3. The code,
running logs, and detailed hyperparameter configurations are available at:
https://anonymous.4open.science/r/DCNv3-E352.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semantic-aware Representation Learning for Homography Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13284v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13284v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhan Liu, Qianxin Huang, Siqi Hui, Jingwen Fu, Sanping Zhou, Kangyi Wu, Pengna Li, Jinjun Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Homography estimation is the task of determining the transformation from an
image pair. Our approach focuses on employing detector-free feature matching
methods to address this issue. Previous work has underscored the importance of
incorporating semantic information, however there still lacks an efficient way
to utilize semantic information. Previous methods suffer from treating the
semantics as a pre-processing, causing the utilization of semantics overly
coarse-grained and lack adaptability when dealing with different tasks. In our
work, we seek another way to use the semantic information, that is
semantic-aware feature representation learning framework.Based on this, we
propose SRMatcher, a new detector-free feature matching method, which
encourages the network to learn integrated semantic feature
representation.Specifically, to capture precise and rich semantics, we leverage
the capabilities of recently popularized vision foundation models (VFMs)
trained on extensive datasets. Then, a cross-images Semantic-aware Fusion Block
(SFB) is proposed to integrate its fine-grained semantic features into the
feature representation space. In this way, by reducing errors stemming from
semantic inconsistencies in matching pairs, our proposed SRMatcher is able to
deliver more accurate and realistic outcomes. Extensive experiments show that
SRMatcher surpasses solid baselines and attains SOTA results on multiple
real-world datasets. Compared to the previous SOTA approach GeoFormer,
SRMatcher increases the area under the cumulative curve (AUC) by about 11\% on
HPatches. Additionally, the SRMatcher could serve as a plug-and-play framework
for other matching methods like LoFTR, yielding substantial precision
improvement.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Aligning Explanations for Recommendation with Rating and Feature via
  Maximizing Mutual Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13274v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13274v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yurou Zhao, Yiding Sun, Ruidong Han, Fei Jiang, Lu Guan, Xiang Li, Wei Lin, Jiaxin Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Providing natural language-based explanations to justify recommendations
helps to improve users' satisfaction and gain users' trust. However, as current
explanation generation methods are commonly trained with an objective to mimic
existing user reviews, the generated explanations are often not aligned with
the predicted ratings or some important features of the recommended items, and
thus, are suboptimal in helping users make informed decision on the
recommendation platform. To tackle this problem, we propose a flexible
model-agnostic method named MMI (Maximizing Mutual Information) framework to
enhance the alignment between the generated natural language explanations and
the predicted rating/important item features. Specifically, we propose to use
mutual information (MI) as a measure for the alignment and train a neural MI
estimator. Then, we treat a well-trained explanation generation model as the
backbone model and further fine-tune it through reinforcement learning with
guidance from the MI estimator, which rewards a generated explanation that is
more aligned with the predicted rating or a pre-defined feature of the
recommended item. Experiments on three datasets demonstrate that our MMI
framework can boost different backbone models, enabling them to outperform
existing baselines in terms of alignment with predicted ratings and item
features. Additionally, user studies verify that MI-enhanced explanations
indeed facilitate users' decisions and are favorable compared with other
baselines due to their better alignment properties.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>this paper has been accepted by cikm2024, and the camera-ready
  version will be updated soon</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Compressed models are NOT miniature versions of large models <span class="chip">CIKM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13174v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13174v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohit Raj Rai, Rishant Pal, Amit Awekar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large neural models are often compressed before deployment. Model compression
is necessary for many practical reasons, such as inference latency, memory
footprint, and energy consumption. Compressed models are assumed to be
miniature versions of corresponding large neural models. However, we question
this belief in our work. We compare compressed models with corresponding large
neural models using four model characteristics: prediction errors, data
representation, data distribution, and vulnerability to adversarial attack. We
perform experiments using the BERT-large model and its five compressed
versions. For all four model characteristics, compressed models significantly
differ from the BERT-large model. Even among compressed models, they differ
from each other on all four model characteristics. Apart from the expected loss
in model performance, there are major side effects of using compressed models
to replace large neural models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the 33rd ACM International Conference on Information and
  Knowledge Management (CIKM 2024) for the Short Research Paper track, 5 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Using LLMs to Investigate Correlations of Conversational Follow-up
  Queries with User Satisfaction <span class="chip">SIGIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13166v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13166v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyunwoo Kim, Yoonseo Choi, Taehyun Yang, Honggu Lee, Chaneon Park, Yongju Lee, Jin Young Kim, Juho Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With large language models (LLMs), conversational search engines shift how
users retrieve information from the web by enabling natural conversations to
express their search intents over multiple turns. Users' natural conversation
embodies rich but implicit signals of users' search intents and evaluation of
search results to understand user experience with the system. However, it is
underexplored how and why users ask follow-up queries to continue conversations
with conversational search engines and how the follow-up queries signal users'
satisfaction. From qualitative analysis of 250 conversational turns from an
in-lab user evaluation of Naver Cue:, a commercial conversational search
engine, we propose a taxonomy of 18 users' follow-up query patterns from
conversational search, comprising two major axes: (1) users' motivations behind
continuing conversations (N = 7) and (2) actions of follow-up queries (N = 11).
Compared to the existing literature on query reformulations, we uncovered a new
set of motivations and actions behind follow-up queries, including asking for
subjective opinions or providing natural language feedback on the engine's
responses. To analyze conversational search logs with our taxonomy in a
scalable and efficient manner, we built an LLM-powered classifier (73%
accuracy). With our classifier, we analyzed 2,061 conversational tuples
collected from real-world usage logs of Cue: and examined how the conversation
patterns from our taxonomy correlates with satisfaction. Our initial findings
suggest some signals of dissatisfactions, such as Clarifying Queries, Excluding
Condition, and Substituting Condition with follow-up queries. We envision our
approach could contribute to automated evaluation of conversation search
experience by providing satisfaction signals and grounds for realistic user
simulations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to LLM4Eval @ SIGIR 2024 - The First Workshop on Large
  Language Models (LLMs) for Evaluation in Information Retrieval</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ROLeR: Effective Reward Shaping in Offline Reinforcement Learning for
  Recommender Systems <span class="chip">CIKM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13163v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13163v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Zhang, Ruihong Qiu, Jiajun Liu, Sen Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Offline reinforcement learning (RL) is an effective tool for real-world
recommender systems with its capacity to model the dynamic interest of users
and its interactive nature. Most existing offline RL recommender systems focus
on model-based RL through learning a world model from offline data and building
the recommendation policy by interacting with this model. Although these
methods have made progress in the recommendation performance, the effectiveness
of model-based offline RL methods is often constrained by the accuracy of the
estimation of the reward model and the model uncertainties, primarily due to
the extreme discrepancy between offline logged data and real-world data in user
interactions with online platforms. To fill this gap, a more accurate reward
model and uncertainty estimation are needed for the model-based RL methods. In
this paper, a novel model-based Reward Shaping in Offline Reinforcement
Learning for Recommender Systems, ROLeR, is proposed for reward and uncertainty
estimation in recommendation systems. Specifically, a non-parametric reward
shaping method is designed to refine the reward model. In addition, a flexible
and more representative uncertainty penalty is designed to fit the needs of
recommendation systems. Extensive experiments conducted on four benchmark
datasets showcase that ROLeR achieves state-of-the-art performance compared
with existing baselines. The source code can be downloaded at
https://github.com/ArronDZhang/ROLeR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CIKM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MLSA4Rec: Mamba Combined with Low-Rank Decomposed Self-Attention for
  Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13135v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13135v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinzhao Su, Zhenhua Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In applications such as e-commerce, online education, and streaming services,
sequential recommendation systems play a critical role. Despite the excellent
performance of self-attention-based sequential recommendation models in
capturing dependencies between items in user interaction history, their
quadratic complexity and lack of structural bias limit their applicability.
Recently, some works have replaced the self-attention module in sequential
recommenders with Mamba, which has linear complexity and structural bias.
However, these works have not noted the complementarity between the two
approaches. To address this issue, this paper proposes a new hybrid
recommendation framework, Mamba combined with Low-Rank decomposed
Self-Attention for Sequential Recommendation (MLSA4Rec), whose complexity is
linear with respect to the length of the user's historical interaction
sequence. Specifically, MLSA4Rec designs an efficient Mamba-LSA interaction
module. This module introduces a low-rank decomposed self-attention (LSA)
module with linear complexity and injects structural bias into it through
Mamba. The LSA module analyzes user preferences from a different perspective
and dynamically guides Mamba to focus on important information in user
historical interactions through a gated information transmission mechanism.
Finally, MLSA4Rec combines user preference information refined by the Mamba and
LSA modules to accurately predict the user's next possible interaction. To our
knowledge, this is the first study to combine Mamba and self-attention in
sequential recommendation systems. Experimental results show that MLSA4Rec
outperforms existing self-attention and Mamba-based sequential recommendation
models in recommendation accuracy on three real-world datasets, demonstrating
the great potential of Mamba and self-attention working together.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Causally Disentangled State Representation Learning for Reinforcement
  Learning based Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13091v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13091v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyu Wang, Xiaocong Chen, Lina Yao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In Reinforcement Learning-based Recommender Systems (RLRS), the complexity
and dynamism of user interactions often result in high-dimensional and noisy
state spaces, making it challenging to discern which aspects of the state are
truly influential in driving the decision-making process. This issue is
exacerbated by the evolving nature of user preferences and behaviors, requiring
the recommender system to adaptively focus on the most relevant information for
decision-making while preserving generaliability. To tackle this problem, we
introduce an innovative causal approach for decomposing the state and
extracting \textbf{C}ausal-\textbf{I}n\textbf{D}ispensable \textbf{S}tate
Representations (CIDS) in RLRS. Our method concentrates on identifying the
\textbf{D}irectly \textbf{A}ction-\textbf{I}nfluenced \textbf{S}tate Variables
(DAIS) and \textbf{A}ction-\textbf{I}nfluence \textbf{A}ncestors (AIA), which
are essential for making effective recommendations. By leveraging conditional
mutual information, we develop a framework that not only discerns the causal
relationships within the generative process but also isolates critical state
variables from the typically dense and high-dimensional state representations.
We provide theoretical evidence for the identifiability of these variables.
Then, by making use of the identified causal relationship, we construct
causal-indispensable state representations, enabling the training of policies
over a more advantageous subset of the agent's state space. We demonstrate the
efficacy of our approach through extensive experiments, showcasing our method
outperforms state-of-the-art methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Sentiment Analysis with Local Large Language Models using
  Majority Voting: A Study on Factors Affecting Restaurant Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13069v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13069v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junichiro Niimi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  User-generated contents (UGCs) on online platforms allow marketing
researchers to understand consumer preferences for products and services. With
the advance of large language models (LLMs), some studies utilized the models
for annotation and sentiment analysis. However, the relationship between the
accuracy and the hyper-parameters of LLMs is yet to be thoroughly examined. In
addition, the issues of variability and reproducibility of results from each
trial of LLMs have rarely been considered in existing literature. Since actual
human annotation uses majority voting to resolve disagreements among
annotators, this study introduces a majority voting mechanism to a sentiment
analysis model using local LLMs. By a series of three analyses of online
reviews on restaurant evaluations, we demonstrate that majority voting with
multiple attempts using a medium-sized model produces more robust results than
using a large model with a single attempt. Furthermore, we conducted further
analysis to investigate the effect of each aspect on the overall evaluation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This manuscript is under peer review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cross-channel Recommendation for Multi-channel Retail 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.00972v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.00972v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yijin Choi, Jongkyung Shin, Chiehyeon Lim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  An increasing number of retailers are expanding their channels to the offline
and online domains, transforming them into multi-channel retailers. This
transition emphasizes the need for cross-channel recommendations. Given that
each retail channel represents a separate domain with a unique context, this
can be regarded as a cross-domain recommendation (CDR). However, existing
studies on CDR did not address the scenarios where both users and items
partially overlap across multi-retail channels which we define as
"cross-channel retail recommendation (CCRR)". This paper introduces our
original work on CCRR using a real-world dataset from a multi-channel retail
store. Specifically, we study significant challenges in integrating user
preferences across both channels and propose a novel model for CCRR using a
channel-wise attention mechanism. We empirically validate our model's
superiority in addressing CCRR over existing models. Finally, we offer
implications for future research on CCRR, delving into our experiment results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 2 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Performance Comparison of Session-based Recommendation Algorithms based
  on GNNs <span class="chip">ECIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.16695v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.16695v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Faisal Shehzad, Dietmar Jannach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In session-based recommendation settings, a recommender system has no access
to long-term user profiles and thus has to base its suggestions on the user
interactions that are observed in an ongoing session. Since such sessions can
consist of only a small set of interactions, various approaches based on Graph
Neural Networks (GNN) were recently proposed, as they allow us to integrate
various types of side information about the items in a natural way.
Unfortunately, a variety of evaluation settings are used in the literature,
e.g., in terms of protocols, metrics and baselines, making it difficult to
assess what represents the state of the art. In this work, we present the
results of an evaluation of eight recent GNN-based approaches that were
published in high-quality outlets. For a fair comparison, all models are
systematically tuned and tested under identical conditions using three common
datasets. We furthermore include k-nearest-neighbor and sequential rules-based
models as baselines, as such models have previously exhibited competitive
performance results for similar settings. To our surprise, the evaluation
showed that the simple models outperform all recent GNN models in terms of the
Mean Reciprocal Rank, which we used as an optimization criterion, and were only
outperformed in three cases in terms of the Hit Rate. Additional analyses
furthermore reveal that several other factors that are often not deeply
discussed in papers, e.g., random seeds, can markedly impact the performance of
GNN-based models. Our results therefore (a) point to continuing issues in the
community in terms of research methodology and (b) indicate that there is ample
room for improvement in session-based recommendation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ECIR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Search Engines, LLMs or Both? Evaluating Information Seeking Strategies
  for Answering Health Questions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12468v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12468v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marcos Fernández-Pichel, Juan C. Pichel, David E. Losada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Search engines have traditionally served as primary tools for information
seeking. However, the new Large Language Models (LLMs) have recently
demonstrated remarkable capabilities in multiple tasks and, specifically, their
adoption as question answering systems is becoming increasingly prevalent. It
is expected that LLM-based conversational systems and traditional web engines
will continue to coexist in the future, supporting end users in various ways.
But there is a need for more scientific research on the effectiveness of both
types of systems in facilitating accurate information seeking. In this study,
we focus on their merits in answering health questions. We conducted an
extensive study comparing different web search engines, LLMs and
retrieval-augmented (RAG) approaches. Our research reveals intriguing
conclusions. For example, we observed that the quality of webpages potentially
responding to a health question does not decline as we navigate further down
the ranked lists. However, according to our evaluation, web engines are less
accurate than LLMs in finding correct answers to health questions. On the other
hand, LLMs are quite sensitive to the input prompts, and we also found out that
RAG leads to highly effective information seeking methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ General Distribution Learning: A theoretical framework for Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05666v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05666v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Binchuan Qi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces General Distribution Learning (GD learning), a novel
theoretical learning framework designed to address a comprehensive range of
machine learning and statistical tasks, including classification, regression,
and parameter estimation. GD learning focuses on estimating the true underlying
probability distribution of dataset and using models to fit the estimated
parameters of the distribution. The learning error in GD learning is thus
decomposed into two distinct categories: estimation error and fitting error.
The estimation error, which stems from the constraints of finite sampling,
limited prior knowledge, and the estimation algorithm's inherent limitations,
quantifies the discrepancy between the true distribution and its estimate. The
fitting error can be attributed to model's capacity limitation and the
performance limitation of the optimization algorithm, which evaluates the
deviation of the model output from the fitted objective. To address the
challenge of non-convexity in the optimization of learning error, we introduce
the standard loss function and demonstrate that, when employing this function,
global optimal solutions in non-convex optimization can be approached by
minimizing the gradient norm and the structural error. Moreover, we demonstrate
that the estimation error is determined by the uncertainty of the estimate $q$,
and propose the minimum uncertainty principle to obtain an optimal estimate of
the true distribution. We further provide upper bounds for the estimation
error, fitting error, and learning error within the GD learning framework.
Ultimately, our findings are applied to offer theoretical explanations for
several unanswered questions on deep learning, including overparameterization,
non-convex optimization, flat minima, dynamic isometry condition and other
techniques in deep learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2105.04026 by other
  authors. arXiv admin note: text overlap with arXiv:2105.04026 by other
  authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AI-Driven Guided Response for Security Operation Centers with Microsoft
  Copilot for Security 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09017v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09017v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Scott Freitas, Jovan Kalajdjieski, Amir Gharib, Robert McCann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Security operation centers contend with a constant stream of security
incidents, ranging from straightforward to highly complex. To address this, we
developed Copilot Guided Response (CGR), an industry-scale ML architecture that
guides security analysts across three key tasks -- (1) investigation, providing
essential historical context by identifying similar incidents; (2) triaging to
ascertain the nature of the incident -- whether it is a true positive, false
positive, or benign positive; and (3) remediation, recommending tailored
containment actions. CGR is integrated into the Microsoft Defender XDR product
and deployed worldwide, generating millions of recommendations across thousands
of customers. Our extensive evaluation, incorporating internal evaluation,
collaboration with security experts, and customer feedback, demonstrates that
CGR delivers high-quality recommendations across all three tasks. We provide a
comprehensive overview of the CGR architecture, setting a precedent as the
first cybersecurity company to openly discuss these capabilities in such depth.
Additionally, we GUIDE, the largest public collection of real-world security
incidents, spanning 13M evidences across 1M annotated incidents. By enabling
researchers and practitioners to conduct research on real-world data, GUIDE
advances the state of cybersecurity and supports the development of
next-generation machine learning systems.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Random Latent Exploration for Deep Reinforcement Learning <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13755v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13755v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Srinath Mahankali, Zhang-Wei Hong, Ayush Sekhari, Alexander Rakhlin, Pulkit Agrawal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ability to efficiently explore high-dimensional state spaces is essential
for the practical success of deep Reinforcement Learning (RL). This paper
introduces a new exploration technique called Random Latent Exploration (RLE),
that combines the strengths of bonus-based and noise-based (two popular
approaches for effective exploration in deep RL) exploration strategies. RLE
leverages the idea of perturbing rewards by adding structured random rewards to
the original task rewards in certain (random) states of the environment, to
encourage the agent to explore the environment during training. RLE is
straightforward to implement and performs well in practice. To demonstrate the
practical effectiveness of RLE, we evaluate it on the challenging Atari and
IsaacGym benchmarks and show that RLE exhibits higher overall scores across all
the tasks than other approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Label Learning with Stronger Consistency Guarantees 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13746v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13746v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anqi Mao, Mehryar Mohri, Yutao Zhong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a detailed study of surrogate losses and algorithms for
multi-label learning, supported by $H$-consistency bounds. We first show that,
for the simplest form of multi-label loss (the popular Hamming loss), the
well-known consistent binary relevance surrogate suffers from a sub-optimal
dependency on the number of labels in terms of $H$-consistency bounds, when
using smooth losses such as logistic losses. Furthermore, this loss function
fails to account for label correlations. To address these drawbacks, we
introduce a novel surrogate loss, multi-label logistic loss, that accounts for
label correlations and benefits from label-independent $H$-consistency bounds.
We then broaden our analysis to cover a more extensive family of multi-label
losses, including all common ones and a new extension defined based on
linear-fractional functions with respect to the confusion matrix. We also
extend our multi-label logistic losses to more comprehensive multi-label
comp-sum losses, adapting comp-sum losses from standard classification to the
multi-label learning. We prove that this family of surrogate losses benefits
from $H$-consistency bounds, and thus Bayes-consistency, across any general
multi-label loss. Our work thus proposes a unified surrogate loss framework
benefiting from strong consistency guarantees for any multi-label loss,
significantly expanding upon previous work which only established
Bayes-consistency and for specific loss functions. Additionally, we adapt
constrained losses from standard classification to multi-label constrained
losses in a similar way, which also benefit from $H$-consistency bounds and
thus Bayes-consistency for any multi-label loss. We further describe efficient
gradient computation algorithms for minimizing the multi-label logistic loss.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimistic Q-learning for average reward and episodic reinforcement
  learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13743v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13743v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Priyank Agrawal, Shipra Agrawal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present an optimistic Q-learning algorithm for regret minimization in
average reward reinforcement learning under an additional assumption on the
underlying MDP that for all policies, the expected time to visit some frequent
state $s_0$ is finite and upper bounded by $H$. Our setting strictly
generalizes the episodic setting and is significantly less restrictive than the
assumption of bounded hitting time {\it for all states} made by most previous
literature on model-free algorithms in average reward settings. We demonstrate
a regret bound of $\tilde{O}(H^5 S\sqrt{AT})$, where $S$ and $A$ are the
numbers of states and actions, and $T$ is the horizon. A key technical novelty
of our work is to introduce an $\overline{L}$ operator defined as $\overline{L}
v = \frac{1}{H} \sum_{h=1}^H L^h v$ where $L$ denotes the Bellman operator. We
show that under the given assumption, the $\overline{L}$ operator has a strict
contraction (in span) even in the average reward setting. Our algorithm design
then uses ideas from episodic Q-learning to estimate and apply this operator
iteratively. Therefore, we provide a unified view of regret minimization in
episodic and non-episodic settings that may be of independent interest.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>36 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Pricing in Securities Lending Market: Application in Revenue
  Optimization for an Agent Lender Portfolio 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13687v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13687v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jing Xu, Yung Cheng Hsu, William Biscarri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Securities lending is an important part of the financial market structure,
where agent lenders help long term institutional investors to lend out their
securities to short sellers in exchange for a lending fee. Agent lenders within
the market seek to optimize revenue by lending out securities at the highest
rate possible. Typically, this rate is set by hard-coded business rules or
standard supervised machine learning models. These approaches are often
difficult to scale and are not adaptive to changing market conditions. Unlike a
traditional stock exchange with a centralized limit order book, the securities
lending market is organized similarly to an e-commerce marketplace, where agent
lenders and borrowers can transact at any agreed price in a bilateral fashion.
This similarity suggests that the use of typical methods for addressing dynamic
pricing problems in e-commerce could be effective in the securities lending
market. We show that existing contextual bandit frameworks can be successfully
utilized in the securities lending market. Using offline evaluation on real
historical data, we show that the contextual bandit approach can consistently
outperform typical approaches by at least 15% in terms of total revenue
generated.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding Reinforcement Learning-Based Fine-Tuning of Diffusion
  Models: A Tutorial and <span class="highlight-title">Review</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13734v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13734v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Masatoshi Uehara, Yulai Zhao, Tommaso Biancalani, Sergey Levine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This tutorial provides a comprehensive survey of methods for fine-tuning
diffusion models to optimize downstream reward functions. While diffusion
models are widely known to provide excellent generative modeling capability,
practical applications in domains such as biology require generating samples
that maximize some desired metric (e.g., translation efficiency in RNA, docking
score in molecules, stability in protein). In these cases, the diffusion model
can be optimized not only to generate realistic samples but also to explicitly
maximize the measure of interest. Such methods are based on concepts from
reinforcement learning (RL). We explain the application of various RL
algorithms, including PPO, differentiable optimization, reward-weighted MLE,
value-weighted sampling, and path consistency learning, tailored specifically
for fine-tuning diffusion models. We aim to explore fundamental aspects such as
the strengths and limitations of different RL-based fine-tuning algorithms
across various scenarios, the benefits of RL-based fine-tuning compared to
non-RL-based approaches, and the formal objectives of RL-based fine-tuning
(target distributions). Additionally, we aim to examine their connections with
related topics such as classifier guidance, Gflownets, flow-based diffusion
models, path integral control theory, and sampling from unnormalized
distributions such as MCMC. The code of this tutorial is available at
https://github.com/masa-ue/RLfinetuning_Diffusion_Bioseq
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>We plan to add more content/codes. Please let us know if there are
  any comments</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Realizable $H$-Consistent and Bayes-Consistent Loss Functions for
  Learning to Defer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13732v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13732v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anqi Mao, Mehryar Mohri, Yutao Zhong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a comprehensive study of surrogate loss functions for learning to
defer. We introduce a broad family of surrogate losses, parameterized by a
non-increasing function $\Psi$, and establish their realizable $H$-consistency
under mild conditions. For cost functions based on classification error, we
further show that these losses admit $H$-consistency bounds when the hypothesis
set is symmetric and complete, a property satisfied by common neural network
and linear function hypothesis sets. Our results also resolve an open question
raised in previous work (Mozannar et al., 2023) by proving the realizable
$H$-consistency and Bayes-consistency of a specific surrogate loss.
Furthermore, we identify choices of $\Psi$ that lead to $H$-consistent
surrogate losses for any general cost function, thus achieving
Bayes-consistency, realizable $H$-consistency, and $H$-consistency bounds
simultaneously. We also investigate the relationship between $H$-consistency
bounds and realizable $H$-consistency in learning to defer, highlighting key
differences from standard classification. Finally, we empirically evaluate our
proposed surrogate losses and compare them with existing baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Predictive Low Rank Matrix Learning under Partial Observations:
  Mixed-Projection ADMM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13731v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13731v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dimitris Bertsimas, Nicholas A. G. Johnson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the problem of learning a partially observed matrix under the low
rank assumption in the presence of fully observed side information that depends
linearly on the true underlying matrix. This problem consists of an important
generalization of the Matrix Completion problem, a central problem in
Statistics, Operations Research and Machine Learning, that arises in
applications such as recommendation systems, signal processing, system
identification and image denoising. We formalize this problem as an
optimization problem with an objective that balances the strength of the fit of
the reconstruction to the observed entries with the ability of the
reconstruction to be predictive of the side information. We derive a
mixed-projection reformulation of the resulting optimization problem and
present a strong semidefinite cone relaxation. We design an efficient, scalable
alternating direction method of multipliers algorithm that produces high
quality feasible solutions to the problem of interest. Our numerical results
demonstrate that in the small rank regime ($k \leq 15$), our algorithm outputs
solutions that achieve on average $79\%$ lower objective value and $90.1\%$
lower $\ell_2$ reconstruction error than the solutions returned by the
experiment-wise best performing benchmark method. The runtime of our algorithm
is competitive with and often superior to that of the benchmark methods. Our
algorithm is able to solve problems with $n = 10000$ rows and $m = 10000$
columns in less than a minute.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Compressing Structured Tensor Algebra 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13726v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13726v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mahdi Ghorbani, Emilien Bauer, Tobias Grosser, Amir Shaikhha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tensor algebra is a crucial component for data-intensive workloads such as
machine learning and scientific computing. As the complexity of data grows,
scientists often encounter a dilemma between the highly specialized dense
tensor algebra and efficient structure-aware algorithms provided by sparse
tensor algebra. In this paper, we introduce DASTAC, a framework to propagate
the tensors's captured high-level structure down to low-level code generation
by incorporating techniques such as automatic data layout compression,
polyhedral analysis, and affine code generation. Our methodology reduces memory
footprint by automatically detecting the best data layout, heavily benefits
from polyhedral optimizations, leverages further optimizations, and enables
parallelization through MLIR. Through extensive experimentation, we show that
DASTAC achieves 1 to 2 orders of magnitude speedup over TACO, a
state-of-the-art sparse tensor compiler, and StructTensor, a state-of-the-art
structured tensor algebra compiler, with a significantly lower memory
footprint.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhanced $H$-Consistency Bounds 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13722v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13722v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anqi Mao, Mehryar Mohri, Yutao Zhong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent research has introduced a key notion of $H$-consistency bounds for
surrogate losses. These bounds offer finite-sample guarantees, quantifying the
relationship between the zero-one estimation error (or other target loss) and
the surrogate loss estimation error for a specific hypothesis set. However,
previous bounds were derived under the condition that a lower bound of the
surrogate loss conditional regret is given as a convex function of the target
conditional regret, without non-constant factors depending on the predictor or
input instance. Can we derive finer and more favorable $H$-consistency bounds?
In this work, we relax this condition and present a general framework for
establishing enhanced $H$-consistency bounds based on more general inequalities
relating conditional regrets. Our theorems not only subsume existing results as
special cases but also enable the derivation of more favorable bounds in
various scenarios. These include standard multi-class classification, binary
and multi-class classification under Tsybakov noise conditions, and bipartite
ranking.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Attention Based Simple Primitives for Open World Compositional Zero-Shot
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13715v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13715v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ans Munir, Faisal Z. Qureshi, Muhammad Haris Khan, Mohsen Ali
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Compositional Zero-Shot Learning (CZSL) aims to predict unknown compositions
made up of attribute and object pairs. Predicting compositions unseen during
training is a challenging task. We are exploring Open World Compositional
Zero-Shot Learning (OW-CZSL) in this study, where our test space encompasses
all potential combinations of attributes and objects. Our approach involves
utilizing the self-attention mechanism between attributes and objects to
achieve better generalization from seen to unseen compositions. Utilizing a
self-attention mechanism facilitates the model's ability to identify
relationships between attribute and objects. The similarity between the
self-attended textual and visual features is subsequently calculated to
generate predictions during the inference phase. The potential test space may
encompass implausible object-attribute combinations arising from unrestricted
attribute-object pairings. To mitigate this issue, we leverage external
knowledge from ConceptNet to restrict the test space to realistic compositions.
Our proposed model, Attention-based Simple Primitives (ASP), demonstrates
competitive performance, achieving results comparable to the state-of-the-art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FSP-Laplace: Function-Space Priors for the Laplace Approximation in
  Bayesian Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13711v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13711v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tristan Cinquin, Marvin Pförtner, Vincent Fortuin, Philipp Hennig, Robert Bamler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Laplace approximations are popular techniques for endowing deep networks with
epistemic uncertainty estimates as they can be applied without altering the
predictions of the neural network, and they scale to large models and datasets.
While the choice of prior strongly affects the resulting posterior
distribution, computational tractability and lack of interpretability of weight
space typically limit the Laplace approximation to isotropic Gaussian priors,
which are known to cause pathological behavior as depth increases. As a remedy,
we directly place a prior on function space. More precisely, since Lebesgue
densities do not exist on infinite-dimensional function spaces, we have to
recast training as finding the so-called weak mode of the posterior measure
under a Gaussian process (GP) prior restricted to the space of functions
representable by the neural network. Through the GP prior, one can express
structured and interpretable inductive biases, such as regularity or
periodicity, directly in function space, while still exploiting the implicit
inductive biases that allow deep networks to generalize. After model
linearization, the training objective induces a negative log-posterior density
to which we apply a Laplace approximation, leveraging highly scalable methods
from matrix-free linear algebra. Our method provides improved results where
prior knowledge is abundant, e.g., in many scientific inference tasks. At the
same time, it stays competitive for black-box regression and classification
tasks where neural networks typically excel.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding Reference Policies in Direct Preference Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13709v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13709v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixin Liu, Pengfei Liu, Arman Cohan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct Preference Optimization (DPO) has become a widely used training method
for the instruction fine-tuning of large language models (LLMs). In this work,
we explore an under-investigated aspect of DPO - its dependency on the
reference model or policy. Such reference policies, typically instantiated as
the model to be further fine-tuned, are important since they can impose an
upper limit on DPO's effectiveness. Therefore, we address three related
research questions in this work. First, we explore the optimal strength of the
KL-divergence constraint in DPO, which penalizes deviations from the reference
policy, and find that DPO is sensitive to this strength. Next, we examine the
necessity of reference policies for instruction fine-tuning by providing both
theoretical and empirical comparisons between DPO and related learning
objectives, demonstrating DPO's superiority. Additionally, we investigate
whether DPO benefits from stronger reference policies, finding that a stronger
reference policy can lead to improved performance, but only when it is similar
to the model being fine-tuned. Our findings highlight the confounding role of
reference policies in DPO and offer insights for best practices, while also
identifying open research questions for future studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are We Ready for Out-of-Distribution Detection in Digital Pathology? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13708v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13708v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ji-Hun Oh, Kianoush Falahkheirkhah, Rohit Bhargava
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The detection of semantic and covariate out-of-distribution (OOD) examples is
a critical yet overlooked challenge in digital pathology (DP). Recently,
substantial insight and methods on OOD detection were presented by the ML
community, but how do they fare in DP applications? To this end, we establish a
benchmark study, our highlights being: 1) the adoption of proper evaluation
protocols, 2) the comparison of diverse detectors in both a single and
multi-model setting, and 3) the exploration into advanced ML settings like
transfer learning (ImageNet vs. DP pre-training) and choice of architecture
(CNNs vs. transformers). Through our comprehensive experiments, we contribute
new insights and guidelines, paving the way for future research and discussion.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Discovering governing equation in structural dynamics from
  acceleration-only measurements 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13704v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13704v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Calvin Alvares, Souvik Chakraborty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over the past few years, equation discovery has gained popularity in
different fields of science and engineering. However, existing equation
discovery algorithms rely on the availability of noisy measurements of the
state variables (i.e., displacement {and velocity}). This is a major bottleneck
in structural dynamics, where we often only have access to acceleration
measurements. To that end, this paper introduces a novel equation discovery
algorithm for discovering governing equations of dynamical systems from
acceleration-only measurements. The proposed algorithm employs a library-based
approach for equation discovery. To enable equation discovery from
acceleration-only measurements, we propose a novel Approximate Bayesian
Computation (ABC) model that prioritizes parsimonious models. The efficacy of
the proposed algorithm is illustrated using {four} structural dynamics examples
that include both linear and nonlinear dynamical systems. The case studies
presented illustrate the possible application of the proposed approach for
equation discovery of dynamical systems from acceleration-only measurements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PASTA: Controllable Part-Aware Shape Generation with Autoregressive
  <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13677v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13677v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Songlin Li, Despoina Paschalidou, Leonidas Guibas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increased demand for tools that automate the 3D content creation process
led to tremendous progress in deep generative models that can generate diverse
3D objects of high fidelity. In this paper, we present PASTA, an autoregressive
transformer architecture for generating high quality 3D shapes. PASTA comprises
two main components: An autoregressive transformer that generates objects as a
sequence of cuboidal primitives and a blending network, implemented with a
transformer decoder that composes the sequences of cuboids and synthesizes high
quality meshes for each object. Our model is trained in two stages: First we
train our autoregressive generative model using only annotated cuboidal parts
as supervision and next, we train our blending network using explicit 3D
supervision, in the form of watertight meshes. Evaluations on various ShapeNet
objects showcase the ability of our model to perform shape generation from
diverse inputs \eg from scratch, from a partial object, from text and images,
as well size-guided generation, by explicitly conditioning on a bounding box
that defines the object's boundaries. Moreover, as our model considers the
underlying part-based structure of a 3D object, we are able to select a
specific part and produce shapes with meaningful variations of this part. As
evidenced by our experiments, our model generates 3D shapes that are both more
realistic and diverse than existing part-based and non part-based methods,
while at the same time is simpler to implement and train.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Non-Asymptotic Uncertainty Quantification in High-Dimensional Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13666v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13666v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Frederik Hoppe, Claudio Mayrink Verdun, Hannah Laus, Felix Krahmer, Holger Rauhut
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Uncertainty quantification (UQ) is a crucial but challenging task in many
high-dimensional regression or learning problems to increase the confidence of
a given predictor. We develop a new data-driven approach for UQ in regression
that applies both to classical regression approaches such as the LASSO as well
as to neural networks. One of the most notable UQ techniques is the debiased
LASSO, which modifies the LASSO to allow for the construction of asymptotic
confidence intervals by decomposing the estimation error into a Gaussian and an
asymptotically vanishing bias component. However, in real-world problems with
finite-dimensional data, the bias term is often too significant to be
neglected, resulting in overly narrow confidence intervals. Our work rigorously
addresses this issue and derives a data-driven adjustment that corrects the
confidence intervals for a large class of predictors by estimating the means
and variances of the bias terms from training data, exploiting high-dimensional
concentration phenomena. This gives rise to non-asymptotic confidence
intervals, which can help avoid overestimating uncertainty in critical
applications such as MRI diagnosis. Importantly, our analysis extends beyond
sparse regression to data-driven predictors like neural networks, enhancing the
reliability of model-based deep learning. Our findings bridge the gap between
established theory and the practical applicability of such debiased methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Decision Focused Causal Learning for Direct Counterfactual Marketing
  Optimization <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13664v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13664v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Zhou, Rongxiao Huang, Shaoming Li, Guibin Jiang, Jiaqi Zheng, Bing Cheng, Wei Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Marketing optimization plays an important role to enhance user engagement in
online Internet platforms. Existing studies usually formulate this problem as a
budget allocation problem and solve it by utilizing two fully decoupled stages,
i.e., machine learning (ML) and operation research (OR). However, the learning
objective in ML does not take account of the downstream optimization task in
OR, which causes that the prediction accuracy in ML may be not positively
related to the decision quality.
  Decision Focused Learning (DFL) integrates ML and OR into an end-to-end
framework, which takes the objective of the downstream task as the decision
loss function and guarantees the consistency of the optimization direction
between ML and OR. However, deploying DFL in marketing is non-trivial due to
multiple technological challenges. Firstly, the budget allocation problem in
marketing is a 0-1 integer stochastic programming problem and the budget is
uncertain and fluctuates a lot in real-world settings, which is beyond the
general problem background in DFL. Secondly, the counterfactual in marketing
causes that the decision loss cannot be directly computed and the optimal
solution can never be obtained, both of which disable the common
gradient-estimation approaches in DFL. Thirdly, the OR solver is called
frequently to compute the decision loss during model training in DFL, which
produces huge computational cost and cannot support large-scale training data.
In this paper, we propose a decision focused causal learning framework (DFCL)
for direct counterfactual marketing optimization, which overcomes the above
technological challenges. Both offline experiments and online A/B testing
demonstrate the effectiveness of DFCL over the state-of-the-art methods.
Currently, DFCL has been deployed in several marketing scenarios in Meituan,
one of the largest online food delivery platform in the world.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by KDD 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CogniVoice: Multimodal and Multilingual Fusion Networks for Mild
  Cognitive Impairment Assessment from Spontaneous Speech <span class="chip">INTERSPEECH 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13660v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13660v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiali Cheng, Mohamed Elgaar, Nidhi Vakil, Hadi Amiri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mild Cognitive Impairment (MCI) is a medical condition characterized by
noticeable declines in memory and cognitive abilities, potentially affecting
individual's daily activities. In this paper, we introduce CogniVoice, a novel
multilingual and multimodal framework to detect MCI and estimate Mini-Mental
State Examination (MMSE) scores by analyzing speech data and its textual
transcriptions. The key component of CogniVoice is an ensemble multimodal and
multilingual network based on ``Product of Experts'' that mitigates reliance on
shortcut solutions. Using a comprehensive dataset containing both English and
Chinese languages from TAUKADIAL challenge, CogniVoice outperforms the best
performing baseline model on MCI classification and MMSE regression tasks by
2.8 and 4.1 points in F1 and RMSE respectively, and can effectively reduce the
performance gap across different language groups by 0.7 points in F1.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>INTERSPEECH 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data Alchemy: Mitigating Cross-Site Model Variability Through Test Time
  Data Calibration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13632v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13632v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abhijeet Parida, Antonia Alomar, Zhifan Jiang, Pooneh Roshanitabrizi, Austin Tapp, Maria Ledesma-Carbayo, Ziyue Xu, Syed Muhammed Anwar, Marius George Linguraru, Holger R. Roth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deploying deep learning-based imaging tools across various clinical sites
poses significant challenges due to inherent domain shifts and regulatory
hurdles associated with site-specific fine-tuning. For histopathology, stain
normalization techniques can mitigate discrepancies, but they often fall short
of eliminating inter-site variations. Therefore, we present Data Alchemy, an
explainable stain normalization method combined with test time data calibration
via a template learning framework to overcome barriers in cross-site analysis.
Data Alchemy handles shifts inherent to multi-site data and minimizes them
without needing to change the weights of the normalization or classifier
networks. Our approach extends to unseen sites in various clinical settings
where data domain discrepancies are unknown. Extensive experiments highlight
the efficacy of our framework in tumor classification in hematoxylin and
eosin-stained patches. Our explainable normalization method boosts
classification tasks' area under the precision-recall curve(AUPR) by 0.165,
0.545 to 0.710. Additionally, Data Alchemy further reduces the multisite
classification domain gap, by improving the 0.710 AUPR an additional 0.142,
elevating classification performance further to 0.852, from 0.545. Our Data
Alchemy framework can popularize precision medicine with minimal operational
overhead by allowing for the seamless integration of pre-trained deep
learning-based clinical tools across multiple sites.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted to Machine Learning in Medical Imaging (MLMI 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distributionally and Adversarially Robust Logistic Regression via
  Intersecting Wasserstein Balls 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13625v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13625v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aras Selvi, Eleonora Kreacic, Mohsen Ghassemi, Vamsi Potluru, Tucker Balch, Manuela Veloso
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Empirical risk minimization often fails to provide robustness against
adversarial attacks in test data, causing poor out-of-sample performance.
Adversarially robust optimization (ARO) has thus emerged as the de facto
standard for obtaining models that hedge against such attacks. However, while
these models are robust against adversarial attacks, they tend to suffer
severely from overfitting. To address this issue for logistic regression, we
study the Wasserstein distributionally robust (DR) counterpart of ARO and show
that this problem admits a tractable reformulation. Furthermore, we develop a
framework to reduce the conservatism of this problem by utilizing an auxiliary
dataset (e.g., synthetic, external, or out-of-domain data), whenever available,
with instances independently sampled from a nonidentical but related ground
truth. In particular, we intersect the ambiguity set of the DR problem with
another Wasserstein ambiguity set that is built using the auxiliary dataset. We
analyze the properties of the underlying optimization problem, develop
efficient solution algorithms, and demonstrate that the proposed method
consistently outperforms benchmark approaches on real-world datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages, 3 color figures, under review at a conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Misspecified $Q$-Learning with Sparse Linear Function Approximation:
  Tight Bounds on Approximation Error 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13622v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13622v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ally Yalei Du, Lin F. Yang, Ruosong Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recent work by Dong & Yang (2023) showed for misspecified sparse linear
bandits, one can obtain an $O\left(\epsilon\right)$-optimal policy using a
polynomial number of samples when the sparsity is a constant, where $\epsilon$
is the misspecification error. This result is in sharp contrast to misspecified
linear bandits without sparsity, which require an exponential number of samples
to get the same guarantee. In order to study whether the analog result is
possible in the reinforcement learning setting, we consider the following
problem: assuming the optimal $Q$-function is a $d$-dimensional linear function
with sparsity $k$ and misspecification error $\epsilon$, whether we can obtain
an $O\left(\epsilon\right)$-optimal policy using number of samples polynomially
in the feature dimension $d$. We first demonstrate why the standard approach
based on Bellman backup or the existing optimistic value function elimination
approach such as OLIVE (Jiang et al., 2017) achieves suboptimal guarantees for
this problem. We then design a novel elimination-based algorithm to show one
can obtain an $O\left(H\epsilon\right)$-optimal policy with sample complexity
polynomially in the feature dimension $d$ and planning horizon $H$. Lastly, we
complement our upper bound with an $\widetilde{\Omega}\left(H\epsilon\right)$
suboptimality lower bound, giving a complete picture of this problem.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Differential Privacy Mechanisms in Neural Tangent Kernel Regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13621v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13621v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiuxiang Gu, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training data privacy is a fundamental problem in modern Artificial
Intelligence (AI) applications, such as face recognition, recommendation
systems, language generation, and many others, as it may contain sensitive user
information related to legal issues. To fundamentally understand how privacy
mechanisms work in AI applications, we study differential privacy (DP) in the
Neural Tangent Kernel (NTK) regression setting, where DP is one of the most
powerful tools for measuring privacy under statistical learning, and NTK is one
of the most popular analysis frameworks for studying the learning mechanisms of
deep neural networks. In our work, we can show provable guarantees for both
differential privacy and test accuracy of our NTK regression. Furthermore, we
conduct experiments on the basic image classification dataset CIFAR10 to
demonstrate that NTK regression can preserve good accuracy under a modest
privacy budget, supporting the validity of our analysis. To our knowledge, this
is the first work to provide a DP guarantee for NTK regression.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Physics-guided Active Sample Reweighting for Urban Flow Prediction <span class="chip">CIKM '24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13605v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13605v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Jiang, Tong Chen, Guanhua Ye, Wentao Zhang, Lizhen Cui, Zi Huang, Hongzhi Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Urban flow prediction is a spatio-temporal modeling task that estimates the
throughput of transportation services like buses, taxis, and ride-sharing,
where data-driven models have become the most popular solution in the past
decade. Meanwhile, the implicitly learned mapping between historical
observations to the prediction targets tend to over-simplify the dynamics of
real-world urban flows, leading to suboptimal predictions. Some recent
spatio-temporal prediction solutions bring remedies with the notion of
physics-guided machine learning (PGML), which describes spatio-temporal data
with nuanced and principled physics laws, thus enhancing both the prediction
accuracy and interpretability. However, these spatio-temporal PGML methods are
built upon a strong assumption that the observed data fully conforms to the
differential equations that define the physical system, which can quickly
become ill-posed in urban flow prediction tasks. The observed urban flow data,
especially when sliced into time-dependent snapshots to facilitate predictions,
is typically incomplete and sparse, and prone to inherent noise incurred in the
collection process. As a result, such physical inconsistency between the data
and PGML model significantly limits the predictive power and robustness of the
solution. Moreover, due to the interval-based predictions and intermittent
nature of data filing in many transportation services, the instantaneous
dynamics of urban flows can hardly be captured, rendering differential
equation-based continuous modeling a loose fit for this setting. To overcome
the challenges, we develop a discretized physics-guided network (PN), and
propose a data-aware framework Physics-guided Active Sample Reweighting
(P-GASR) to enhance PN. Experimental results in four real-world datasets
demonstrate that our method achieves state-of-the-art performance with a
demonstrable improvement in robustness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper is accepted by Proceedings of the 33nd ACM International
  Conference on Information and Knowledge Management (CIKM '24)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mechanistically Interpreting a <span class="highlight-title">Transformer</span>-based 2-SAT Solver: An
  Axiomatic Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13594v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13594v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nils Palumbo, Ravi Mangal, Zifan Wang, Saranya Vijayakumar, Corina S. Pasareanu, Somesh Jha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mechanistic interpretability aims to reverse engineer the computation
performed by a neural network in terms of its internal components. Although
there is a growing body of research on mechanistic interpretation of neural
networks, the notion of a mechanistic interpretation itself is often ad-hoc.
Inspired by the notion of abstract interpretation from the program analysis
literature that aims to develop approximate semantics for programs, we give a
set of axioms that formally characterize a mechanistic interpretation as a
description that approximately captures the semantics of the neural network
under analysis in a compositional manner. We use these axioms to guide the
mechanistic interpretability analysis of a Transformer-based model trained to
solve the well-known 2-SAT problem. We are able to reverse engineer the
algorithm learned by the model -- the model first parses the input formulas and
then evaluates their satisfiability via enumeration of different possible
valuations of the Boolean input variables. We also present evidence to support
that the mechanistic interpretation of the analyzed model indeed satisfies the
stated axioms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MeshFeat: Multi-Resolution Features for Neural Fields on Meshes <span class="chip">ECCV</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13592v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13592v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mihir Mahajan, Florian Hofherr, Daniel Cremers
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parametric feature grid encodings have gained significant attention as an
encoding approach for neural fields since they allow for much smaller MLPs,
which significantly decreases the inference time of the models. In this work,
we propose MeshFeat, a parametric feature encoding tailored to meshes, for
which we adapt the idea of multi-resolution feature grids from Euclidean space.
We start from the structure provided by the given vertex topology and use a
mesh simplification algorithm to construct a multi-resolution feature
representation directly on the mesh. The approach allows the usage of small
MLPs for neural fields on meshes, and we show a significant speed-up compared
to previous representations while maintaining comparable reconstruction quality
for texture reconstruction and BRDF representation. Given its intrinsic
coupling to the vertices, the method is particularly well-suited for
representations on deforming meshes, making it a good fit for object animation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at European Conference on Computer Vision (ECCV), 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ With or Without Replacement? Improving Confidence in Fourier Imaging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13575v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13575v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Frederik Hoppe, Claudio Mayrink Verdun, Felix Krahmer, Marion I. Menzel, Holger Rauhut
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over the last few years, debiased estimators have been proposed in order to
establish rigorous confidence intervals for high-dimensional problems in
machine learning and data science. The core argument is that the error of these
estimators with respect to the ground truth can be expressed as a Gaussian
variable plus a remainder term that vanishes as long as the dimension of the
problem is sufficiently high. Thus, uncertainty quantification (UQ) can be
performed exploiting the Gaussian model. Empirically, however, the remainder
term cannot be neglected in many realistic situations of moderately-sized
dimensions, in particular in certain structured measurement scenarios such as
Magnetic Resonance Imaging (MRI). This, in turn, can downgrade the advantage of
the UQ methods as compared to non-UQ approaches such as the standard LASSO. In
this paper, we present a method to improve the debiased estimator by sampling
without replacement. Our approach leverages recent results of ours on the
structure of the random nature of certain sampling schemes showing how a
transition between sampling with and without replacement can lead to a weighted
reconstruction scheme with improved performance for the standard LASSO. In this
paper, we illustrate how this reweighted sampling idea can also improve the
debiased estimator and, consequently, provide a better method for UQ in Fourier
imaging.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at Cosera 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EnergyDiff: Universal Time-Series Energy Data Generation using Diffusion
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13538v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13538v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nan Lin, Peter Palensky, Pedro P. Vergara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-resolution time series data are crucial for operation and planning in
energy systems such as electrical power systems and heating systems. However,
due to data collection costs and privacy concerns, such data is often
unavailable or insufficient for downstream tasks. Data synthesis is a potential
solution for this data scarcity. With the recent development of generative AI,
we propose EnergyDiff, a universal data generation framework for energy time
series data. EnergyDiff builds on state-of-the-art denoising diffusion
probabilistic models, utilizing a proposed denoising network dedicated to
high-resolution time series data and introducing a novel Marginal Calibration
technique. Our extensive experimental results demonstrate that EnergyDiff
achieves significant improvement in capturing temporal dependencies and
marginal distributions compared to baselines, particularly at the 1-minute
resolution. Additionally, EnergyDiff consistently generates high-quality time
series data across diverse energy domains, time resolutions, and at both
customer and transformer levels with reduced computational need.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating the performance-deviation of itemKNN in RecBole and LensKit 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13531v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13531v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Schmidt, Jannik Nitschke, Tim Prinz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study examines the performance of item-based k-Nearest Neighbors
(ItemKNN) algorithms in the RecBole and LensKit recommender system libraries.
Using four data sets (Anime, Modcloth, ML-100K, and ML-1M), we assess each
library's efficiency, accuracy, and scalability, focusing primarily on
normalized discounted cumulative gain (nDCG). Our results show that RecBole
outperforms LensKit on two of three metrics on the ML-100K data set: it
achieved an 18% higher nDCG, 14% higher precision, and 35% lower recall. To
ensure a fair comparison, we adjusted LensKit's nDCG calculation to match
RecBole's method. This alignment made the performance more comparable, with
LensKit achieving an nDCG of 0.2540 and RecBole 0.2674. Differences in
similarity matrix calculations were identified as the main cause of performance
deviations. After modifying LensKit to retain only the top K similar items,
both libraries showed nearly identical nDCG values across all data sets. For
instance, both achieved an nDCG of 0.2586 on the ML-1M data set with the same
random seed. Initially, LensKit's original implementation only surpassed
RecBole in the ModCloth dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Pages: 6, Figures: 4, Tables: 4, Subsections: Introduction, Library
  Introduction, Method (Data Sets, Algorithms, Pre-processing and Data
  Splitting, Algorithm Training and Evaluation, Hardware Specifications),
  Results (First Steps, Further Investigations, Discussion)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Discussion: Effective and Interpretable Outcome Prediction by Training
  Sparse Mixtures of Linear Experts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13526v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13526v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francesco Folino, Luigi Pontieri, Pietro Sabatino
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Process Outcome Prediction entails predicting a discrete property of an
unfinished process instance from its partial trace. High-capacity outcome
predictors discovered with ensemble and deep learning methods have been shown
to achieve top accuracy performances, but they suffer from a lack of
transparency. Aligning with recent efforts to learn inherently interpretable
outcome predictors, we propose to train a sparse Mixture-of-Experts where both
the ``gate'' and ``expert'' sub-nets are Logistic Regressors. This
ensemble-like model is trained end-to-end while automatically selecting a
subset of input features in each sub-net, as an alternative to the common
approach of performing a global feature selection step prior to model training.
Test results on benchmark logs confirmed the validity and efficacy of this
approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper summarizes results presented at workshop \emph{ML4PM
  2023}, associated with conference ICPM 2023, October 23-27, 2023, Rome,
  Italy. 6 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ INDIC QA BENCHMARK: A Multilingual Benchmark to Evaluate Question
  Answering capability of LLMs for Indic Languages 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13522v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13522v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abhishek Kumar Singh, Rudra Murthy, Vishwajeet kumar, Jaydeep Sen, Ganesh Ramakrishnan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated remarkable zero-shot and
few-shot capabilities in unseen tasks, including context-grounded question
answering (QA) in English. However, the evaluation of LLMs' capabilities in
non-English languages for context-based QA is limited by the scarcity of
benchmarks in non-English languages. To address this gap, we introduce
Indic-QA, the largest publicly available context-grounded question-answering
dataset for 11 major Indian languages from two language families. The dataset
comprises both extractive and abstractive question-answering tasks and includes
existing datasets as well as English QA datasets translated into Indian
languages. Additionally, we generate a synthetic dataset using the Gemini model
to create question-answer pairs given a passage, which is then manually
verified for quality assurance. We evaluate various multilingual Large Language
Models and their instruction-fine-tuned variants on the benchmark and observe
that their performance is subpar, particularly for low-resource languages. We
hope that the release of this dataset will stimulate further research on the
question-answering abilities of LLMs for low-resource languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Model-based Policy Optimization using Symbolic World Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13518v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13518v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrey Gorodetskiy, Konstantin Mironov, Aleksandr Panov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The application of learning-based control methods in robotics presents
significant challenges. One is that model-free reinforcement learning
algorithms use observation data with low sample efficiency. To address this
challenge, a prevalent approach is model-based reinforcement learning, which
involves employing an environment dynamics model. We suggest approximating
transition dynamics with symbolic expressions, which are generated via symbolic
regression. Approximation of a mechanical system with a symbolic model has
fewer parameters than approximation with neural networks, which can potentially
lead to higher accuracy and quality of extrapolation. We use a symbolic
dynamics model to generate trajectories in model-based policy optimization to
improve the sample efficiency of the learning algorithm. We evaluate our
approach across various tasks within simulated environments. Our method
demonstrates superior sample efficiency in these tasks compared to model-free
and model-based baseline methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Instance Selection for Dynamic Algorithm Configuration with
  Reinforcement Learning: Improving Generalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13513v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13513v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Carolin Benjamins, Gjorgjina Cenikj, Ana Nikolikj, Aditya Mohan, Tome Eftimov, Marius Lindauer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dynamic Algorithm Configuration (DAC) addresses the challenge of dynamically
setting hyperparameters of an algorithm for a diverse set of instances rather
than focusing solely on individual tasks. Agents trained with Deep
Reinforcement Learning (RL) offer a pathway to solve such settings. However,
the limited generalization performance of these agents has significantly
hindered the application in DAC. Our hypothesis is that a potential bias in the
training instances limits generalization capabilities. We take a step towards
mitigating this by selecting a representative subset of training instances to
overcome overrepresentation and then retraining the agent on this subset to
improve its generalization performance. For constructing the meta-features for
the subset selection, we particularly account for the dynamic nature of the RL
agent by computing time series features on trajectories of actions and rewards
generated by the agent's interaction with the environment. Through empirical
evaluations on the Sigmoid and CMA-ES benchmarks from the standard benchmark
library for DAC, called DACBench, we discuss the potentials of our selection
technique compared to training on the entire instance set. Our results
highlight the efficacy of instance selection in refining DAC policies for
diverse instance spaces.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spontaneous Style Text-to-Speech Synthesis with Controllable Spontaneous
  Behaviors Based on Language Models <span class="chip">INTERSPEECH 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13509v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13509v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weiqin Li, Peiji Yang, Yicheng Zhong, Yixuan Zhou, Zhisheng Wang, Zhiyong Wu, Xixin Wu, Helen Meng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spontaneous style speech synthesis, which aims to generate human-like speech,
often encounters challenges due to the scarcity of high-quality data and
limitations in model capabilities. Recent language model-based TTS systems can
be trained on large, diverse, and low-quality speech datasets, resulting in
highly natural synthesized speech. However, they are limited by the difficulty
of simulating various spontaneous behaviors and capturing prosody variations in
spontaneous speech. In this paper, we propose a novel spontaneous speech
synthesis system based on language models. We systematically categorize and
uniformly model diverse spontaneous behaviors. Moreover, fine-grained prosody
modeling is introduced to enhance the model's ability to capture subtle prosody
variations in spontaneous speech.Experimental results show that our proposed
method significantly outperforms the baseline methods in terms of prosody
naturalness and spontaneous behavior naturalness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by INTERSPEECH 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Training Foundation Models as Data Compression: On Information, Model
  Weights and Copyright Law 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13493v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13493v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giorgio Franceschelli, Claudia Cevenini, Mirco Musolesi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The training process of foundation models as for other classes of deep
learning systems is based on minimizing the reconstruction error over a
training set. For this reason, they are susceptible to the memorization and
subsequent reproduction of training samples. In this paper, we introduce a
training-as-compressing perspective, wherein the model's weights embody a
compressed representation of the training data. From a copyright standpoint,
this point of view implies that the weights could be considered a reproduction
or a derivative work of a potentially protected set of works. We investigate
the technical and legal challenges that emerge from this framing of the
copyright of outputs generated by foundation models, including their
implications for practitioners and researchers. We demonstrate that adopting an
information-centric approach to the problem presents a promising pathway for
tackling these emerging complex legal issues.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for spotlight presentation at GenLaw'24, see
  https://www.genlaw.org/2024-icml-papers#training-foundation-models-as-data-compression-on-information-model-weights-and-copyright-law</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LIMT: Language-Informed Multi-Task Visual World Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13466v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13466v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elie Aljalbout, Nikolaos Sotirakis, Patrick van der Smagt, Maximilian Karl, Nutan Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most recent successes in robot reinforcement learning involve learning a
specialized single-task agent.
  However, robots capable of performing multiple tasks can be much more
valuable in real-world applications.
  Multi-task reinforcement learning can be very challenging due to the
increased sample complexity and the potentially conflicting task objectives.
  Previous work on this topic is dominated by model-free approaches.
  The latter can be very sample inefficient even when learning specialized
single-task agents.
  In this work, we focus on model-based multi-task reinforcement learning.
  We propose a method for learning multi-task visual world models, leveraging
pre-trained language models to extract semantically meaningful task
representations.
  These representations are used by the world model and policy to reason about
task similarity in dynamics and behavior.
  Our results highlight the benefits of using language-driven task
representations for world models and a clear advantage of model-based
multi-task learning over the more common model-free paradigm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SA-DVAE: Improving Zero-Shot Skeleton-Based Action Recognition by
  Disentangled Variational Autoencoders <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13460v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13460v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sheng-Wei Li, Zi-Xiang Wei, Wei-Jie Chen, Yi-Hsin Yu, Chih-Yuan Yang, Jane Yung-jen Hsu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing zero-shot skeleton-based action recognition methods utilize
projection networks to learn a shared latent space of skeleton features and
semantic embeddings. The inherent imbalance in action recognition datasets,
characterized by variable skeleton sequences yet constant class labels,
presents significant challenges for alignment. To address the imbalance, we
propose SA-DVAE -- Semantic Alignment via Disentangled Variational
Autoencoders, a method that first adopts feature disentanglement to separate
skeleton features into two independent parts -- one is semantic-related and
another is irrelevant -- to better align skeleton and semantic features. We
implement this idea via a pair of modality-specific variational autoencoders
coupled with a total correction penalty. We conduct experiments on three
benchmark datasets: NTU RGB+D, NTU RGB+D 120 and PKU-MMD, and our experimental
results show that SA-DAVE produces improved performance over existing methods.
The code is available at https://github.com/pha123661/SA-DVAE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ All Roads Lead to Rome? Exploring Representational Similarities Between
  Latent Spaces of Generative Image Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13449v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13449v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Charumathi Badrinath, Usha Bhalla, Alex Oesterling, Suraj Srinivas, Himabindu Lakkaraju
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Do different generative image models secretly learn similar underlying
representations? We investigate this by measuring the latent space similarity
of four different models: VAEs, GANs, Normalizing Flows (NFs), and Diffusion
Models (DMs). Our methodology involves training linear maps between frozen
latent spaces to "stitch" arbitrary pairs of encoders and decoders and
measuring output-based and probe-based metrics on the resulting "stitched''
models. Our main findings are that linear maps between latent spaces of
performant models preserve most visual information even when latent sizes
differ; for CelebA models, gender is the most similarly represented probe-able
attribute. Finally we show on an NF that latent space representations converge
early in training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Out-of-Vocabulary Performance of Indian TTS Systems for
  Practical Applications through Low-Effort Data Strategies <span class="chip">INTERSPEECH 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13435v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13435v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Srija Anand, Praveen Srinivasa Varadhan, Ashwin Sankar, Giri Raju, Mitesh M. Khapra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Publicly available TTS datasets for low-resource languages like Hindi and
Tamil typically contain 10-20 hours of data, leading to poor vocabulary
coverage. This limitation becomes evident in downstream applications where
domain-specific vocabulary coupled with frequent code-mixing with English,
results in many OOV words. To highlight this problem, we create a benchmark
containing OOV words from several real-world applications. Indeed,
state-of-the-art Hindi and Tamil TTS systems perform poorly on this OOV
benchmark, as indicated by intelligibility tests. To improve the model's OOV
performance, we propose a low-effort and economically viable strategy to obtain
more training data. Specifically, we propose using volunteers as opposed to
high quality voice artists to record words containing character bigrams unseen
in the training data. We show that using such inexpensive data, the model's
performance improves on OOV words, while not affecting voice quality and
in-domain performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at INTERSPEECH 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Art of Imitation: Learning Long-Horizon Manipulation Tasks from Few
  Demonstrations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13432v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13432v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jan Ole von Hartz, Tim Welschehold, Abhinav Valada, Joschka Boedecker
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Task Parametrized Gaussian Mixture Models (TP-GMM) are a sample-efficient
method for learning object-centric robot manipulation tasks. However, there are
several open challenges to applying TP-GMMs in the wild. In this work, we
tackle three crucial challenges synergistically. First, end-effector velocities
are non-Euclidean and thus hard to model using standard GMMs. We thus propose
to factorize the robot's end-effector velocity into its direction and
magnitude, and model them using Riemannian GMMs. Second, we leverage the
factorized velocities to segment and sequence skills from complex demonstration
trajectories. Through the segmentation, we further align skill trajectories and
hence leverage time as a powerful inductive bias. Third, we present a method to
automatically detect relevant task parameters per skill from visual
observations. Our approach enables learning complex manipulation tasks from
just five demonstrations while using only RGB-D observations. Extensive
experimental evaluations on RLBench demonstrate that our approach achieves
state-of-the-art performance with 20-fold improved sample efficiency. Our
policies generalize across different environments, object instances, and object
positions, while the learned skills are reusable.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Out-of-Distribution Generalization of Trajectory Prediction
  for Autonomous Driving via Polynomial Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13431v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13431v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yue Yao, Shengchao Yan, Daniel Goehring, Wolfram Burgard, Joerg Reichardt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Robustness against Out-of-Distribution (OoD) samples is a key performance
indicator of a trajectory prediction model. However, the development and
ranking of state-of-the-art (SotA) models are driven by their In-Distribution
(ID) performance on individual competition datasets. We present an OoD testing
protocol that homogenizes datasets and prediction tasks across two large-scale
motion datasets. We introduce a novel prediction algorithm based on polynomial
representations for agent trajectory and road geometry on both the input and
output sides of the model. With a much smaller model size, training effort, and
inference time, we reach near SotA performance for ID testing and significantly
improve robustness in OoD testing. Within our OoD testing protocol, we further
study two augmentation strategies of SotA models and their effects on model
generalization. Highlighting the contrast between ID and OoD performance, we
suggest adding OoD testing to the evaluation criteria of trajectory prediction
models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Dynamic Feature Acquisition on Medical Time Series by Maximizing
  Conditional Mutual Information <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13429v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13429v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fedor Sergeev, Paola Malsot, Gunnar Rätsch, Vincent Fortuin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowing which features of a multivariate time series to measure and when is a
key task in medicine, wearables, and robotics. Better acquisition policies can
reduce costs while maintaining or even improving the performance of downstream
predictors. Inspired by the maximization of conditional mutual information, we
propose an approach to train acquirers end-to-end using only the downstream
loss. We show that our method outperforms random acquisition policy, matches a
model with an unrestrained budget, but does not yet overtake a static
acquisition strategy. We highlight the assumptions and outline avenues for
future work.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Presented at the ICML 2024 Next Generation of Sequence Modeling
  Architectures (NGSM) Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring End-to-end Differentiable Neural Charged Particle Tracking --
  A Loss Landscape Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13420v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13420v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tobias Kortus, Ralf Keidel, Nicolas R. Gauger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Measurement and analysis of high energetic particles for scientific, medical
or industrial applications is a complex procedure, requiring the design of
sophisticated detector and data processing systems. The development of adaptive
and differentiable software pipelines using a combination of conventional and
machine learning algorithms is therefore getting ever more important to
optimize and operate the system efficiently while maintaining end-to-end (E2E)
differentiability. We propose for the application of charged particle tracking
an E2E differentiable decision-focused learning scheme using graph neural
networks with combinatorial components solving a linear assignment problem for
each detector layer. We demonstrate empirically that including differentiable
variations of discrete assignment operations allows for efficient network
optimization, working better or on par with approaches that lack E2E
differentiability. In additional studies, we dive deeper into the optimization
process and provide further insights from a loss landscape perspective. We
demonstrate that while both methods converge into similar performing, globally
well-connected regions, they suffer under substantial predictive instability
across initialization and optimization methods, which can have unpredictable
consequences on the performance of downstream tasks such as image
reconstruction. We also point out a dependency between the interpolation factor
of the gradient estimator and the prediction stability of the model, suggesting
the choice of sufficiently small values. Given the strong global connectivity
of learned solutions and the excellent training performance, we argue that E2E
differentiability provides, besides the general availability of gradient
information, an important tool for robust particle tracking to mitigate
prediction instabilities by favoring solutions that perform well on downstream
tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From Words to Worlds: Compositionality for Cognitive Architectures <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13419v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13419v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruchira Dhar, Anders Søgaard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are very performant connectionist systems, but
do they exhibit more compositionality? More importantly, is that part of why
they perform so well? We present empirical analyses across four LLM families
(12 models) and three task categories, including a novel task introduced below.
Our findings reveal a nuanced relationship in learning of compositional
strategies by LLMs -- while scaling enhances compositional abilities,
instruction tuning often has a reverse effect. Such disparity brings forth some
open issues regarding the development and improvement of large language models
in alignment with human cognitive capacities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICML 2024 Workshop on LLMs & Cognition</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Correcting the Mythos of KL-Regularization: Direct Alignment without
  Overparameterization via Chi-squared Preference Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13399v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13399v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Audrey Huang, Wenhao Zhan, Tengyang Xie, Jason D. Lee, Wen Sun, Akshay Krishnamurthy, Dylan J. Foster
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language model alignment methods, such as reinforcement learning from human
feedback (RLHF), have led to impressive advances in language model
capabilities, but existing techniques are limited by a widely observed
phenomenon known as overoptimization, where the quality of the language model
plateaus or degrades over the course of the alignment process. Overoptimization
is often attributed to overfitting to an inaccurate reward model, and while it
can be mitigated through online data collection, this is infeasible in many
settings. This raises a fundamental question: Do existing offline alignment
algorithms make the most of the data they have, or can their sample-efficiency
be improved further?
  We address this question with a new algorithm for offline alignment,
$\chi^2$-Preference Optimization ($\chi$PO). $\chi$PO is a one-line change to
Direct Preference Optimization (DPO; Rafailov et al., 2023), which only
involves modifying the logarithmic link function in the DPO objective. Despite
this minimal change, $\chi$PO implicitly implements the principle of pessimism
in the face of uncertainty via regularization with the $\chi^2$-divergence --
which quantifies uncertainty more effectively than KL-regularization -- and
provably alleviates overoptimization, achieving sample-complexity guarantees
based on single-policy concentrability -- the gold standard in offline
reinforcement learning. $\chi$PO's simplicity and strong guarantees make it the
first practical and general-purpose offline alignment algorithm that is
provably robust to overoptimization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Open-World Visual Reasoning by a Neuro-Symbolic Program of Zero-Shot
  Symbols 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13382v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13382v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gertjan Burghouts, Fieke Hillerström, Erwin Walraven, Michael van Bekkum, Frank Ruis, Joris Sijs, Jelle van Mil, Judith Dijk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the problem of finding spatial configurations of multiple objects
in images, e.g., a mobile inspection robot is tasked to localize abandoned
tools on the floor. We define the spatial configuration of objects by
first-order logic in terms of relations and attributes. A neuro-symbolic
program matches the logic formulas to probabilistic object proposals for the
given image, provided by language-vision models by querying them for the
symbols. This work is the first to combine neuro-symbolic programming
(reasoning) and language-vision models (learning) to find spatial
configurations of objects in images in an open world setting. We show the
effectiveness by finding abandoned tools on floors and leaking pipes. We find
that most prediction errors are due to biases in the language-vision model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Geometric Active Exploration in Markov Decision Processes: the Benefit
  of Abstraction <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13364v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13364v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Riccardo De Santi, Federico Arangath Joseph, Noah Liniger, Mirco Mutti, Andreas Krause
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  How can a scientist use a Reinforcement Learning (RL) algorithm to design
experiments over a dynamical system's state space? In the case of finite and
Markovian systems, an area called Active Exploration (AE) relaxes the
optimization problem of experiments design into Convex RL, a generalization of
RL admitting a wider notion of reward. Unfortunately, this framework is
currently not scalable and the potential of AE is hindered by the vastness of
experiment spaces typical of scientific discovery applications. However, these
spaces are often endowed with natural geometries, e.g., permutation invariance
in molecular design, that an agent could leverage to improve the statistical
and computational efficiency of AE. To achieve this, we bridge AE and MDP
homomorphisms, which offer a way to exploit known geometric structures via
abstraction. Towards this goal, we make two fundamental contributions: we
extend MDP homomorphisms formalism to Convex RL, and we present, to the best of
our knowledge, the first analysis that formally captures the benefit of
abstraction via homomorphisms on sample efficiency. Ultimately, we propose the
Geometric Active Exploration (GAE) algorithm, which we analyse theoretically
and experimentally in environments motivated by problems in scientific
discovery.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Capturing Style in Author and Document Representation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13358v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13358v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Enzo Terreau, Antoine Gourru, Julien Velcin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A wide range of Deep Natural Language Processing (NLP) models integrates
continuous and low dimensional representations of words and documents.
Surprisingly, very few models study representation learning for authors. These
representations can be used for many NLP tasks, such as author identification
and classification, or in recommendation systems. A strong limitation of
existing works is that they do not explicitly capture writing style, making
them hardly applicable to literary data. We therefore propose a new
architecture based on Variational Information Bottleneck (VIB) that learns
embeddings for both authors and documents with a stylistic constraint. Our
model fine-tunes a pre-trained document encoder. We stimulate the detection of
writing style by adding predefined stylistic features making the representation
axis interpretable with respect to writing style indicators. We evaluate our
method on three datasets: a literary corpus extracted from the Gutenberg
Project, the Blog Authorship Corpus and IMDb62, for which we show that it
matches or outperforms strong/recent baselines in authorship attribution while
capturing much more accurately the authors stylistic aspects.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reconstruct the Pruned Model without Any Retraining 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13331v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13331v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pingjie Wang, Ziqing Fan, Shengchao Hu, Zhe Chen, Yanfeng Wang, Yu Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Structured pruning is a promising hardware-friendly compression technique for
large language models (LLMs), which is expected to be retraining-free to avoid
the enormous retraining cost. This retraining-free paradigm involves (1)
pruning criteria to define the architecture and (2) distortion reconstruction
to restore performance. However, existing methods often emphasize pruning
criteria while using reconstruction techniques that are specific to certain
modules or criteria, resulting in limited generalizability. To address this, we
introduce the Linear Interpolation-based Adaptive Reconstruction (LIAR)
framework, which is both efficient and effective. LIAR does not require
back-propagation or retraining and is compatible with various pruning criteria
and modules. By applying linear interpolation to the preserved weights, LIAR
minimizes reconstruction error and effectively reconstructs the pruned output.
Our evaluations on benchmarks such as GLUE, SQuAD, WikiText, and common sense
reasoning show that LIAR enables a BERT model to maintain 98% accuracy even
after removing 50% of its parameters and achieves top performance for LLaMA in
just a few minutes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RISC-V RVV efficiency for ANN algorithms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13326v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13326v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Konstantin Rumyantsev, Pavel Yakovlev, Andrey Gorshkov, Andrey P. Sokolov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Handling vast amounts of data is crucial in today's world. The growth of
high-performance computing has created a need for parallelization, particularly
in the area of machine learning algorithms such as ANN (Approximate Nearest
Neighbors). To improve the speed of these algorithms, it is important to
optimize them for specific processor architectures. RISC-V (Reduced Instruction
Set Computer Five) is one of the modern processor architectures, which features
a vector instruction set called RVV (RISC-V Vector Extension). In machine
learning algorithms, vector extensions are widely utilized to improve the
processing of voluminous data. This study examines the effectiveness of
applying RVV to commonly used ANN algorithms. The algorithms were adapted for
RISC-V and optimized using RVV after identifying the primary bottlenecks.
Additionally, we developed a theoretical model of a parameterized vector block
and identified the best on average configuration that demonstrates the highest
theoretical performance of the studied ANN algorithms when the other CPU
parameters are fixed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deterministic Trajectory Optimization through Probabilistic Optimal
  Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13316v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13316v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Mahmoudi Filabadi, Tom Lefebvre, Guillaume Crevecoeur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article proposes two new algorithms tailored to discrete-time
deterministic finite-horizon nonlinear optimal control problems or so-called
trajectory optimization problems. Both algorithms are inspired by a novel
theoretical paradigm known as probabilistic optimal control, that reformulates
optimal control as an equivalent probabilistic inference problem. This
perspective allows to address the problem using the Expectation-Maximization
algorithm. We show that the application of this algorithm results in a fixed
point iteration of probabilistic policies that converge to the deterministic
optimal policy. Two strategies for policy evaluation are discussed, using
state-of-the-art uncertainty quantification methods resulting into two distinct
algorithms. The algorithms are structurally closest related to the differential
dynamic programming algorithm and related methods that use sigma-point methods
to avoid direct gradient evaluations. The main advantage of our work is an
improved balance between exploration and exploitation over the iterations,
leading to improved numerical stability and accelerated convergence. These
properties are demonstrated on different nonlinear systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A deep latent variable model for semi-supervised multi-unit soft sensing
  in industrial processes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13310v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13310v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bjarne Grimstad, Kristian Løvland, Lars S. Imsland, Vidar Gunnerud
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In many industrial processes, an apparent lack of data limits the development
of data-driven soft sensors. There are, however, often opportunities to learn
stronger models by being more data-efficient. To achieve this, one can leverage
knowledge about the data from which the soft sensor is learned. Taking
advantage of properties frequently possessed by industrial data, we introduce a
deep latent variable model for semi-supervised multi-unit soft sensing. This
hierarchical, generative model is able to jointly model different units, as
well as learning from both labeled and unlabeled data.
  An empirical study of multi-unit soft sensing is conducted using two
datasets: a synthetic dataset of single-phase fluid flow, and a large, real
dataset of multi-phase flow in oil and gas wells. We show that by combining
semi-supervised and multi-task learning, the proposed model achieves superior
results, outperforming current leading methods for this soft sensing problem.
We also show that when a model has been trained on a multi-unit dataset, it may
be finetuned to previously unseen units using only a handful of data points. In
this finetuning procedure, unlabeled data improve soft sensor performance;
remarkably, this is true even when no labeled data are available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mean Teacher based SSL Framework for Indoor Localization Using Wi-Fi
  RSSI Fingerprinting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13303v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13303v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sihao Li, Zhe Tang, Kyeong Soo Kim, Jeremy S. Smith
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Wi-Fi fingerprinting is widely applied for indoor localization due to the
widespread availability of Wi-Fi devices. However, traditional methods are not
ideal for multi-building and multi-floor environments due to the scalability
issues. Therefore, more and more researchers have employed deep learning
techniques to enable scalable indoor localization. This paper introduces a
novel semi-supervised learning framework for neural networks based on wireless
access point selection, noise injection, and Mean Teacher model, which
leverages unlabeled fingerprints to enhance localization performance. The
proposed framework can manage hybrid in/outsourcing and voluntarily contributed
databases and continually expand the fingerprint database with newly submitted
unlabeled fingerprints during service. The viability of the proposed framework
was examined using two established deep-learning models with the UJIIndoorLoc
database. The experimental results suggest that the proposed framework
significantly improves localization performance compared to the supervised
learning-based approach in terms of floor-level coordinate estimation using
EvAAL metric. It shows enhancements up to 10.99% and 8.98% in the former
scenario and 4.25% and 9.35% in the latter, respectively with additional
studies highlight the importance of the essential components of the proposed
framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 10 figures, under preparation for a journal publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13301v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13301v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junying Chen, Chi Gui, Anningzhe Gao, Ke Ji, Xidong Wang, Xiang Wan, Benyou Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The field of medical diagnosis has undergone a significant transformation
with the advent of large language models (LLMs), yet the challenges of
interpretability within these models remain largely unaddressed. This study
introduces Chain-of-Diagnosis (CoD) to enhance the interpretability of
LLM-based medical diagnostics. CoD transforms the diagnostic process into a
diagnostic chain that mirrors a physician's thought process, providing a
transparent reasoning pathway. Additionally, CoD outputs the disease confidence
distribution to ensure transparency in decision-making. This interpretability
makes model diagnostics controllable and aids in identifying critical symptoms
for inquiry through the entropy reduction of confidences. With CoD, we
developed DiagnosisGPT, capable of diagnosing 9604 diseases. Experimental
results demonstrate that DiagnosisGPT outperforms other LLMs on diagnostic
benchmarks. Moreover, DiagnosisGPT provides interpretability while ensuring
controllability in diagnostic rigor.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scikit-fingerprints: easy and efficient computation of molecular
  fingerprints in Python 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13291v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13291v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jakub Adamczyk, Piotr Ludynia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we present \textit{scikit-fingerprints}, a Python package for
computation of molecular fingerprints for applications in chemoinformatics. Our
library offers an industry-standard scikit-learn interface, allowing intuitive
usage and easy integration with machine learning pipelines. It is also highly
optimized, featuring parallel computation that enables efficient processing of
large molecular datasets. Currently, \textit{scikit-fingerprints} stands as the
most feature-rich library in the Python ecosystem, offering over 30 molecular
fingerprints. Our library simplifies chemoinformatics tasks based on molecular
fingerprints, including molecular property prediction and virtual screening. It
is also flexible, highly efficient, and fully open source.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hierarchical Stage-Wise Training of Linked Deep Neural Networks for
  Multi-Building and Multi-Floor Indoor Localization Based on Wi-Fi RSSI
  Fingerprinting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13288v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13288v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sihao Li, Kyeong Soo Kim, Zhe Tang,  Graduate, Jeremy S. Smith
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present a new solution to the problem of large-scale
multi-building and multi-floor indoor localization based on linked neural
networks, where each neural network is dedicated to a sub-problem and trained
under a hierarchical stage-wise training framework. When the measured data from
sensors have a hierarchical representation as in multi-building and multi-floor
indoor localization, it is important to exploit the hierarchical nature in data
processing to provide a scalable solution. In this regard, the hierarchical
stage-wise training framework extends the original stage-wise training
framework to the case of multiple linked networks by training a lower-hierarchy
network based on the prior knowledge gained from the training of
higher-hierarchy networks. The experimental results with the publicly-available
UJIIndoorLoc multi-building and multi-floor Wi-Fi RSSI fingerprint database
demonstrate that the linked neural networks trained under the proposed
hierarchical stage-wise training framework can achieve a three-dimensional
localization error of 8.19 m, which, to the best of the authors' knowledge, is
the most accurate result ever obtained for neural network-based models trained
and evaluated with the full datasets of the UJIIndoorLoc database, and that,
when applied to a model based on hierarchical convolutional neural networks,
the proposed training framework can also significantly reduce the
three-dimensional localization error from 11.78 m to 8.71 m.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 5 figures, under review for journal publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Auditing Local Explanations is Hard 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13281v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13281v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robi Bhattacharjee, Ulrike von Luxburg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In sensitive contexts, providers of machine learning algorithms are
increasingly required to give explanations for their algorithms' decisions.
However, explanation receivers might not trust the provider, who potentially
could output misleading or manipulated explanations. In this work, we
investigate an auditing framework in which a third-party auditor or a
collective of users attempts to sanity-check explanations: they can query model
decisions and the corresponding local explanations, pool all the information
received, and then check for basic consistency properties. We prove upper and
lower bounds on the amount of queries that are needed for an auditor to succeed
within this framework. Our results show that successful auditing requires a
potentially exorbitant number of queries -- particularly in high dimensional
cases. Our analysis also reveals that a key property is the ``locality'' of the
provided explanations -- a quantity that so far has not been paid much
attention to in the explainability literature. Looking forward, our results
suggest that for complex high-dimensional settings, merely providing a
pointwise prediction and explanation could be insufficient, as there is no way
for the users to verify that the provided explanations are not completely
made-up.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>40 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Analyzing and Bridging the Gap between Maximizing Total Reward and
  Discounted Reward in Deep Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13279v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13279v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuyu Yin, Fei Wen, Peilin Liu, Tao Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In deep reinforcement learning applications, maximizing discounted reward is
often employed instead of maximizing total reward to ensure the convergence and
stability of algorithms, even though the performance metric for evaluating the
policy remains the total reward. However, the optimal policies corresponding to
these two objectives may not always be consistent. To address this issue, we
analyzed the suboptimality of the policy obtained through maximizing discounted
reward in relation to the policy that maximizes total reward and identified the
influence of hyperparameters. Additionally, we proposed sufficient conditions
for aligning the optimal policies of these two objectives under various
settings. The primary contributions are as follows: We theoretically analyzed
the factors influencing performance when using discounted reward as a proxy for
total reward, thereby enhancing the theoretical understanding of this scenario.
Furthermore, we developed methods to align the optimal policies of the two
objectives in certain situations, which can improve the performance of
reinforcement learning algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Time Series Models: A Comprehensive <span class="highlight-title">Survey</span> and Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13278v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13278v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Wang, Haixu Wu, Jiaxiang Dong, Yong Liu, Mingsheng Long, Jianmin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Time series, characterized by a sequence of data points arranged in a
discrete-time order, are ubiquitous in real-world applications. Different from
other modalities, time series present unique challenges due to their complex
and dynamic nature, including the entanglement of nonlinear patterns and
time-variant trends. Analyzing time series data is of great significance in
real-world scenarios and has been widely studied over centuries. Recent years
have witnessed remarkable breakthroughs in the time series community, with
techniques shifting from traditional statistical methods to advanced deep
learning models. In this paper, we delve into the design of deep time series
models across various analysis tasks and review the existing literature from
two perspectives: basic modules and model architectures. Further, we develop
and release Time Series Library (TSLib) as a fair benchmark of deep time series
models for diverse analysis tasks, which implements 24 mainstream models,
covers 30 datasets from different domains, and supports five prevalent analysis
tasks. Based on TSLib, we thoroughly evaluate 12 advanced deep time series
models on different tasks. Empirical results indicate that models with specific
structures are well-suited for distinct analytical tasks, which offers insights
for research and adoption of deep time series models. Code is available at
https://github.com/thuml/Time-Series-Library.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>\</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mixture of Experts based Multi-task Supervise Learning from Crowds 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13268v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13268v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tao Han, Huaixuan Shi, Xinyi Ding, Xiao Ma, Huamao Gu, Yili Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing truth inference methods in crowdsourcing aim to map redundant labels
and items to the ground truth. They treat the ground truth as hidden variables
and use statistical or deep learning-based worker behavior models to infer the
ground truth. However, worker behavior models that rely on ground truth hidden
variables overlook workers' behavior at the item feature level, leading to
imprecise characterizations and negatively impacting the quality of truth
inference. This paper proposes a new paradigm of multi-task supervised learning
from crowds, which eliminates the need for modeling of items's ground truth in
worker behavior models. Within this paradigm, we propose a worker behavior
model at the item feature level called Mixture of Experts based Multi-task
Supervised Learning from Crowds (MMLC). Two truth inference strategies are
proposed within MMLC. The first strategy, named MMLC-owf, utilizes clustering
methods in the worker spectral space to identify the projection vector of the
oracle worker. Subsequently, the labels generated based on this vector are
considered as the inferred truth. The second strategy, called MMLC-df, employs
the MMLC model to fill the crowdsourced data, which can enhance the
effectiveness of existing truth inference methods. Experimental results
demonstrate that MMLC-owf outperforms state-of-the-art methods and MMLC-df
enhances the quality of existing truth inference methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Motif-Consistent Counterfactuals with Adversarial Refinement for
  Graph-Level Anomaly Detection <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13251v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13251v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chunjing Xiao, Shikang Pang, Wenxin Tai, Yanlong Huang, Goce Trajcevski, Fan Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph-level anomaly detection is significant in diverse domains. To improve
detection performance, counterfactual graphs have been exploited to benefit the
generalization capacity by learning causal relations. Most existing studies
directly introduce perturbations (e.g., flipping edges) to generate
counterfactual graphs, which are prone to alter the semantics of generated
examples and make them off the data manifold, resulting in sub-optimal
performance. To address these issues, we propose a novel approach,
Motif-consistent Counterfactuals with Adversarial Refinement (MotifCAR), for
graph-level anomaly detection. The model combines the motif of one graph, the
core subgraph containing the identification (category) information, and the
contextual subgraph (non-motif) of another graph to produce a raw
counterfactual graph. However, the produced raw graph might be distorted and
cannot satisfy the important counterfactual properties: Realism, Validity,
Proximity and Sparsity. Towards that, we present a Generative Adversarial
Network (GAN)-based graph optimizer to refine the raw counterfactual graphs. It
adopts the discriminator to guide the generator to generate graphs close to
realistic data, i.e., meet the property Realism. Further, we design the motif
consistency to force the motif of the generated graphs to be consistent with
the realistic graphs, meeting the property Validity. Also, we devise the
contextual loss and connection loss to control the contextual subgraph and the
newly added links to meet the properties Proximity and Sparsity. As a result,
the model can generate high-quality counterfactual graphs. Experiments
demonstrate the superiority of MotifCAR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by KDD 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Transformer</span>s with Stochastic Competition for Tabular Data Modelling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13238v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13238v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andreas Voskou, Charalambos Christoforou, Sotirios Chatzis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the prevalence and significance of tabular data across numerous
industries and fields, it has been relatively underexplored in the realm of
deep learning. Even today, neural networks are often overshadowed by techniques
such as gradient boosted decision trees (GBDT). However, recent models are
beginning to close this gap, outperforming GBDT in various setups and garnering
increased attention in the field. Inspired by this development, we introduce a
novel stochastic deep learning model specifically designed for tabular data.
The foundation of this model is a Transformer-based architecture, carefully
adapted to cater to the unique properties of tabular data through strategic
architectural modifications and leveraging two forms of stochastic competition.
First, we employ stochastic "Local Winner Takes All" units to promote
generalization capacity through stochasticity and sparsity. Second, we
introduce a novel embedding layer that selects among alternative linear
embedding layers through a mechanism of stochastic competition. The
effectiveness of the model is validated on a variety of widely-used, publicly
available datasets. We demonstrate that, through the incorporation of these
elements, our model yields high performance and marks a significant advancement
in the application of deep learning to tabular data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Large Language Models for Anxiety and Depression
  Classification using Counseling and Psychotherapy Transcripts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13228v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13228v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junwei Sun, Siqi Ma, Yiran Fan, Peter Washington
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We aim to evaluate the efficacy of traditional machine learning and large
language models (LLMs) in classifying anxiety and depression from long
conversational transcripts. We fine-tune both established transformer models
(BERT, RoBERTa, Longformer) and more recent large models (Mistral-7B), trained
a Support Vector Machine with feature engineering, and assessed GPT models
through prompting. We observe that state-of-the-art models fail to enhance
classification outcomes compared to traditional machine learning methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Non-Contact Breath Rate Classification Using SVM Model and mmWave Radar
  Sensor Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13222v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13222v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Wassaf Ali, Ayushi Gupta, Mujeev Khan, Mohd Wajid
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work presents the use of frequency modulated continuous wave (FMCW)
radar technology combined with a machine learning model to differentiate
between normal and abnormal breath rates. The proposed system non-contactly
collects data using FMCW radar, which depends on breath rates. Various support
vector machine kernels are used to classify the observed data into normal and
abnormal states. Prolonged experiments show good accuracy in breath rate
classification, confirming the model's efficacy. The best accuracy is 95
percent with the smallest number of support vectors in the case of the
quadratic polynomial kernel.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 Pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LiNR: Model Based Neural Retrieval on GPUs at LinkedIn 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13218v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13218v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fedor Borisyuk, Qingquan Song, Mingzhou Zhou, Ganesh Parameswaran, Madhu Arun, Siva Popuri, Tugrul Bingol, Zhuotao Pei, Kuang-Hsuan Lee, Lu Zheng, Qizhan Shao, Ali Naqvi, Sen Zhou, Aman Gupta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces LiNR, LinkedIn's large-scale, GPU-based retrieval
system. LiNR supports a billion-sized index on GPU models. We discuss our
experiences and challenges in creating scalable, differentiable search indexes
using TensorFlow and PyTorch at production scale. In LiNR, both items and model
weights are integrated into the model binary. Viewing index construction as a
form of model training, we describe scaling our system for large indexes,
incorporating full scans and efficient filtering. A key focus is on enabling
attribute-based pre-filtering for exhaustive GPU searches, addressing the
common challenge of post-filtering in KNN searches that often reduces system
quality. We further provide multi-embedding retrieval algorithms and strategies
for tackling cold start issues in retrieval. Our advancements in supporting
larger indexes through quantization are also discussed. We believe LiNR
represents one of the industry's first Live-updated model-based retrieval
indexes. Applied to out-of-network post recommendations on LinkedIn Feed, LiNR
has contributed to a 3% relative increase in professional daily active users.
We envisage LiNR as a step towards integrating retrieval and ranking into a
single GPU model, simplifying complex infrastructures and enabling end-to-end
optimization of the entire differentiable infrastructure through gradient
descent.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive Foundation Models for Online Decisions: HyperAgent with Fast
  Incremental Uncertainty Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13195v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13195v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingru Li, Jiawei Xu, Zhi-Quan Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation models often struggle with uncertainty when faced with new
situations in online decision-making, necessitating scalable and efficient
exploration to resolve this uncertainty. We introduce GPT-HyperAgent, an
augmentation of GPT with HyperAgent for uncertainty-aware, scalable exploration
in contextual bandits, a fundamental online decision problem involving natural
language input. We prove that HyperAgent achieves fast incremental uncertainty
estimation with $\tilde{O}(\log T)$ per-step computational complexity over $T$
periods under the linear realizable assumption. Our analysis demonstrates that
HyperAgent's regret order matches that of exact Thompson sampling in linear
contextual bandits, closing a significant theoretical gap in scalable
exploration. Empirical results in real-world contextual bandit tasks, such as
automated content moderation with human feedback, validate the practical
effectiveness of GPT-HyperAgent for safety-critical decisions. Our code is
open-sourced at \url{https://github.com/szrlee/GPT-HyperAgent/}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>41 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Multivariate Time Series Forecasting against Intra- and
  Inter-Series Transitional Shift 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13194v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13194v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hui He, Qi Zhang, Kun Yi, Xiaojun Xue, Shoujin Wang, Liang Hu, Longbing Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The non-stationary nature of real-world Multivariate Time Series (MTS) data
presents forecasting models with a formidable challenge of the time-variant
distribution of time series, referred to as distribution shift. Existing
studies on the distribution shift mostly adhere to adaptive normalization
techniques for alleviating temporal mean and covariance shifts or time-variant
modeling for capturing temporal shifts. Despite improving model generalization,
these normalization-based methods often assume a time-invariant transition
between outputs and inputs but disregard specific intra-/inter-series
correlations, while time-variant models overlook the intrinsic causes of the
distribution shift. This limits model expressiveness and interpretability of
tackling the distribution shift for MTS forecasting. To mitigate such a
dilemma, we present a unified Probabilistic Graphical Model to Jointly
capturing intra-/inter-series correlations and modeling the time-variant
transitional distribution, and instantiate a neural framework called JointPGM
for non-stationary MTS forecasting. Specifically, JointPGM first employs
multiple Fourier basis functions to learn dynamic time factors and designs two
distinct learners: intra-series and inter-series learners. The intra-series
learner effectively captures temporal dynamics by utilizing temporal gates,
while the inter-series learner explicitly models spatial dynamics through
multi-hop propagation, incorporating Gumbel-softmax sampling. These two types
of series dynamics are subsequently fused into a latent variable, which is
inversely employed to infer time factors, generate final prediction, and
perform reconstruction. We validate the effectiveness and efficiency of
JointPGM through extensive experiments on six highly non-stationary MTS
datasets, achieving state-of-the-art forecasting performance of MTS
forecasting.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-Driven Estimation of Conditional Expectations, Application to
  Optimal Stopping and Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13189v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13189v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        George V. Moustakides
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When the underlying conditional density is known, conditional expectations
can be computed analytically or numerically. When, however, such knowledge is
not available and instead we are given a collection of training data, the goal
of this work is to propose simple and purely data-driven means for estimating
directly the desired conditional expectation. Because conditional expectations
appear in the description of a number of stochastic optimization problems with
the corresponding optimal solution satisfying a system of nonlinear equations,
we extend our data-driven method to cover such cases as well. We test our
methodology by applying it to Optimal Stopping and Optimal Action Policy in
Reinforcement Learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SpaDiT: Diffusion <span class="highlight-title">Transformer</span> for Spatial Gene Expression Prediction
  using scRNA-seq 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13182v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13182v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyu Li, Fangfang Zhu, Wenwen Min
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid development of spatial transcriptomics (ST) technologies is
revolutionizing our understanding of the spatial organization of biological
tissues. Current ST methods, categorized into next-generation sequencing-based
(seq-based) and fluorescence in situ hybridization-based (image-based) methods,
offer innovative insights into the functional dynamics of biological tissues.
However, these methods are limited by their cellular resolution and the
quantity of genes they can detect. To address these limitations, we propose
SpaDiT, a deep learning method that utilizes a diffusion generative model to
integrate scRNA-seq and ST data for the prediction of undetected genes. By
employing a Transformer-based diffusion model, SpaDiT not only accurately
predicts unknown genes but also effectively generates the spatial structure of
ST genes. We have demonstrated the effectiveness of SpaDiT through extensive
experiments on both seq-based and image-based ST data. SpaDiT significantly
contributes to ST gene prediction methods with its innovative approach.
Compared to eight leading baseline methods, SpaDiT achieved state-of-the-art
performance across multiple metrics, highlighting its substantial
bioinformatics contribution.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Compressed models are NOT miniature versions of large models <span class="chip">CIKM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13174v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13174v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohit Raj Rai, Rishant Pal, Amit Awekar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large neural models are often compressed before deployment. Model compression
is necessary for many practical reasons, such as inference latency, memory
footprint, and energy consumption. Compressed models are assumed to be
miniature versions of corresponding large neural models. However, we question
this belief in our work. We compare compressed models with corresponding large
neural models using four model characteristics: prediction errors, data
representation, data distribution, and vulnerability to adversarial attack. We
perform experiments using the BERT-large model and its five compressed
versions. For all four model characteristics, compressed models significantly
differ from the BERT-large model. Even among compressed models, they differ
from each other on all four model characteristics. Apart from the expected loss
in model performance, there are major side effects of using compressed models
to replace large neural models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the 33rd ACM International Conference on Information and
  Knowledge Management (CIKM 2024) for the Short Research Paper track, 5 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HHGT: Hierarchical Heterogeneous Graph <span class="highlight-title">Transformer</span> for Heterogeneous
  Graph Representation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13158v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13158v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiuyu Zhu, Liang Zhang, Qianxiong Xu, Kaijun Liu, Cheng Long, Xiaoyang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the success of Heterogeneous Graph Neural Networks (HGNNs) in
modeling real-world Heterogeneous Information Networks (HINs), challenges such
as expressiveness limitations and over-smoothing have prompted researchers to
explore Graph Transformers (GTs) for enhanced HIN representation learning.
However, research on GT in HINs remains limited, with two key shortcomings in
existing work: (1) A node's neighbors at different distances in HINs convey
diverse semantics. Unfortunately, existing methods ignore such differences and
uniformly treat neighbors within a given distance in a coarse manner, which
results in semantic confusion. (2) Nodes in HINs have various types, each with
unique semantics. Nevertheless, existing methods mix nodes of different types
during neighbor aggregation, hindering the capture of proper correlations
between nodes of diverse types. To bridge these gaps, we design an innovative
structure named (k,t)-ring neighborhood, where nodes are initially organized by
their distance, forming different non-overlapping k-ring neighborhoods for each
distance. Within each k-ring structure, nodes are further categorized into
different groups according to their types, thus emphasizing the heterogeneity
of both distances and types in HINs naturally. Based on this structure, we
propose a novel Hierarchical Heterogeneous Graph Transformer (HHGT) model,
which seamlessly integrates a Type-level Transformer for aggregating nodes of
different types within each k-ring neighborhood, followed by a Ring-level
Transformer for aggregating different k-ring neighborhoods in a hierarchical
manner. Extensive experiments are conducted on downstream tasks to verify
HHGT's superiority over 14 baselines, with a notable improvement of up to
24.75% in NMI and 29.25% in ARI for node clustering task on the ACM dataset
compared to the best baseline.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Preset-Voice Matching for Privacy Regulated Speech-to-Speech Translation
  Systems <span class="chip">ACL</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13153v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13153v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Platnick, Bishoy Abdelnour, Eamon Earl, Rahul Kumar, Zahra Rezaei, Thomas Tsangaris, Faraj Lagum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, there has been increased demand for speech-to-speech
translation (S2ST) systems in industry settings. Although successfully
commercialized, cloning-based S2ST systems expose their distributors to
liabilities when misused by individuals and can infringe on personality rights
when exploited by media organizations. This work proposes a regulated S2ST
framework called Preset-Voice Matching (PVM). PVM removes cross-lingual voice
cloning in S2ST by first matching the input voice to a similar prior consenting
speaker voice in the target-language. With this separation, PVM avoids cloning
the input speaker, ensuring PVM systems comply with regulations and reduce risk
of misuse. Our results demonstrate PVM can significantly improve S2ST system
run-time in multi-speaker settings and the naturalness of S2ST synthesized
speech. To our knowledge, PVM is the first explicitly regulated S2ST framework
leveraging similarly-matched preset-voices for dynamic S2ST tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the ACL PrivateNLP 2024 Workshop, 7 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PG-Rainbow: Using Distributional Reinforcement Learning in Policy
  Gradient Methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13146v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13146v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        WooJae Jeon, KanJun Lee, Jeewoo Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces PG-Rainbow, a novel algorithm that incorporates a
distributional reinforcement learning framework with a policy gradient
algorithm. Existing policy gradient methods are sample inefficient and rely on
the mean of returns when calculating the state-action value function,
neglecting the distributional nature of returns in reinforcement learning
tasks. To address this issue, we use an Implicit Quantile Network that provides
the quantile information of the distribution of rewards to the critic network
of the Proximal Policy Optimization algorithm. We show empirical results that
through the integration of reward distribution information into the policy
network, the policy agent acquires enhanced capabilities to comprehensively
evaluate the consequences of potential actions in a given state, facilitating
more sophisticated and informed decision-making processes. We evaluate the
performance of the proposed algorithm in the Atari-2600 game suite, simulated
via the Arcade Learning Environment (ALE).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Integrated Hardware Architecture and Device Placement Search <span class="chip">ICML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13143v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13143v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Irene Wang, Jakub Tarnawski, Amar Phanishayee, Divya Mahajan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Distributed execution of deep learning training involves a dynamic interplay
between hardware accelerator architecture and device placement strategy. This
is the first work to explore the co-optimization of determining the optimal
architecture and device placement strategy through novel algorithms, improving
the balance of computational resources, memory usage, and data distribution.
Our architecture search leverages tensor and vector units, determining their
quantity and dimensionality, and on-chip and off-chip memory configurations. It
also determines the microbatch size and decides whether to recompute or stash
activations, balancing the memory footprint of training and storage size. For
each explored architecture configuration, we use an Integer Linear Program
(ILP) to find the optimal schedule for executing operators on the accelerator.
The ILP results then integrate with a dynamic programming solution to identify
the most effective device placement strategy, combining data, pipeline, and
tensor model parallelism across multiple accelerators. Our approach achieves
higher throughput on large language models compared to the state-of-the-art
TPUv4 and the Spotlight accelerator search framework. The entire source code of
PHAZE is available at https://github.com/msr-fiddle/phaze.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the 41st International Conference on Machine Learning
  (ICML), 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A light-weight and efficient punctuation and word casing prediction
  model for on-device streaming ASR 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13142v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13142v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian You, Xiangfeng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Punctuation and word casing prediction are necessary for automatic speech
recognition (ASR). With the popularity of on-device end-to-end streaming ASR
systems, the on-device punctuation and word casing prediction become a
necessity while we found little discussion on this. With the emergence of
Transformer, Transformer based models have been explored for this scenario.
However, Transformer based models are too large for on-device ASR systems. In
this paper, we propose a light-weight and efficient model that jointly predicts
punctuation and word casing in real time. The model is based on Convolutional
Neural Network (CNN) and Bidirectional Long Short-Term Memory (BiLSTM).
Experimental results on the IWSLT2011 test set show that the proposed model
obtains 9% relative improvement compared to the best of non-Transformer models
on overall F1-score. Compared to the representative of Transformer based
models, the proposed model achieves comparable results to the representative
model while being only one-fortieth its size and 2.5 times faster in terms of
inference time. It is suitable for on-device streaming ASR systems. Our code is
publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Out-of-Distribution Detection through Soft Clustering with Non-Negative
  Kernel Regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13141v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13141v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aryan Gulati, Xingjian Dong, Carlos Hurtado, Sarath Shekkizhar, Swabha Swayamdipta, Antonio Ortega
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As language models become more general purpose, increased attention needs to
be paid to detecting out-of-distribution (OOD) instances, i.e., those not
belonging to any of the distributions seen during training. Existing methods
for detecting OOD data are computationally complex and storage-intensive. We
propose a novel soft clustering approach for OOD detection based on
non-negative kernel regression. Our approach greatly reduces computational and
space complexities (up to 11x improvement in inference time and 87% reduction
in storage requirements) and outperforms existing approaches by up to 4 AUROC
points on four different benchmarks. We also introduce an entropy-constrained
version of our algorithm, which leads to further reductions in storage
requirements (up to 97% lower than comparable approaches) while retaining
competitive performance. Our soft clustering approach for OOD detection
highlights its potential for detecting tail-end phenomena in extreme-scale data
settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NeRF-MAE: Masked AutoEncoders for <span class="highlight-title">Self-Supervised</span> 3D Representation
  Learning for Neural Radiance Fields <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.01300v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.01300v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Zubair Irshad, Sergey Zakharov, Vitor Guizilini, Adrien Gaidon, Zsolt Kira, Rares Ambrus
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural fields excel in computer vision and robotics due to their ability to
understand the 3D visual world such as inferring semantics, geometry, and
dynamics. Given the capabilities of neural fields in densely representing a 3D
scene from 2D images, we ask the question: Can we scale their self-supervised
pretraining, specifically using masked autoencoders, to generate effective 3D
representations from posed RGB images. Owing to the astounding success of
extending transformers to novel data modalities, we employ standard 3D Vision
Transformers to suit the unique formulation of NeRFs. We leverage NeRF's
volumetric grid as a dense input to the transformer, contrasting it with other
3D representations such as pointclouds where the information density can be
uneven, and the representation is irregular. Due to the difficulty of applying
masked autoencoders to an implicit representation, such as NeRF, we opt for
extracting an explicit representation that canonicalizes scenes across domains
by employing the camera trajectory for sampling. Our goal is made possible by
masking random patches from NeRF's radiance and density grid and employing a
standard 3D Swin Transformer to reconstruct the masked patches. In doing so,
the model can learn the semantic and spatial structure of complete scenes. We
pretrain this representation at scale on our proposed curated posed-RGB data,
totaling over 1.8 million images. Once pretrained, the encoder is used for
effective 3D transfer learning. Our novel self-supervised pretraining for
NeRFs, NeRF-MAE, scales remarkably well and improves performance on various
challenging 3D tasks. Utilizing unlabeled posed 2D data for pretraining,
NeRF-MAE significantly outperforms self-supervised 3D pretraining and NeRF
scene understanding baselines on Front3D and ScanNet datasets with an absolute
performance improvement of over 20% AP50 and 8% AP25 for 3D object detection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024. Project Page: https://nerf-mae.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Transformer</span>s Get Stable: An End-to-End Signal Propagation Theory for
  Language Models <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.09635v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.09635v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akhil Kedia, Mohd Abbas Zaidi, Sushil Khyalia, Jungho Jung, Harshith Goka, Haejun Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In spite of their huge success, transformer models remain difficult to scale
in depth. In this work, we develop a unified signal propagation theory and
provide formulae that govern the moments of the forward and backward signal
through the transformer model. Our framework can be used to understand and
mitigate vanishing/exploding gradients, rank collapse, and instability
associated with high attention scores. We also propose DeepScaleLM, an
initialization and scaling scheme that conserves unit output/gradient moments
throughout the model, enabling the training of very deep models with 1000
layers. We find that transformer models could be much deeper - our deep models
with fewer parameters outperform shallow models in Language Modeling, Speech
Translation, and Image Classification, across encoder-only, decoder-only and
encoder-decoder variants, for both Pre-LN and Post-LN transformers, for
multiple datasets and model sizes. These improvements also translate into
improved performance on downstream Question Answering tasks and improved
robustness for Image Classification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICML 2024. Source code is available at
  https://github.com/akhilkedia/TranformersGetStable. Akhil Kedia, Mohd Abbas
  Zaidi, Sushil Khyalia equal contribution</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scalable Spatiotemporal Prediction with Bayesian Neural Fields 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.07657v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.07657v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Feras Saad, Jacob Burnim, Colin Carroll, Brian Patton, Urs Köster, Rif A. Saurous, Matthew Hoffman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spatiotemporal datasets, which consist of spatially-referenced time series,
are ubiquitous in many scientific and business-intelligence applications, such
as air pollution monitoring, disease tracking, and cloud-demand forecasting. As
modern datasets continue to increase in size and complexity, there is a growing
need for new statistical methods that are flexible enough to capture complex
spatiotemporal dynamics and scalable enough to handle large prediction
problems. This work presents the Bayesian Neural Field (BayesNF), a
domain-general statistical model for inferring rich probability distributions
over a spatiotemporal domain, which can be used for data-analysis tasks
including forecasting, interpolation, and variography. BayesNF integrates a
novel deep neural network architecture for high-capacity function estimation
with hierarchical Bayesian inference for robust uncertainty quantification. By
defining the prior through a sequence of smooth differentiable transforms,
posterior inference is conducted on large-scale data using variationally
learned surrogates trained via stochastic gradient descent. We evaluate BayesNF
against prominent statistical and machine-learning baselines, showing
considerable improvements on diverse prediction problems from climate and
public health datasets that contain tens to hundreds of thousands of
measurements. The paper is accompanied with an open-source software package
(https://github.com/google/bayesnf) that is easy-to-use and compatible with
modern GPU and TPU accelerators on the JAX machine learning platform.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 7 figures, 3 tables, 2 listings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FBChain: A Blockchain-based Federated Learning Model with Efficiency and
  Secure Communication 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.00035v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.00035v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Li, Chunhe Xia, Wei Liu, Chen Chen, Tianbo Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Privacy and security in the parameter transmission process of federated
learning are currently among the most prominent concerns. However, there are
two thorny problems caused by unprotected communication methods:
"parameter-leakage" and "inefficient-communication". This article proposes
Blockchain-based Federated Learning (FBChain) model for federated learning
parameter communication to overcome the above two problems. First, we utilize
the immutability of blockchain to store the global model and hash value of
local model parameters in case of tampering during the communication process,
protect data privacy by encrypting parameters, and verify data consistency by
comparing the hash values of local parameters, thus addressing the
"parameter-leakage" problem. Second, the Proof of Weighted Link Speed (PoWLS)
consensus algorithm comprehensively selects nodes with the higher weighted link
speed to aggregate global model and package blocks, thereby solving the
"inefficient-communication" problem. Experimental results demonstrate the
effectiveness of our proposed FBChain model and its ability to improve model
communication efficiency in federated learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Information Complexity of Stochastic Convex Optimization: Applications
  to Generalization and Memorization <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.09327v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.09327v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Idan Attias, Gintare Karolina Dziugaite, Mahdi Haghifam, Roi Livni, Daniel M. Roy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we investigate the interplay between memorization and learning
in the context of \emph{stochastic convex optimization} (SCO). We define
memorization via the information a learning algorithm reveals about its
training data points. We then quantify this information using the framework of
conditional mutual information (CMI) proposed by Steinke and Zakynthinou
(2020). Our main result is a precise characterization of the tradeoff between
the accuracy of a learning algorithm and its CMI, answering an open question
posed by Livni (2023). We show that, in the $L^2$ Lipschitz--bounded setting
and under strong convexity, every learner with an excess error $\varepsilon$
has CMI bounded below by $\Omega(1/\varepsilon^2)$ and $\Omega(1/\varepsilon)$,
respectively. We further demonstrate the essential role of memorization in
learning problems in SCO by designing an adversary capable of accurately
identifying a significant fraction of the training samples in specific SCO
problems. Finally, we enumerate several implications of our results, such as a
limitation of generalization bounds based on CMI and the incompressibility of
samples in SCO problems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>41 Pages, To appear in ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lessons from a human-in-the-loop machine learning approach for
  identifying vacant, abandoned, and deteriorated properties in Savannah,
  Georgia 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11138v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11138v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaofan Liang, Brian Brainerd, Tara Hicks, Clio Andris
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Addressing strategies for managing vacant, abandoned, and deteriorated (VAD)
properties is important for maintaining healthy communities. Yet, the process
of identifying these properties can be difficult. Here, we create a
human-in-the-loop machine learning (HITLML) model called VADecide and apply it
to a parcel-level case study in Savannah, Georgia. The results show a higher
prediction accuracy than was achieved when using a machine learning model
without human input in the training. The HITLML approach also reveals
differences between machine vs. human-generated results. Our findings
contribute to knowledge about the advantages and challenges of HITLML in urban
planning.
  [Accepted for Publication at a Peer Review Journal]
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Intrinsic Vector Heat Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09648v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09648v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Gao, Maurice Chu, Mubbasir Kapadia, Ming C. Lin, Hsueh-Ti Derek Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vector fields are widely used to represent and model flows for many science
and engineering applications. This paper introduces a novel neural network
architecture for learning tangent vector fields that are intrinsically defined
on manifold surfaces embedded in 3D. Previous approaches to learning vector
fields on surfaces treat vectors as multi-dimensional scalar fields, using
traditional scalar-valued architectures to process channels individually, thus
fail to preserve fundamental intrinsic properties of the vector field. The core
idea of this work is to introduce a trainable vector heat diffusion module to
spatially propagate vector-valued feature data across the surface, which we
incorporate into our proposed architecture that consists of vector-valued
neurons. Our architecture is invariant to rigid motion of the input, isometric
deformation, and choice of local tangent bases, and is robust to
discretizations of the surface. We evaluate our Vector Heat Network on triangle
meshes, and empirically validate its invariant properties. We also demonstrate
the effectiveness of our method on the useful industrial application of
quadrilateral mesh generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Localizing Anomalies via Multiscale Score Matching Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.00148v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.00148v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahsan Mahmood, Junier Oliva, Martin Styner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anomaly detection and localization in medical imaging remain critical
challenges in healthcare. This paper introduces Spatial-MSMA (Multiscale Score
Matching Analysis), a novel unsupervised method for anomaly localization in
volumetric brain MRIs. Building upon the MSMA framework, our approach
incorporates spatial information and conditional likelihoods to enhance anomaly
detection capabilities. We employ a flexible normalizing flow model conditioned
on patch positions and global image features to estimate patch-wise anomaly
scores. The method is evaluated on a dataset of 1,650 T1- and T2-weighted brain
MRIs from typically developing children, with simulated lesions added to the
test set. Spatial-MSMA significantly outperforms existing methods, including
reconstruction-based, generative-based, and interpretation-based approaches, in
lesion detection and segmentation tasks. Our model achieves superior
performance in both distance-based metrics (99th percentile Hausdorff Distance:
$7.05 \pm 0.61$, Mean Surface Distance: $2.10 \pm 0.43$) and component-wise
metrics (True Positive Rate: $0.83 \pm 0.01$, Positive Predictive Value: $0.96
\pm 0.01$). These results demonstrate Spatial-MSMA's potential for accurate and
interpretable anomaly localization in medical imaging, with implications for
improved diagnosis and treatment planning in clinical settings. Our code is
available at~\url{https://github.com/ahsanMah/sade/}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ QJL: 1-Bit Quantized JL Transform for KV Cache Quantization with Zero
  Overhead 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.03482v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.03482v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amir Zandieh, Majid Daliri, Insu Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Serving LLMs requires substantial memory due to the storage requirements of
Key-Value (KV) embeddings in the KV cache, which grows with sequence length. An
effective approach to compress KV cache is quantization. However, traditional
quantization methods face significant memory overhead due to the need to store
quantization constants (at least a zero point and a scale) in full precision
per data block. Depending on the block size, this overhead can add 1 or 2 bits
per quantized number. We introduce QJL, a new quantization approach that
consists of a Johnson-Lindenstrauss (JL) transform followed by sign-bit
quantization. In contrast to existing methods, QJL eliminates memory overheads
by removing the need for storing quantization constants. We propose an
asymmetric estimator for the inner product of two vectors and demonstrate that
applying QJL to one vector and a standard JL transform without quantization to
the other provides an unbiased estimator with minimal distortion. We have
developed an efficient implementation of the QJL sketch and its corresponding
inner product estimator, incorporating a lightweight CUDA kernel for optimized
computation. When applied across various LLMs and NLP tasks to quantize the KV
cache to only 3 bits, QJL demonstrates a more than fivefold reduction in KV
cache memory usage without compromising accuracy, all while achieving faster
runtime. Codes are available at \url{https://github.com/amirzandieh/QJL}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Private Mean Estimation with Person-Level Differential Privacy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.20405v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.20405v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sushant Agarwal, Gautam Kamath, Mahbod Majid, Argyris Mouzakis, Rose Silver, Jonathan Ullman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study person-level differentially private (DP) mean estimation in the case
where each person holds multiple samples. DP here requires the usual notion of
distributional stability when $\textit{all}$ of a person's datapoints can be
modified. Informally, if $n$ people each have $m$ samples from an unknown
$d$-dimensional distribution with bounded $k$-th moments, we show that people
are necessary and sufficient to estimate the mean up to distance $\alpha$ in
$\ell_2$-norm under $\varepsilon$-differential privacy (and its common
relaxations). In the multivariate setting, we give computationally efficient
algorithms under approximate-DP and computationally inefficient algorithms
under pure DP, and our nearly matching lower bounds hold for the most
permissive case of approximate DP. Our computationally efficient estimators are
based on the standard clip-and-noise framework, but the analysis for our
setting requires both new algorithmic techniques and new analyses. In
particular, our new bounds on the tails of sums of independent, vector-valued,
bounded-moments random variables may be of interest.
  \[n = \tilde \Theta\left(\frac{d}{\alpha^2 m} + \frac{d}{\alpha m^{1/2}
\varepsilon} + \frac{d}{\alpha^{k/(k-1)} m \varepsilon} +
\frac{d}{\varepsilon}\right)\]
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>72 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Not Just Change the Labels, Learn the Features: Watermarking Deep Neural
  Networks with Multi-View Data <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.10663v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.10663v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Li, Sarthak Kumar Maharana, Yunhui Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the increasing prevalence of Machine Learning as a Service (MLaaS)
platforms, there is a growing focus on deep neural network (DNN) watermarking
techniques. These methods are used to facilitate the verification of ownership
for a target DNN model to protect intellectual property. One of the most widely
employed watermarking techniques involves embedding a trigger set into the
source model. Unfortunately, existing methodologies based on trigger sets are
still susceptible to functionality-stealing attacks, potentially enabling
adversaries to steal the functionality of the source model without a reliable
means of verifying ownership. In this paper, we first introduce a novel
perspective on trigger set-based watermarking methods from a feature learning
perspective. Specifically, we demonstrate that by selecting data exhibiting
multiple features, also referred to as \emph{multi-view data}, it becomes
feasible to effectively defend functionality stealing attacks. Based on this
perspective, we introduce a novel watermarking technique based on Multi-view
dATa, called MAT, for efficiently embedding watermarks within DNNs. This
approach involves constructing a trigger set with multi-view data and
incorporating a simple feature-based regularization method for training the
source model. We validate our method across various benchmarks and demonstrate
its efficacy in defending against model extraction attacks, surpassing relevant
baselines by a significant margin. The code is available at:
\href{https://github.com/liyuxuan-github/MAT}{https://github.com/liyuxuan-github/MAT}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision
  Language Models <span class="chip">NAACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.17912v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.17912v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manav Nitin Kapadnis, Sohan Patnaik, Abhilash Nandy, Sourjyadip Ray, Pawan Goyal, Debdoot Sheet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Radiology Report Generation (R2Gen) demonstrates how Multi-modal Large
Language Models (MLLMs) can automate the creation of accurate and coherent
radiological reports. Existing methods often hallucinate details in text-based
reports that don't accurately reflect the image content. To mitigate this, we
introduce a novel strategy, SERPENT-VLM (SElf Refining Radiology RePort
GENeraTion using Vision Language Models), which improves the R2Gen task by
integrating a self-refining mechanism into the MLLM framework. We employ a
unique self-supervised loss that leverages similarity between pooled image
representations and the contextual representations of the generated
radiological text, alongside the standard Causal Language Modeling objective,
to refine image-text representations. This allows the model to scrutinize and
align the generated text through dynamic interaction between a given image and
the generated text, therefore reducing hallucination and continuously enhancing
nuanced report generation. SERPENT-VLM outperforms existing baselines such as
LLaVA-Med, BiomedGPT, etc., achieving SoTA performance on the IU X-ray and
Radiology Objects in COntext (ROCO) datasets, and also proves to be robust
against noisy images. A qualitative case study emphasizes the significant
advancements towards more sophisticated MLLM frameworks for R2Gen, opening
paths for further research into self-supervised refinement in the medical
imaging domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 3 figures, 4 tables, Accepted as oral at Clinical NLP
  workshop at NAACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ No More Sliding-Windows: Dynamic Functional Connectivity Based On Random
  Convolutions Without Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16619v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16619v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongjie Duan, Zhiying Long
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Compared to static functional connectivity, dynamic functional connectivity
provides more detailed temporal information. The traditional sliding window
method constructs functional connectivity matrices by applying a moving time
window across the entire time series to calculate correlations between brain
regions. However, as a method of feature extraction, it exhibits significant
limitations, such as the dependency of feature dimensions on the window length
and the generation of features lacking information from other time points
within the window. This paper presents RandCon, a novel method for calculating
dynamic functional connectivity (DFC), which employs randomly generated
multi-dimensional convolution kernels. This method performs convolution
operations directly on the BOLD signal without the need for learning,
extracting functional connectivity features. Compared to the sliding window
method, RandCon shows notable improvements in performance on simulated data,
particularly in terms of temporal accuracy and noise resistance. Results from
real data indicate that this method maintains stability within short time
windows and better identifies gender differences. Furthermore, we propose a
more comprehensive theoretical framework, the multi-dimensional convolution
method, where the sliding window method and its variants are specific cases of
this method. The proposed method is straightforward and efficient,
significantly broadening the scope of dynamic functional connectivity research
and offering substantial theoretical and practical potential.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LADDER: Revisiting the Cosmic Distance Ladder with Deep Learning
  Approaches and Exploring its Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.17029v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.17029v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rahul Shah, Soumadeep Saha, Purba Mukherjee, Utpal Garain, Supratik Pal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate the prospect of reconstructing the ''cosmic distance ladder''
of the Universe using a novel deep learning framework called LADDER - Learning
Algorithm for Deep Distance Estimation and Reconstruction. LADDER is trained on
the apparent magnitude data from the Pantheon Type Ia supernovae compilation,
incorporating the full covariance information among data points, to produce
predictions along with corresponding errors. After employing several validation
tests with a number of deep learning models, we pick LADDER as the best
performing one. We then demonstrate applications of our method in the
cosmological context, including serving as a model-independent tool for
consistency checks for other datasets like baryon acoustic oscillations,
calibration of high-redshift datasets such as gamma ray bursts, and use as a
model-independent mock catalog generator for future probes. Our analysis
advocates for careful consideration of machine learning techniques applied to
cosmological contexts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 6 sets of figures, 5 tables. To appear in the Astrophys. J.
  Suppl. Ser. Code available at https://github.com/rahulshah1397/LADDER</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Information-Theoretic Foundations for Machine Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12288v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12288v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hong Jun Jeon, Benjamin Van Roy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The staggering progress of machine learning in the past decade has been a
sight to behold. In retrospect, it is both remarkable and unsettling that these
milestones were achievable with little to no rigorous theory to guide
experimentation. Despite this fact, practitioners have been able to guide their
future experimentation via observations from previous large-scale empirical
investigations. However, alluding to Plato's Allegory of the cave, it is likely
that the observations which form the field's notion of reality are but shadows
representing fragments of that reality. In this work, we propose a theoretical
framework which attempts to answer what exists outside of the cave. To the
theorist, we provide a framework which is mathematically rigorous and leaves
open many interesting ideas for future exploration. To the practitioner, we
provide a framework whose results are very intuitive, general, and which will
help form principles to guide future investigations. Concretely, we provide a
theoretical framework rooted in Bayesian statistics and Shannon's information
theory which is general enough to unify the analysis of many phenomena in
machine learning. Our framework characterizes the performance of an optimal
Bayesian learner, which considers the fundamental limits of information.
Throughout this work, we derive very general theoretical results and apply them
to derive insights specific to settings ranging from data which is
independently and identically distributed under an unknown distribution, to
data which is sequential, to data which exhibits hierarchical structure
amenable to meta-learning. We conclude with a section dedicated to
characterizing the performance of misspecified algorithms. These results are
exciting and particularly relevant as we strive to overcome increasingly
difficult machine learning challenges in this endlessly complex world.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Policy Optimization for Personalized Interventions in Behavioral Health 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.12206v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.12206v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jackie Baek, Justin J. Boutilier, Vivek F. Farias, Jonas Oddur Jonasson, Erez Yoeli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Behavioral health interventions, delivered through digital platforms, have
the potential to significantly improve health outcomes, through education,
motivation, reminders, and outreach. We study the problem of optimizing
personalized interventions for patients to maximize a long-term outcome, where
interventions are costly and capacity-constrained. We assume we have access to
a historical dataset collected from an initial pilot study. We present a new
approach for this problem that we dub DecompPI, which decomposes the state
space for a system of patients to the individual level and then approximates
one step of policy iteration. Implementing DecompPI simply consists of a
prediction task using the dataset, alleviating the need for online
experimentation. DecompPI is a generic model-free algorithm that can be used
irrespective of the underlying patient behavior model. We derive theoretical
guarantees on a simple, special case of the model that is representative of our
problem setting. When the initial policy used to collect the data is
randomized, we establish an approximation guarantee for DecompPI with respect
to the improvement beyond a null policy that does not allocate interventions.
We show that this guarantee is robust to estimation errors. We then conduct a
rigorous empirical case study using real-world data from a mobile health
platform for improving treatment adherence for tuberculosis. Using a validated
simulation model, we demonstrate that DecompPI can provide the same efficacy as
the status quo approach with approximately half the capacity of interventions.
DecompPI is simple and easy to implement for an organization aiming to improve
long-term behavior through targeted interventions, and this paper demonstrates
its strong performance both theoretically and empirically, particularly in
resource-limited settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Chinchilla-Optimal: Accounting for Inference in Language Model
  Scaling Laws 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.00448v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.00448v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nikhil Sardana, Jacob Portes, Sasha Doubov, Jonathan Frankle
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language model (LLM) scaling laws are empirical formulas that estimate
changes in model quality as a result of increasing parameter count and training
data. However, these formulas, including the popular Deepmind Chinchilla
scaling laws, neglect to include the cost of inference. We modify the
Chinchilla scaling laws to calculate the optimal LLM parameter count and
pre-training data size to train and deploy a model of a given quality and
inference demand. We conduct our analysis both in terms of a compute budget and
real-world costs and find that LLM researchers expecting reasonably large
inference demand (~1B requests) should train models smaller and longer than
Chinchilla-optimal. Furthermore, we train 47 models of varying sizes and
parameter counts to validate our formula and find that model quality continues
to improve as we scale tokens per parameter to extreme ranges (up to 10,000).
Finally, we ablate the procedure used to fit the Chinchilla scaling law
coefficients and find that developing scaling laws only from data collected at
typical token/parameter ratios overestimates the impact of additional tokens at
these extreme ranges.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 7 figures, To appear in the 41st International Conference
  on Machine Learning, 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mixed-Curvature Decision Trees and Random Forests 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05227v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05227v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Philippe Chlenski, Quentin Chu, Itsik Pe'er
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We extend decision tree and random forest algorithms to product space
manifolds: Cartesian products of Euclidean, hyperspherical, and hyperbolic
manifolds. Such spaces have extremely expressive geometries capable of
representing many arrangements of distances with low metric distortion. To
date, all classifiers for product spaces fit a single linear decision boundary,
and no regressor has been described. Our method enables a simple, expressive
method for classification and regression in product manifolds. We demonstrate
the superior accuracy of our tool compared to Euclidean methods operating in
the ambient space or the tangent plane of the manifold across a range of
constant-curvature and product manifolds. Code for our implementation and
experiments is available at https://github.com/pchlenski/embedders.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Queue-based Eco-Driving at Roundabouts with Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.00625v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.00625v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anna-Lena Schlamp, Werner Huber, Stefanie Schmidtner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address eco-driving at roundabouts in mixed traffic to enhance traffic
flow and traffic efficiency in urban areas. The aim is to proactively optimize
speed of automated or non-automated connected vehicles (CVs), ensuring both an
efficient approach and smooth entry into roundabouts. We incorporate the
traffic situation ahead, i.e. preceding vehicles and waiting queues. Further,
we develop two approaches: a rule-based and an Reinforcement Learning (RL)
based eco-driving system, with both using the approach link and information
from conflicting CVs for speed optimization. A fair comparison of rule-based
and RL-based approaches is performed to explore RL as a viable alternative to
classical optimization. Results show that both approaches outperform the
baseline. Improvements significantly increase with growing traffic volumes,
leading to best results on average being obtained at high volumes. Near
capacity, performance deteriorates, indicating limited applicability at
capacity limits. Examining different CV penetration rates, a decline in
performance is observed, but with substantial results still being achieved at
lower CV rates. RL agents can discover effective policies for speed
optimization in dynamic roundabout settings, but they do not offer a
substantial advantage over classical approaches, especially at higher traffic
volumes or lower CV penetration rates.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Reward function of the RL-agent needs to be updated, optimization in
  progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Higher-order Spatio-temporal Physics-incorporated Graph Neural Network
  for Multivariate Time Series Imputation <span class="chip">CIKM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.10995v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.10995v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guojun Liang, Prayag Tiwari, Slawomir Nowaczyk, Stefan Byttner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Exploring the missing values is an essential but challenging issue due to the
complex latent spatio-temporal correlation and dynamic nature of time series.
Owing to the outstanding performance in dealing with structure learning
potentials, Graph Neural Networks (GNNs) and Recurrent Neural Networks (RNNs)
are often used to capture such complex spatio-temporal features in multivariate
time series. However, these data-driven models often fail to capture the
essential spatio-temporal relationships when significant signal corruption
occurs. Additionally, calculating the high-order neighbor nodes in these models
is of high computational complexity. To address these problems, we propose a
novel higher-order spatio-temporal physics-incorporated GNN (HSPGNN). Firstly,
the dynamic Laplacian matrix can be obtained by the spatial attention
mechanism. Then, the generic inhomogeneous partial differential equation (PDE)
of physical dynamic systems is used to construct the dynamic higher-order
spatio-temporal GNN to obtain the missing time series values. Moreover, we
estimate the missing impact by Normalizing Flows (NF) to evaluate the
importance of each node in the graph for better explainability. Experimental
results on four benchmark datasets demonstrate the effectiveness of HSPGNN and
the superior performance when combining various order neighbor nodes. Also,
graph-like optical flow, dynamic graphs, and missing impact can be obtained
naturally by HSPGNN, which provides better dynamic analysis and explanation
than traditional data-driven models. Our code is available at
https://github.com/gorgen2020/HSPGNN.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 7 figures, CIKM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Open-Source Conversational AI with SpeechBrain 1.0 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.00463v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.00463v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mirco Ravanelli, Titouan Parcollet, Adel Moumen, Sylvain de Langen, Cem Subakan, Peter Plantinga, Yingzhi Wang, Pooneh Mousavi, Luca Della Libera, Artem Ploujnikov, Francesco Paissan, Davide Borra, Salah Zaiem, Zeyu Zhao, Shucong Zhang, Georgios Karakasidis, Sung-Lin Yeh, Pierre Champion, Aku Rouhe, Rudolf Braun, Florian Mai, Juan Zuluaga-Gomez, Seyed Mahed Mousavi, Andreas Nautsch, Xuechen Liu, Sangeet Sagar, Jarod Duret, Salima Mdhaffar, Gaelle Laperriere, Mickael Rouvier, Renato De Mori, Yannick Esteve
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  SpeechBrain is an open-source Conversational AI toolkit based on PyTorch,
focused particularly on speech processing tasks such as speech recognition,
speech enhancement, speaker recognition, text-to-speech, and much more. It
promotes transparency and replicability by releasing both the pre-trained
models and the complete "recipes" of code and algorithms required for training
them. This paper presents SpeechBrain 1.0, a significant milestone in the
evolution of the toolkit, which now has over 200 recipes for speech, audio, and
language processing tasks, and more than 100 models available on Hugging Face.
SpeechBrain 1.0 introduces new technologies to support diverse learning
modalities, Large Language Model (LLM) integration, and advanced decoding
strategies, along with novel models, tasks, and modalities. It also includes a
new benchmark repository, offering researchers a unified platform for
evaluating models across diverse tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to JMLR (Machine Learning Open Source Software)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Masked Autoencoders are Efficient Continual Federated Learners 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.03542v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.03542v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Subarnaduti Paul, Lars-Joel Frey, Roshni Kamath, Kristian Kersting, Martin Mundt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning is typically framed from a perspective of i.i.d., and more
importantly, isolated data. In parts, federated learning lifts this assumption,
as it sets out to solve the real-world challenge of collaboratively learning a
shared model from data distributed across clients. However, motivated primarily
by privacy and computational constraints, the fact that data may change,
distributions drift, or even tasks advance individually on clients, is seldom
taken into account. The field of continual learning addresses this separate
challenge and first steps have recently been taken to leverage synergies in
distributed supervised settings, in which several clients learn to solve
changing classification tasks over time without forgetting previously seen
ones. Motivated by these prior works, we posit that such federated continual
learning should be grounded in unsupervised learning of representations that
are shared across clients; in the loose spirit of how humans can indirectly
leverage others' experience without exposure to a specific task. For this
purpose, we demonstrate that masked autoencoders for distribution estimation
are particularly amenable to this setup. Specifically, their masking strategy
can be seamlessly integrated with task attention mechanisms to enable selective
knowledge transfer between clients. We empirically corroborate the latter
statement through several continual federated scenarios on both image and
binary datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Correlation inference attacks against machine learning models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2112.08806v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2112.08806v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ana-Maria Creţu, Florent Guépin, Yves-Alexandre de Montjoye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite machine learning models being widely used today, the relationship
between a model and its training dataset is not well understood. We explore
correlation inference attacks, whether and when a model leaks information about
the correlations between the input variables of its training dataset. We first
propose a model-less attack, where an adversary exploits the spherical
parametrization of correlation matrices alone to make an informed guess.
Second, we propose a model-based attack, where an adversary exploits black-box
model access to infer the correlations using minimal and realistic assumptions.
Third, we evaluate our attacks against logistic regression and multilayer
perceptron models on three tabular datasets and show the models to leak
correlations. We finally show how extracted correlations can be used as
building blocks for attribute inference attacks and enable weaker adversaries.
Our results raise fundamental questions on what a model does and should
remember from its training set.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in Science Advances. This version contains both the main
  paper and supplementary material. There are minor editorial differences
  between this version and the published version. The first two authors
  contributed equally</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improved Membership Inference Attacks Against Language Classification
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.07219v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.07219v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shlomit Shachor, Natalia Razinkov, Abigail Goldsteen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial intelligence systems are prevalent in everyday life, with use
cases in retail, manufacturing, health, and many other fields. With the rise in
AI adoption, associated risks have been identified, including privacy risks to
the people whose data was used to train models. Assessing the privacy risks of
machine learning models is crucial to enabling knowledgeable decisions on
whether to use, deploy, or share a model. A common approach to privacy risk
assessment is to run one or more known attacks against the model and measure
their success rate. We present a novel framework for running membership
inference attacks against classification models. Our framework takes advantage
of the ensemble method, generating many specialized attack models for different
subsets of the data. We show that this approach achieves higher accuracy than
either a single attack model or an attack model per class label, both on
classical and language classification tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TrialDura: Hierarchical Attention <span class="highlight-title">Transformer</span> for Interpretable Clinical
  Trial Duration Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.13235v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.13235v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ling Yue, Jonathan Li, Sixue Xing, Md Zabirul Islam, Bolun Xia, Tianfan Fu, Jintai Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The clinical trial process, a critical phase in drug development, is
essential for developing new treatments. The primary goal of interventional
clinical trials is to evaluate the safety and efficacy of drug-based treatments
for specific diseases. However, these trials are often lengthy,
labor-intensive, and expensive. The duration of a clinical trial significantly
impacts overall costs, making efficient timeline management crucial for
controlling budgets and ensuring the economic feasibility of research. To
address this issue, We propose TrialDura, a machine learning-based method that
estimates the duration of clinical trials using multimodal data, including
disease names, drug molecules, trial phases, and eligibility criteria. Then, we
encode them into Bio-BERT embeddings specifically tuned for biomedical contexts
to provide a deeper and more relevant semantic understanding of clinical trial
data. Finally, the model's hierarchical attention mechanism connects all of the
embeddings to capture their interactions and predict clinical trial duration.
Our proposed model demonstrated superior performance with a mean absolute error
(MAE) of 1.04 years and a root mean square error (RMSE) of 1.39 years compared
to the other models, indicating more accurate clinical trial duration
prediction. Publicly available code can be found at:
https://anonymous.4open.science/r/TrialDura-F196.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MER 2024: Semi-Supervised Learning, Noise Robustness, and
  Open-Vocabulary Multimodal Emotion Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.17113v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.17113v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheng Lian, Haiyang Sun, Licai Sun, Zhuofan Wen, Siyuan Zhang, Shun Chen, Hao Gu, Jinming Zhao, Ziyang Ma, Xie Chen, Jiangyan Yi, Rui Liu, Kele Xu, Bin Liu, Erik Cambria, Guoying Zhao, Björn W. Schuller, Jianhua Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal emotion recognition is an important research topic in artificial
intelligence. Over the past few decades, researchers have made remarkable
progress by increasing the dataset size and building more effective algorithms.
However, due to problems such as complex environments and inaccurate
annotations, current systems are hard to meet the demands of practical
applications. Therefore, we organize the MER series of competitions to promote
the development of this field. Last year, we launched MER2023, focusing on
three interesting topics: multi-label learning, noise robustness, and
semi-supervised learning. In this year's MER2024, besides expanding the dataset
size, we further introduce a new track around open-vocabulary emotion
recognition. The main purpose of this track is that existing datasets usually
fix the label space and use majority voting to enhance the annotator
consistency. However, this process may lead to inaccurate annotations, such as
ignoring non-majority or non-candidate labels. In this track, we encourage
participants to generate any number of labels in any category, aiming to
describe emotional states as accurately as possible. Our baseline code relies
on MERTools and is available at:
https://github.com/zeroQiaoba/MERTools/tree/master/MER2024.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HORAE: A Domain-Agnostic Modeling Language for Automating Multimodal
  Service Regulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.06600v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.06600v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yutao Sun, Mingshuai Chen, Tiancheng Zhao, Kangjia Zhao, He Li, Jintao Chen, Liqiang Lu, Xinkui Zhao, Shuiguang Deng, Jianwei Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial intelligence is rapidly encroaching on the field of service
regulation. This work presents the design principles behind HORAE, a unified
specification language to model multimodal regulation rules across a diverse
set of domains. We show how HORAE facilitates an intelligent service regulation
pipeline by further exploiting a fine-tuned large language model named HORAE
that automates the HORAE modeling process, thereby yielding an end-to-end
framework for fully automated intelligent service regulation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BAM-DETR: Boundary-Aligned Moment Detection <span class="highlight-title">Transformer</span> for Temporal
  Sentence Grounding in Videos <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.00083v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.00083v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pilhyeon Lee, Hyeran Byun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Temporal sentence grounding aims to localize moments relevant to a language
description. Recently, DETR-like approaches achieved notable progress by
predicting the center and length of a target moment. However, they suffer from
the issue of center misalignment raised by the inherent ambiguity of moment
centers, leading to inaccurate predictions. To remedy this problem, we propose
a novel boundary-oriented moment formulation. In our paradigm, the model no
longer needs to find the precise center but instead suffices to predict any
anchor point within the interval, from which the boundaries are directly
estimated. Based on this idea, we design a boundary-aligned moment detection
transformer, equipped with a dual-pathway decoding process. Specifically, it
refines the anchor and boundaries within parallel pathways using global and
boundary-focused attention, respectively. This separate design allows the model
to focus on desirable regions, enabling precise refinement of moment
predictions. Further, we propose a quality-based ranking method, ensuring that
proposals with high localization qualities are prioritized over incomplete
ones. Experiments on three benchmarks validate the effectiveness of the
proposed methods. The code is available at
https://github.com/Pilhyeon/BAM-DETR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Graph Expansions of Deep Neural Networks and their Universal Scaling
  Limits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.08459v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.08459v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicola Muca Cirone, Jad Hamdan, Cristopher Salvi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a unified approach to obtain scaling limits of neural networks
using the genus expansion technique from random matrix theory. This approach
begins with a novel expansion of neural networks which is reminiscent of
Butcher series for ODEs, and is obtained through a generalisation of Fa\`a di
Bruno's formula to an arbitrary number of compositions. In this expansion, the
role of monomials is played by random multilinear maps indexed by directed
graphs whose edges correspond to random matrices, which we call operator
graphs. This expansion linearises the effect of the activation functions,
allowing for the direct application of Wick's principle to compute the
expectation of each of its terms. We then determine the leading contribution to
each term by embedding the corresponding graphs onto surfaces, and computing
their Euler characteristic. Furthermore, by developing a correspondence between
analytic and graphical operations, we obtain similar graph expansions for the
neural tangent kernel as well as the input-output Jacobian of the original
neural network, and derive their infinite-width limits with relative ease.
Notably, we find explicit formulae for the moments of the limiting singular
value distribution of the Jacobian. We then show that all of these results hold
for networks with more general weights, such as general matrices with i.i.d.
entries satisfying moment assumptions, complex matrices and sparse matrices.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>v2: added acknowledgements paragraph</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SynthCLIP: Are We Ready for a Fully Synthetic CLIP Training? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.01832v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.01832v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hasan Abed Al Kader Hammoud, Hani Itani, Fabio Pizzati, Philip Torr, Adel Bibi, Bernard Ghanem
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present SynthCLIP, a CLIP model trained on entirely synthetic text-image
pairs. Leveraging recent text-to-image (TTI) networks and large language models
(LLM), we generate synthetic datasets of images and corresponding captions at
scale, with no human intervention. In this work, we provide an analysis on CLIP
models trained on synthetic data. We provide insights on the data generation
strategy, number of samples required, scaling trends, and resulting properties.
We also introduce SynthCI-30M, a purely synthetic dataset comprising 30 million
captioned images. Our code, trained models, and data, are released as open
source at https://github.com/hammoudhasan/SynthCLIP
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fusion of Movement and Naive Predictions for Point Forecasting in
  Univariate Random Walks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14469v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14469v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cheng Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional methods for point forecasting in univariate random walks often
fail to surpass naive benchmarks due to data unpredictability. This study
introduces a novel forecasting method that fuses movement prediction (binary
classification) with naive forecasts for accurate one-step-ahead point
forecasting in univariate random walks. The method's efficacy is demonstrated
through theoretical analysis, simulations, and real-world data experiments. It
reliably outperforms naive forecasts with moderate movement prediction
accuracies, such as 0.55, and is superior to baseline models such as the ARIMA,
linear regression, MLP, and LSTM networks in forecasting the S&P 500 index and
Bitcoin prices. This method is particularly advantageous when accurate point
predictions are challenging but accurate movement predictions are attainable,
translating movement predictions into point forecasts in random walk contexts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semantic Residual <span class="highlight-title">Prompt</span>s for Continual Learning <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.06870v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.06870v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Martin Menabue, Emanuele Frascaroli, Matteo Boschini, Enver Sangineto, Lorenzo Bonicelli, Angelo Porrello, Simone Calderara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt-tuning methods for Continual Learning (CL) freeze a large pre-trained
model and train a few parameter vectors termed prompts. Most of these methods
organize these vectors in a pool of key-value pairs and use the input image as
query to retrieve the prompts (values). However, as keys are learned while
tasks progress, the prompting selection strategy is itself subject to
catastrophic forgetting, an issue often overlooked by existing approaches. For
instance, prompts introduced to accommodate new tasks might end up interfering
with previously learned prompts. To make the selection strategy more stable, we
leverage a foundation model (CLIP) to select our prompts within a two-level
adaptation mechanism. Specifically, the first level leverages a standard
textual prompt pool for the CLIP textual encoder, leading to stable class
prototypes. The second level, instead, uses these prototypes along with the
query image as keys to index a second pool. The retrieved prompts serve to
adapt a pre-trained ViT, granting plasticity. In doing so, we also propose a
novel residual mechanism to transfer CLIP semantics to the ViT layers. Through
extensive analysis on established CL benchmarks, we show that our method
significantly outperforms both state-of-the-art CL approaches and the zero-shot
CLIP test. Notably, our findings hold true even for datasets with a substantial
domain gap w.r.t. the pre-training knowledge of the backbone model, as
showcased by experiments on satellite imagery and medical datasets. The
codebase is available at https://github.com/aimagelab/mammoth.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 5 figures, Accepted at 18th European Conference on Computer
  Vision (ECCV 2024), Milan, Italy</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Self-Supervised</span> Learning with Generative Adversarial Networks for
  Electron Microscopy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.18286v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.18286v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bashir Kazimi, Karina Ruzaeva, Stefan Sandfeld
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we explore the potential of self-supervised learning with
Generative Adversarial Networks (GANs) for electron microscopy datasets. We
show how self-supervised pretraining facilitates efficient fine-tuning for a
spectrum of downstream tasks, including semantic segmentation, denoising, noise
\& background removal, and super-resolution. Experimentation with varying model
complexities and receptive field sizes reveals the remarkable phenomenon that
fine-tuned models of lower complexity consistently outperform more complex
models with random weight initialization. We demonstrate the versatility of
self-supervised pretraining across various downstream tasks in the context of
electron microscopy, allowing faster convergence and better performance. We
conclude that self-supervised pretraining serves as a powerful catalyst, being
especially advantageous when limited annotated data are available and efficient
scaling of computational cost is important.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Injecting Hierarchical Biological Priors into Graph Neural Networks for
  Flow Cytometry Prediction <span class="chip">ICML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.18507v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.18507v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fatemeh Nassajian Mojarrad, Lorenzo Bini, Thomas Matthes, Stéphane Marchand-Maillet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the complex landscape of hematologic samples such as peripheral blood or
bone marrow derived from flow cytometry (FC) data, cell-level prediction
presents profound challenges. This work explores injecting hierarchical prior
knowledge into graph neural networks (GNNs) for single-cell multi-class
classification of tabular cellular data. By representing the data as graphs and
encoding hierarchical relationships between classes, we propose our
hierarchical plug-in method to be applied to several GNN models, namely,
FCHC-GNN, and effectively designed to capture neighborhood information crucial
for single-cell FC domain. Extensive experiments on our cohort of 19 distinct
patients, demonstrate that incorporating hierarchical biological constraints
boosts performance significantly across multiple metrics compared to baseline
GNNs without such priors. The proposed approach highlights the importance of
structured inductive biases for gaining improved generalization in complex
biological prediction tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, ICML Conference Workshop 2024. arXiv admin note: text
  overlap with arXiv:2402.18610</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sparse and geometry-aware generalisation of the mutual information for
  joint discriminative clustering and feature selection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2302.03391v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2302.03391v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Louis Ohl, Pierre-Alexandre Mattei, Charles Bouveyron, Mickaël Leclercq, Arnaud Droit, Frédéric Precioso
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Feature selection in clustering is a hard task which involves simultaneously
the discovery of relevant clusters as well as relevant variables with respect
to these clusters. While feature selection algorithms are often model-based
through optimised model selection or strong assumptions on the data
distribution, we introduce a discriminative clustering model trying to maximise
a geometry-aware generalisation of the mutual information called GEMINI with a
simple l1 penalty: the Sparse GEMINI. This algorithm avoids the burden of
combinatorial feature subset exploration and is easily scalable to
high-dimensional data and large amounts of samples while only designing a
discriminative clustering model. We demonstrate the performances of Sparse
GEMINI on synthetic datasets and large-scale datasets. Our results show that
Sparse GEMINI is a competitive algorithm and has the ability to select relevant
subsets of variables with respect to the clustering without using relevance
criteria or prior hypotheses.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in Statistics and Computing, Volume 34, article number 155,
  (2024), https://doi.org/10.1007/s11222-024-10467-9</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Not All Frequencies Are Created Equal:Towards a Dynamic Fusion of
  Frequencies in Time-Series Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12415v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12415v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingyu Zhang, Siyu Zhao, Zeen Song, Huijie Guo, Jianqi Zhang, Changwen Zheng, Wenwen Qiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-term time series forecasting is a long-standing challenge in various
applications. A central issue in time series forecasting is that methods should
expressively capture long-term dependency. Furthermore, time series forecasting
methods should be flexible when applied to different scenarios. Although
Fourier analysis offers an alternative to effectively capture reusable and
periodic patterns to achieve long-term forecasting in different scenarios,
existing methods often assume high-frequency components represent noise and
should be discarded in time series forecasting. However, we conduct a series of
motivation experiments and discover that the role of certain frequencies varies
depending on the scenarios. In some scenarios, removing high-frequency
components from the original time series can improve the forecasting
performance, while in others scenarios, removing them is harmful to forecasting
performance. Therefore, it is necessary to treat the frequencies differently
according to specific scenarios. To achieve this, we first reformulate the time
series forecasting problem as learning a transfer function of each frequency in
the Fourier domain. Further, we design Frequency Dynamic Fusion (FreDF), which
individually predicts each Fourier component, and dynamically fuses the output
of different frequencies. Moreover, we provide a novel insight into the
generalization ability of time series forecasting and propose the
generalization bound of time series forecasting. Then we prove FreDF has a
lower bound, indicating that FreDF has better generalization ability. Extensive
experiments conducted on multiple benchmark datasets and ablation studies
demonstrate the effectiveness of FreDF.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accpeted by ACMMM2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MSPipe: Efficient Temporal GNN Training via Staleness-Aware Pipeline 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.15113v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.15113v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guangming Sheng, Junwei Su, Chao Huang, Chuan Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Memory-based Temporal Graph Neural Networks (MTGNNs) are a class of temporal
graph neural networks that utilize a node memory module to capture and retain
long-term temporal dependencies, leading to superior performance compared to
memory-less counterparts. However, the iterative reading and updating process
of the memory module in MTGNNs to obtain up-to-date information needs to follow
the temporal dependencies. This introduces significant overhead and limits
training throughput. Existing optimizations for static GNNs are not directly
applicable to MTGNNs due to differences in training paradigm, model
architecture, and the absence of a memory module. Moreover, they do not
effectively address the challenges posed by temporal dependencies, making them
ineffective for MTGNN training. In this paper, we propose MSPipe, a general and
efficient framework for MTGNNs that maximizes training throughput while
maintaining model accuracy. Our design addresses the unique challenges
associated with fetching and updating node memory states in MTGNNs by
integrating staleness into the memory module. However, simply introducing a
predefined staleness bound in the memory module to break temporal dependencies
may lead to suboptimal performance and lack of generalizability across
different models and datasets. To solve this, we introduce an online pipeline
scheduling algorithm in MSPipe that strategically breaks temporal dependencies
with minimal staleness and delays memory fetching to obtain fresher memory
states. Moreover, we design a staleness mitigation mechanism to enhance
training convergence and model accuracy. We provide convergence analysis and
prove that MSPipe maintains the same convergence rate as vanilla sample-based
GNN training. Experimental results show that MSPipe achieves up to 2.45x
speed-up without sacrificing accuracy, making it a promising solution for
efficient MTGNN training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On <span class="highlight-title">Pretrain</span>ing Data Diversity for <span class="highlight-title">Self-Supervised</span> Learning <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.13808v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.13808v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hasan Abed Al Kader Hammoud, Tuhin Das, Fabio Pizzati, Philip Torr, Adel Bibi, Bernard Ghanem
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We explore the impact of training with more diverse datasets, characterized
by the number of unique samples, on the performance of self-supervised learning
(SSL) under a fixed computational budget. Our findings consistently demonstrate
that increasing pretraining data diversity enhances SSL performance, albeit
only when the distribution distance to the downstream data is minimal. Notably,
even with an exceptionally large pretraining data diversity achieved through
methods like web crawling or diffusion-generated data, among other ways, the
distribution shift remains a challenge. Our experiments are comprehensive with
seven SSL methods using large-scale datasets such as ImageNet and YFCC100M
amounting to over 200 GPU days. Code and trained models are available at
https://github.com/hammoudhasan/DiversitySSL
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Realistic Unsupervised CLIP Fine-tuning with Universal Entropy
  Optimization <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.12919v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.12919v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian Liang, Lijun Sheng, Zhengbo Wang, Ran He, Tieniu Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The emergence of vision-language models, such as CLIP, has spurred a
significant research effort towards their application for downstream supervised
learning tasks. Although some previous studies have explored the unsupervised
fine-tuning of CLIP, they often rely on prior knowledge in the form of class
names associated with ground truth labels. This paper explores a realistic
unsupervised fine-tuning scenario, considering the presence of
out-of-distribution samples from unknown classes within the unlabeled data. In
particular, we focus on simultaneously enhancing out-of-distribution detection
and the recognition of instances associated with known classes. To tackle this
problem, we present a simple, efficient, and effective approach called
Universal Entropy Optimization (UEO). UEO leverages sample-level confidence to
approximately minimize the conditional entropy of confident instances and
maximize the marginal entropy of less confident instances. Apart from
optimizing the textual prompt, UEO incorporates optimization of channel-wise
affine transformations within the visual branch of CLIP. Extensive experiments
across 15 domains and 4 different types of prior knowledge validate the
effectiveness of UEO compared to baseline methods. The code is publicly
available at \url{https://github.com/tim-learn/UEO}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024 Highlight</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Private Aggregation in Hierarchical Wireless Federated Learning with
  Partial and Full Collusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.14088v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.14088v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maximilian Egger, Christoph Hofmeister, Antonia Wachter-Zeh, Rawad Bitar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In federated learning, a federator coordinates the training of a model, e.g.,
a neural network, on privately owned data held by several participating
clients. The gradient descent algorithm, a well-known and popular iterative
optimization procedure, is run to train the model. Every client computes
partial gradients based on their local data and sends them to the federator,
which aggregates the results and updates the model. Privacy of the clients'
data is a major concern. In fact, it is shown that observing the partial
gradients can be enough to reveal the clients' data. Existing literature
focuses on private aggregation schemes that tackle the privacy problem in
federated learning in settings where all users are connected to each other and
to the federator. In this paper, we consider a hierarchical wireless system
architecture in which the clients are connected to base stations; the base
stations are connected to the federator either directly or through relays. We
examine settings with and without relays, and derive fundamental limits on the
communication cost under information-theoretic privacy with different collusion
assumptions. We introduce suitable private aggregation schemes tailored for
these settings whose communication costs are multiplicative factors away from
the derived bounds.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> of Artificial Intelligence in Gait-Based Neurodegenerative
  Disease Diagnosis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.13082v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.13082v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haocong Rao, Minlin Zeng, Xuejiao Zhao, Chunyan Miao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent years have witnessed an increasing global population affected by
neurodegenerative diseases (NDs), which traditionally require extensive
healthcare resources and human effort for medical diagnosis and monitoring. As
a crucial disease-related motor symptom, human gait can be exploited to
characterize different NDs. The current advances in artificial intelligence
(AI) models enable automatic gait analysis for NDs identification and
classification, opening a new avenue to facilitate faster and more
cost-effective diagnosis of NDs. In this paper, we provide a comprehensive
survey on recent progress of machine learning and deep learning based AI
techniques applied to diagnosis of five typical NDs through gait. We provide an
overview of the process of AI-assisted NDs diagnosis, and present a systematic
taxonomy of existing gait data and AI models. Meanwhile, a novel quality
evaluation criterion is proposed to quantitatively assess the quality of
existing studies. Through an extensive review and analysis of 164 studies, we
identify and discuss the challenges, potential solutions, and future directions
in this field. Finally, we envision the prospective utilization of 3D skeleton
data for human gait representation and the development of more efficient AI
models for NDs diagnosis. We provide a public resource repository to track and
facilitate developments in this emerging field:
https://github.com/Kali-Hac/AI4NDD-Survey.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Article: 46 pages, 9 figures, 7 tables, citing 274 papers. Appendix:
  29 pages, 1 figure, 5 tables. A up-to-date resource (papers, data, etc.) of
  this survey (AI4NDD) is provided at https://github.com/Kali-Hac/AI4NDD-Survey</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Convex mixed-integer optimization with Frank-Wolfe methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2208.11010v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2208.11010v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Deborah Hendrych, Hannah Troppens, Mathieu Besançon, Sebastian Pokutta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mixed-integer nonlinear optimization encompasses a broad class of problems
that present both theoretical and computational challenges. We propose a new
type of method to solve these problems based on a branch-and-bound algorithm
with convex node relaxations. These relaxations are solved with a Frank-Wolfe
algorithm over the convex hull of mixed-integer feasible points instead of the
continuous relaxation via calls to a mixed-integer linear solver as the linear
minimization oracle. The proposed method computes feasible solutions while
working on a single representation of the polyhedral constraints, leveraging
the full extent of mixed-integer linear solvers without an outer approximation
scheme and can exploit inexact solutions of node subproblems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Self-play with Execution Feedback: Improving Instruction-following
  Capabilities of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13542v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13542v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guanting Dong, Keming Lu, Chengpeng Li, Tingyu Xia, Bowen Yu, Chang Zhou, Jingren Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One core capability of large language models (LLMs) is to follow natural
language instructions. However, the issue of automatically constructing
high-quality training data to enhance the complex instruction-following
abilities of LLMs without manual annotation remains unresolved. In this paper,
we introduce AutoIF, the first scalable and reliable method for automatically
generating instruction-following training data. AutoIF transforms the
validation of instruction-following data quality into code verification,
requiring LLMs to generate instructions, the corresponding code to check the
correctness of the instruction responses, and unit test samples to verify the
code's correctness. Then, execution feedback-based rejection sampling can
generate data for Supervised Fine-Tuning (SFT) and Reinforcement Learning from
Human Feedback (RLHF) training. AutoIF achieves significant improvements across
three training algorithms, SFT, Offline DPO, and Online DPO, when applied to
the top open-source LLMs, Qwen2 and LLaMA3, in self-alignment and
strong-to-weak distillation settings. Our code is publicly available at
https://github.com/QwenLM/AutoIF.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Avoiding strict saddle points of nonconvex regularized problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.09274v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.09274v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luwei Bai, Yaohua Hu, Hao Wang, Xiaoqi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we consider a class of non-convex and non-smooth sparse
optimization problems, which encompass most existing nonconvex
sparsity-inducing terms. We show the second-order optimality conditions only
depend on the nonzeros of the stationary points. We propose two damped
iterative reweighted algorithms including the iteratively reweighted $\ell_1$
algorithm (DIRL$_1$) and the iteratively reweighted $\ell_2$ (DIRL$_2$)
algorithm, to solve these problems. For DIRL$_1$, we show the reweighted
$\ell_1$ subproblem has support identification property so that DIRL$_1$
locally reverts to a gradient descent algorithm around a stationary point. For
DIRL$_2$, we show the solution map of the reweighted $\ell_2$ subproblem is
differentiable and Lipschitz continuous everywhere. Therefore, the map of
DIRL$_1$ and DIRL$_2$ and their inverse are Lipschitz continuous, and the
strict saddle points are their unstable fixed points. By applying the stable
manifold theorem, these algorithms are shown to converge only to local
minimizers with randomly initialization when the strictly saddle point property
is assumed.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages,4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Model Provenance via Model DNA 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.02121v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.02121v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Mu, Yu Wang, Yehong Zhang, Jiaqi Zhang, Hui Wang, Yang Xiang, Yue Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding the life cycle of the machine learning (ML) model is an
intriguing area of research (e.g., understanding where the model comes from,
how it is trained, and how it is used). This paper focuses on a novel problem
within this field, namely Model Provenance (MP), which concerns the
relationship between a target model and its pre-training model and aims to
determine whether a source model serves as the provenance for a target model.
This is an important problem that has significant implications for ensuring the
security and intellectual property of machine learning models but has not
received much attention in the literature. To fill in this gap, we introduce a
novel concept of Model DNA which represents the unique characteristics of a
machine learning model. We utilize a data-driven and model-driven
representation learning method to encode the model's training data and
input-output information as a compact and comprehensive representation (i.e.,
DNA) of the model. Using this model DNA, we develop an efficient framework for
model provenance identification, which enables us to identify whether a source
model is a pre-training model of a target model. We conduct evaluations on both
computer vision and natural language processing tasks using various models,
datasets, and scenarios to demonstrate the effectiveness of our approach in
accurately identifying model provenance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GLAD: Improving Latent Graph Generative Modeling with Simple
  Quantization <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.16883v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.16883v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Van Khoa Nguyen, Yoann Boget, Frantzeska Lavda, Alexandros Kalousis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Exploring the graph latent structures has not garnered much attention in the
graph generative research field. Yet, exploiting the latent space is as crucial
as working on the data space for discrete data such as graphs. However,
previous methods either failed to preserve the permutation symmetry of graphs
or lacked an effective approaches to model appropriately within the latent
space. To mitigate those issues, we propose a simple, yet effective discrete
latent graph diffusion generative model. Our model, namely GLAD, not only
overcomes the drawbacks of existing latent approaches, but also alleviates
inherent issues present in diffusion methods applied on the graph space. We
validate our generative model on the molecular benchmark datasets, on which it
demonstrates competitive performance compared with the state-of-the-art
baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in the 2nd Structured Probabilistic Inference & Generative
  Modeling workshop of ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Motion-Oriented Compositional Neural Radiance Fields for Monocular
  Dynamic Human Modeling <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11962v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11962v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaehyeok Kim, Dongyoon Wee, Dan Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces Motion-oriented Compositional Neural Radiance Fields
(MoCo-NeRF), a framework designed to perform free-viewpoint rendering of
monocular human videos via novel non-rigid motion modeling approach. In the
context of dynamic clothed humans, complex cloth dynamics generate non-rigid
motions that are intrinsically distinct from skeletal articulations and
critically important for the rendering quality. The conventional approach
models non-rigid motions as spatial (3D) deviations in addition to skeletal
transformations. However, it is either time-consuming or challenging to achieve
optimal quality due to its high learning complexity without a direct
supervision. To target this problem, we propose a novel approach of modeling
non-rigid motions as radiance residual fields to benefit from more direct color
supervision in the rendering and utilize the rigid radiance fields as a prior
to reduce the complexity of the learning process. Our approach utilizes a
single multiresolution hash encoding (MHE) to concurrently learn the canonical
T-pose representation from rigid skeletal motions and the radiance residual
field for non-rigid motions. Additionally, to further improve both training
efficiency and usability, we extend MoCo-NeRF to support simultaneous training
of multiple subjects within a single framework, thanks to our effective design
for modeling non-rigid motions. This scalability is achieved through the
integration of a global MHE and learnable identity codes in addition to
multiple local MHEs. We present extensive results on ZJU-MoCap and MonoCap,
clearly demonstrating state-of-the-art performance in both single- and
multi-subject settings. The code and model will be made publicly available at
the project page: https://stevejaehyeok.github.io/publications/moco-nerf.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dynamic Dimension Wrapping (DDW) Algorithm: A Novel Approach for
  Efficient Cross-Dimensional Search in Dynamic Multidimensional Spaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11626v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11626v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongnan Jin, Yali Liu, Qiuzhi Song, Xunju Ma, Yue Liu, Dehao Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the real world, as the complexity of optimization problems continues to
increase, there is an urgent need to research more efficient optimization
methods. Current optimization algorithms excel in solving problems with a fixed
number of dimensions. However, their efficiency in searching dynamic
multi-dimensional spaces is unsatisfactory. In response to the challenge of
cross-dimensional search in multi-dimensional spaces with varying numbers of
dimensions, this study proposes a new optimization algorithm-Dynamic Dimension
Wrapping (DDW) algorithm. Firstly, by utilizing the Dynamic Time Warping (DTW)
algorithm and Euclidean distance, a mapping relationship between different time
series across dimensions is established, thus creating a fitness function
suitable for dimensionally dynamic multi-dimensional space. Additionally, DDW
introduces a novel, more efficient cross-dimensional search mechanism for
dynamic multidimensional spaces. Finally, through comparative tests with 31
optimization algorithms in dynamic multidimensional space search, the results
demonstrate that DDW exhibits outstanding search efficiency and provides search
results closest to the actual optimal solution.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PARMESAN: Parameter-Free Memory Search and Transduction for Dense
  Prediction Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.11743v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.11743v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Philip Matthias Winter, Maria Wimmer, David Major, Dimitrios Lenis, Astrid Berg, Theresa Neubauer, Gaia Romana De Paolis, Johannes Novotny, Sophia Ulonska, Katja Bühler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work addresses flexibility in deep learning by means of transductive
reasoning. For adaptation to new data and tasks, e.g., in continual learning,
existing methods typically involve tuning learnable parameters or complete
re-training from scratch, rendering such approaches unflexible in practice. We
argue that the notion of separating computation from memory by the means of
transduction can act as a stepping stone for solving these issues. We therefore
propose PARMESAN (parameter-free memory search and transduction), a scalable
method which leverages a memory module for solving dense prediction tasks. At
inference, hidden representations in memory are being searched to find
corresponding patterns. In contrast to other methods that rely on continuous
training of learnable parameters, PARMESAN learns via memory consolidation
simply by modifying stored contents. Our method is compatible with commonly
used architectures and canonically transfers to 1D, 2D, and 3D grid-based data.
The capabilities of our approach are demonstrated at the complex task of
continual learning. PARMESAN learns by 3-4 orders of magnitude faster than
established baselines while being on par in terms of predictive performance,
hardware-efficiency, and knowledge retention.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint, 25 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Understand What LLM Needs: Dual Preference Alignment for
  Retrieval-Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18676v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18676v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guanting Dong, Yutao Zhu, Chenghao Zhang, Zechen Wang, Zhicheng Dou, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) has demonstrated effectiveness in
mitigating the hallucination problem of large language models (LLMs). However,
the difficulty of aligning the retriever with the diverse LLMs' knowledge
preferences inevitably poses an inevitable challenge in developing a reliable
RAG system. To address this issue, we propose DPA-RAG, a universal framework
designed to align diverse knowledge preferences within RAG systems.
Specifically, we initially introduce a preference knowledge construction
pipline and incorporate five novel query augmentation strategies to alleviate
preference data scarcity. Based on preference data, DPA-RAG accomplishes both
external and internal preference alignment: 1) It jointly integrate pair-wise,
point-wise, and contrastive preference alignment abilities into the reranker,
achieving external preference alignment among RAG components. 2) It further
introduces a pre-aligned stage before vanilla Supervised Fine-tuning (SFT),
enabling LLMs to implicitly capture knowledge aligned with their reasoning
preferences, achieving LLMs' internal alignment. Experimental results across
four knowledge-intensive QA datasets demonstrate that DPA-RAG outperforms all
baselines and seamlessly integrates both black-box and open-sourced LLM
readers. Further qualitative analysis and discussions also provide empirical
guidance for achieving reliable RAG systems. Our code is publicly available at
https://github.com/dongguanting/DPA-RAG.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Feedback Efficient Online Fine-Tuning of Diffusion Models <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.16359v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.16359v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Masatoshi Uehara, Yulai Zhao, Kevin Black, Ehsan Hajiramezanali, Gabriele Scalia, Nathaniel Lee Diamant, Alex M Tseng, Sergey Levine, Tommaso Biancalani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models excel at modeling complex data distributions, including
those of images, proteins, and small molecules. However, in many cases, our
goal is to model parts of the distribution that maximize certain properties:
for example, we may want to generate images with high aesthetic quality, or
molecules with high bioactivity. It is natural to frame this as a reinforcement
learning (RL) problem, in which the objective is to fine-tune a diffusion model
to maximize a reward function that corresponds to some property. Even with
access to online queries of the ground-truth reward function, efficiently
discovering high-reward samples can be challenging: they might have a low
probability in the initial distribution, and there might be many infeasible
samples that do not even have a well-defined reward (e.g., unnatural images or
physically impossible molecules). In this work, we propose a novel
reinforcement learning procedure that efficiently explores on the manifold of
feasible samples. We present a theoretical analysis providing a regret
guarantee, as well as empirical validation across three domains: images,
biological sequences, and molecules.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ E(n) Equivariant Message Passing Cellular Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.03145v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.03145v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Veljko Kovač, Erik J. Bekkers, Pietro Liò, Floor Eijkelboom
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces E(n) Equivariant Message Passing Cellular Networks
(EMPCNs), an extension of E(n) Equivariant Graph Neural Networks to
CW-complexes. Our approach addresses two aspects of geometric message passing
networks: 1) enhancing their expressiveness by incorporating arbitrary cells,
and 2) achieving this in a computationally efficient way with a decoupled
EMPCNs technique. We demonstrate that EMPCNs achieve close to state-of-the-art
performance on multiple tasks without the need for steerability, including
many-body predictions and motion capture. Moreover, ablation studies confirm
that decoupled EMPCNs exhibit stronger generalization capabilities than their
non-topologically informed counterparts. These findings show that EMPCNs can be
used as a scalable and expressive framework for higher-order message passing in
geometric and topological graphs
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Privacy Side Channels in Machine Learning Systems <span class="chip">USENIX Security 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.05610v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.05610v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Edoardo Debenedetti, Giorgio Severi, Nicholas Carlini, Christopher A. Choquette-Choo, Matthew Jagielski, Milad Nasr, Eric Wallace, Florian Tramèr
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most current approaches for protecting privacy in machine learning (ML)
assume that models exist in a vacuum. Yet, in reality, these models are part of
larger systems that include components for training data filtering, output
monitoring, and more. In this work, we introduce privacy side channels: attacks
that exploit these system-level components to extract private information at
far higher rates than is otherwise possible for standalone models. We propose
four categories of side channels that span the entire ML lifecycle (training
data filtering, input preprocessing, output post-processing, and query
filtering) and allow for enhanced membership inference, data extraction, and
even novel threats such as extraction of users' test queries. For example, we
show that deduplicating training data before applying differentially-private
training creates a side-channel that completely invalidates any provable
privacy guarantees. We further show that systems which block language models
from regenerating training data can be exploited to exfiltrate private keys
contained in the training set--even if the model did not memorize these keys.
Taken together, our results demonstrate the need for a holistic, end-to-end
privacy analysis of machine learning systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>USENIX Security 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ General Distribution Learning: A theoretical framework for Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05666v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05666v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Binchuan Qi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces General Distribution Learning (GD learning), a novel
theoretical learning framework designed to address a comprehensive range of
machine learning and statistical tasks, including classification, regression,
and parameter estimation. GD learning focuses on estimating the true underlying
probability distribution of dataset and using models to fit the estimated
parameters of the distribution. The learning error in GD learning is thus
decomposed into two distinct categories: estimation error and fitting error.
The estimation error, which stems from the constraints of finite sampling,
limited prior knowledge, and the estimation algorithm's inherent limitations,
quantifies the discrepancy between the true distribution and its estimate. The
fitting error can be attributed to model's capacity limitation and the
performance limitation of the optimization algorithm, which evaluates the
deviation of the model output from the fitted objective. To address the
challenge of non-convexity in the optimization of learning error, we introduce
the standard loss function and demonstrate that, when employing this function,
global optimal solutions in non-convex optimization can be approached by
minimizing the gradient norm and the structural error. Moreover, we demonstrate
that the estimation error is determined by the uncertainty of the estimate $q$,
and propose the minimum uncertainty principle to obtain an optimal estimate of
the true distribution. We further provide upper bounds for the estimation
error, fitting error, and learning error within the GD learning framework.
Ultimately, our findings are applied to offer theoretical explanations for
several unanswered questions on deep learning, including overparameterization,
non-convex optimization, flat minima, dynamic isometry condition and other
techniques in deep learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2105.04026 by other
  authors. arXiv admin note: text overlap with arXiv:2105.04026 by other
  authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Training Efficiency Using Packing with Flash Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09105v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09105v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Achintya Kundu, Rhui Dih Lee, Laura Wynter, Raghu Kiran Ganti, Mayank Mishra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Padding is often used in tuning LLM models by adding special tokens to
shorter training examples to match the length of the longest sequence in each
batch. While this ensures uniformity for batch processing, it introduces
inefficiencies by including irrelevant padding tokens in the computation and
wastes GPU resources. On the other hand, the Hugging Face SFT trainer offers
the option to use packing to combine multiple training examples up to the
maximum sequence length. This allows for maximal utilization of GPU resources.
However, without proper masking of each packed training example, attention will
not be computed correctly when using SFT trainer. We enable and then analyse
packing and Flash Attention with proper attention masking of each example and
show the benefits of this training paradigm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards AI-Architecture Li<span class="highlight-title">bert</span>y: A Comprehensive <span class="highlight-title">Survey</span> on Design and
  Generation of Virtual Architecture by Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.00510v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.00510v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anqi Wang, Jiahua Dong, Lik-Hang Lee, Jiachuan Shen, Pan Hui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D shape generation techniques leveraging deep learning have garnered
significant interest from both the computer vision and architectural design
communities, promising to enrich the content in the virtual environment.
However, research on virtual architectural design remains limited, particularly
regarding designer-AI collaboration and deep learning-assisted design. In our
survey, we reviewed 149 related articles (81.2% of articles published between
2019 and 2023) covering architectural design, 3D shape techniques, and virtual
environments. Through scrutinizing the literature, we first identify the
principles of virtual architecture and illuminate its current production
challenges, including datasets, multimodality, design intuition, and generative
frameworks. We then introduce the latest approaches to designing and generating
virtual buildings leveraging 3D shape generation and summarize four
characteristics of various approaches to virtual architecture. Based on our
analysis, we expound on four research agendas, including agency, communication,
user consideration, and integrating tools. Additionally, we highlight four
important enablers of ubiquitous interaction with immersive systems in deep
learning-assisted architectural generation. Our work contributes to fostering
understanding between designers and deep learning techniques, broadening access
to designer-AI collaboration. We advocate for interdisciplinary efforts to
address this timely research topic, facilitating content designing and
generation in the virtual environment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>36 pages, 9 figures, and 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Aligning Cyber Space with Physical World: A Comprehensive <span class="highlight-title">Survey</span> on
  Embodied AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06886v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06886v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Liu, Weixing Chen, Yongjie Bai, Jingzhou Luo, Xinshuai Song, Kaixuan Jiang, Zhida Li, Ganlong Zhao, Junyi Lin, Guanbin Li, Wen Gao, Liang Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embodied Artificial Intelligence (Embodied AI) is crucial for achieving
Artificial General Intelligence (AGI) and serves as a foundation for various
applications that bridge cyberspace and the physical world. Recently, the
emergence of Multi-modal Large Models (MLMs) and World Models (WMs) have
attracted significant attention due to their remarkable perception,
interaction, and reasoning capabilities, making them a promising architecture
for the brain of embodied agents. However, there is no comprehensive survey for
Embodied AI in the era of MLMs. In this survey, we give a comprehensive
exploration of the latest advancements in Embodied AI. Our analysis firstly
navigates through the forefront of representative works of embodied robots and
simulators, to fully understand the research focuses and their limitations.
Then, we analyze four main research targets: 1) embodied perception, 2)
embodied interaction, 3) embodied agent, and 4) sim-to-real adaptation,
covering the state-of-the-art methods, essential paradigms, and comprehensive
datasets. Additionally, we explore the complexities of MLMs in virtual and real
embodied agents, highlighting their significance in facilitating interactions
in dynamic digital and physical environments. Finally, we summarize the
challenges and limitations of embodied AI and discuss their potential future
directions. We hope this survey will serve as a foundational reference for the
research community and inspire continued innovation. The associated project can
be found at https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first comprehensive review of Embodied AI in the era of MLMs, 37
  pages. We also provide the paper list for Embodied AI:
  https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for
  LLM Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13352v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13352v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Edoardo Debenedetti, Jie Zhang, Mislav Balunović, Luca Beurer-Kellner, Marc Fischer, Florian Tramèr
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  AI agents aim to solve complex tasks by combining text-based reasoning with
external tool calls. Unfortunately, AI agents are vulnerable to prompt
injection attacks where data returned by external tools hijacks the agent to
execute malicious tasks. To measure the adversarial robustness of AI agents, we
introduce AgentDojo, an evaluation framework for agents that execute tools over
untrusted data. To capture the evolving nature of attacks and defenses,
AgentDojo is not a static test suite, but rather an extensible environment for
designing and evaluating new agent tasks, defenses, and adaptive attacks. We
populate the environment with 97 realistic tasks (e.g., managing an email
client, navigating an e-banking website, or making travel bookings), 629
security test cases, and various attack and defense paradigms from the
literature. We find that AgentDojo poses a challenge for both attacks and
defenses: state-of-the-art LLMs fail at many tasks (even in the absence of
attacks), and existing prompt injection attacks break some security properties
but not all. We hope that AgentDojo can foster research on new design
principles for AI agents that solve common tasks in a reliable and robust
manner. We release the code for AgentDojo at
https://github.com/ethz-spylab/agentdojo.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Updated version after fixing a bug in the Llama implementation and
  updating the travel suite</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From paintbrush to pixel: A <span class="highlight-title">review</span> of deep neural networks in
  AI-generated art 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2302.10913v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2302.10913v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anne-Sofie Maerten, Derya Soydaner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper delves into the fascinating field of AI-generated art and explores
the various deep neural network architectures and models that have been
utilized to create it. From the classic convolutional networks to the
cutting-edge diffusion models, we examine the key players in the field. We
explain the general structures and working principles of these neural networks.
Then, we showcase examples of milestones, starting with the dreamy landscapes
of DeepDream and moving on to the most recent developments, including Stable
Diffusion and DALL-E 3, which produce mesmerizing images. We provide a detailed
comparison of these models, highlighting their strengths and limitations, and
examining the remarkable progress that deep neural networks have made so far in
a short period of time. With a unique blend of technical explanations and
insights into the current state of AI-generated art, this paper exemplifies how
art and computer science interact.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Graph Attention with Random Rewiring 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.05649v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.05649v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tongzhou Liao, Barnabás Póczos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph Neural Networks (GNNs) have become fundamental in graph-structured deep
learning. Key paradigms of modern GNNs include message passing, graph rewiring,
and Graph Transformers. This paper introduces Graph-Rewiring Attention with
Stochastic Structures (GRASS), a novel GNN architecture that combines the
advantages of these three paradigms. GRASS rewires the input graph by
superimposing a random regular graph, enhancing long-range information
propagation while preserving structural features of the input graph. It also
employs a unique additive attention mechanism tailored for graph-structured
data, providing a graph inductive bias while remaining computationally
efficient. Our empirical evaluations demonstrate that GRASS achieves
state-of-the-art performance on multiple benchmark datasets, confirming its
practical efficacy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Receler: Reliable Concept Erasing of Text-to-Image Diffusion Models via
  Lightweight Erasers <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.17717v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.17717v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chi-Pin Huang, Kai-Po Chang, Chung-Ting Tsai, Yung-Hsuan Lai, Fu-En Yang, Yu-Chiang Frank Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Concept erasure in text-to-image diffusion models aims to disable pre-trained
diffusion models from generating images related to a target concept. To perform
reliable concept erasure, the properties of robustness and locality are
desirable. The former refrains the model from producing images associated with
the target concept for any paraphrased or learned prompts, while the latter
preserves its ability in generating images with non-target concepts. In this
paper, we propose Reliable Concept Erasing via Lightweight Erasers (Receler).
It learns a lightweight Eraser to perform concept erasing while satisfying the
above desirable properties through the proposed concept-localized
regularization and adversarial prompt learning scheme. Experiments with various
concepts verify the superiority of Receler over previous methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024. Project page:
  https://jasper0314-huang.github.io/receler-concept-erasing/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Attention-based Class-Conditioned Alignment for Multi-Source Domain
  Adaptation of Object Detectors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.09918v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.09918v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Atif Belal, Akhil Meethal, Francisco Perdigon Romero, Marco Pedersoli, Eric Granger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Domain adaptation methods for object detection (OD) strive to mitigate the
impact of distribution shifts by promoting feature alignment across source and
target domains. Multi-source domain adaptation (MSDA) allows leveraging
multiple annotated source datasets and unlabeled target data to improve the
accuracy and robustness of the detection model. Most state-of-the-art MSDA
methods for OD perform feature alignment in a class-agnostic manner. This is
challenging since the objects have unique modal information due to variations
in object appearance across domains. A recent prototype-based approach proposed
a class-wise alignment, yet it suffers from error accumulation due to noisy
pseudo-labels that can negatively affect adaptation with imbalanced data. To
overcome these limitations, we propose an attention-based class-conditioned
alignment method for MSDA that aligns instances of each object category across
domains. In particular, an attention module coupled with an adversarial domain
classifier allows learning domain-invariant and class-specific instance
representations. Experimental results on multiple benchmarking MSDA datasets
indicate that our method outperforms the state-of-the-art methods and is robust
to class imbalance using a conceptually simple class-conditioning method. Our
code is available at https://github.com/imatif17/ACIA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Collective Variable Free Transition Path Sampling with Generative Flow
  Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19961v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19961v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kiyoung Seong, Seonghyun Park, Seonghwan Kim, Woo Youn Kim, Sungsoo Ahn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding transition paths between meta-stable states in molecular
systems is fundamental for material design and drug discovery. However,
sampling these paths via unbiased molecular dynamics simulations is
computationally prohibitive due to the high energy barriers between the
meta-stable states. Recent machine learning approaches are often restricted to
simple systems or rely on collective variables (CVs) extracted from expensive
domain knowledge. In this work, we propose to leverage generative flow networks
(GFlowNets) to sample transition paths without relying on CVs. We reformulate
the problem as amortized energy-based sampling over transition paths and train
a neural bias potential by minimizing the squared log-ratio between the target
distribution and the generator, derived from the flow matching objective of
GFlowNets. Our evaluation on three proteins (Alanine Dipeptide, Polyproline
Helix, and Chignolin) demonstrates that our approach, called TPS-GFN, generates
more realistic and diverse transition paths than the previous CV-free machine
learning approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 5 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fermi-Bose Machine achieves both generalization and adversarial
  robustness 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.13631v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.13631v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingshan Xie, Yuchen Wang, Haiping Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Distinct from human cognitive processing, deep neural networks trained by
backpropagation can be easily fooled by adversarial examples. To design a
semantically meaningful representation learning, we discard backpropagation,
and instead, propose a local contrastive learning, where the representation for
the inputs bearing the same label shrink (akin to boson) in hidden layers,
while those of different labels repel (akin to fermion). This layer-wise
learning is local in nature, being biological plausible. A statistical
mechanics analysis shows that the target fermion-pair-distance is a key
parameter. Moreover, the application of this local contrastive learning to
MNIST benchmark dataset demonstrates that the adversarial vulnerability of
standard perceptron can be greatly mitigated by tuning the target distance,
i.e., controlling the geometric separation of prototype manifolds.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages, 6 figures, a physics inspired machine without
  backpropagation yet with enhanced adversarial robustness</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Blood Glucose Control Via <span class="highlight-title">Pre-train</span>ed Counterfactual Invertible Neural
  Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17458v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17458v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingchi Jiang, Rujia Shen, Boran Wang, Yi Guan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Type 1 diabetes mellitus (T1D) is characterized by insulin deficiency and
blood glucose (BG) control issues. The state-of-the-art solution for continuous
BG control is reinforcement learning (RL), where an agent can dynamically
adjust exogenous insulin doses in time to maintain BG levels within the target
range. However, due to the lack of action guidance, the agent often needs to
learn from randomized trials to understand misleading correlations between
exogenous insulin doses and BG levels, which can lead to instability and
unsafety. To address these challenges, we propose an introspective RL based on
Counterfactual Invertible Neural Networks (CINN). We use the pre-trained CINN
as a frozen introspective block of the RL agent, which integrates forward
prediction and counterfactual inference to guide the policy updates, promoting
more stable and safer BG control. Constructed based on interpretable causal
order, CINN employs bidirectional encoders with affine coupling layers to
ensure invertibility while using orthogonal weight normalization to enhance the
trainability, thereby ensuring the bidirectional differentiability of network
parameters. We experimentally validate the accuracy and generalization ability
of the pre-trained CINN in BG prediction and counterfactual inference for
action. Furthermore, our experimental results highlight the effectiveness of
pre-trained CINN in guiding RL policy updates for more accurate and safer BG
control.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mechanics-Informed Autoencoder Enables Automated Detection and
  Localization of Unforeseen Structural Damage 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.15492v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.15492v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuyang Li, Hamed Bolandi, Mahdi Masmoudi, Talal Salem, Nizar Lajnef, Vishnu Naresh Boddeti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Structural health monitoring (SHM) ensures the safety and longevity of
structures like buildings and bridges. As the volume and scale of structures
and the impact of their failure continue to grow, there is a dire need for SHM
techniques that are scalable, inexpensive, can operate passively without human
intervention, and are customized for each mechanical structure without the need
for complex baseline models. We present MIDAS, a novel "deploy-and-forget"
approach for automated detection and localization of damage in structures. It
is a synergistic integration of entirely passive measurements from inexpensive
sensors, data compression, and a mechanics-informed autoencoder. Once deployed,
MIDAS continuously learns and adapts a bespoke baseline model for each
structure, learning from its undamaged state's response characteristics. After
learning from just 3 hours of data, it can autonomously detect and localize
different types of unforeseen damage. Results from numerical simulations and
experiments indicate that incorporating the mechanical characteristics into the
autoencoder allows for up to a 35% improvement in the detection and
localization of minor damage over a standard autoencoder. Our approach holds
significant promise for reducing human intervention and inspection costs while
enabling proactive and preventive maintenance strategies. This will extend the
lifespan, reliability, and sustainability of civil infrastructures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SGOOD: Substructure-enhanced Graph-Level Out-of-Distribution Detection <span class="chip">CIKM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.10237v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.10237v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhihao Ding, Jieming Shi, Shiqi Shen, Xuequn Shang, Jiannong Cao, Zhipeng Wang, Zhi Gong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph-level representation learning is important in a wide range of
applications. Existing graph-level models are generally built on i.i.d.
assumption for both training and testing graphs. However, in an open world,
models can encounter out-of-distribution (OOD) testing graphs that are from
different distributions unknown during training. A trustworthy model should be
able to detect OOD graphs to avoid unreliable predictions, while producing
accurate in-distribution (ID) predictions. To achieve this, we present SGOOD, a
novel graph-level OOD detection framework. We find that substructure
differences commonly exist between ID and OOD graphs, and design SGOOD with a
series of techniques to encode task-agnostic substructures for effective OOD
detection. Specifically, we build a super graph of substructures for every
graph, and develop a two-level graph encoding pipeline that works on both
original graphs and super graphs to obtain substructure-enhanced graph
representations. We then devise substructure-preserving graph augmentation
techniques to further capture more substructure semantics of ID graphs.
Extensive experiments against 11 competitors on numerous graph datasets
demonstrate the superiority of SGOOD, often surpassing existing methods by a
significant margin. The code is available at https://github.com/TommyDzh/SGOOD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CIKM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GraphRCG: Self-Conditioned Graph Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.01071v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.01071v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Song Wang, Zhen Tan, Xinyu Zhao, Tianlong Chen, Huan Liu, Jundong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph generation generally aims to create new graphs that closely align with
a specific graph distribution. Existing works often implicitly capture this
distribution through the optimization of generators, potentially overlooking
the intricacies of the distribution itself. Furthermore, these approaches
generally neglect the insights offered by the learned distribution for graph
generation. In contrast, in this work, we propose a novel self-conditioned
graph generation framework designed to explicitly model graph distributions and
employ these distributions to guide the generation process. We first perform
self-conditioned modeling to capture the graph distributions by transforming
each graph sample into a low-dimensional representation and optimizing a
representation generator to create new representations reflective of the
learned distribution. Subsequently, we leverage these bootstrapped
representations as self-conditioned guidance for the generation process,
thereby facilitating the generation of graphs that more accurately reflect the
learned distributions. We conduct extensive experiments on generic and
molecular graph datasets across various fields. Our framework demonstrates
superior performance over existing state-of-the-art graph generation methods in
terms of graph quality and fidelity to training data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Effective Illicit Account Detection on Large Cryptocurrency MultiGraphs <span class="chip">CIKM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.02460v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.02460v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhihao Ding, Jieming Shi, Qing Li, Jiannong Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cryptocurrencies are rapidly expanding and becoming vital in digital
financial markets. However, the rise in cryptocurrency-related illicit
activities has led to significant losses for users. To protect the security of
these platforms, it is critical to identify illicit accounts effectively.
Current detection methods mainly depend on feature engineering or are
inadequate to leverage the complex information within cryptocurrency
transaction networks, resulting in suboptimal performance. In this paper, we
present DIAM, an effective method for detecting illicit accounts in
cryptocurrency transaction networks modeled by directed multi-graphs with
attributed edges. DIAM first features an Edge2Seq module that captures
intrinsic transaction patterns from parallel edges by considering edge
attributes and their directed sequences, to generate effective node
representations. Then in DIAM, we design a multigraph Discrepancy (MGD) module
with a tailored message passing mechanism to capture the discrepant features
between normal and illicit nodes over the multigraph topology, assisted by an
attention mechanism. DIAM integrates these techniques for end-to-end training
to detect illicit accounts from legitimate ones. Extensive experiments,
comparing against 15 existing solutions on 4 large cryptocurrency datasets of
Bitcoin and Ethereum, demonstrate that DIAM consistently outperforms others in
accurately identifying illicit accounts. For example, on a Bitcoin dataset with
20 million nodes and 203 million edges, DIAM attains an F1 score of 96.55%,
markedly surpassing the runner-up's score of 83.92%. The code is available at
https://github.com/TommyDzh/DIAM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CIKM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Detecting out-of-distribution text using topological features of
  <span class="highlight-title">transformer</span>-based language models <span class="chip">IJCAI-2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.13102v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.13102v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andres Pollano, Anupam Chaudhuri, Anj Simmons
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To safeguard machine learning systems that operate on textual data against
out-of-distribution (OOD) inputs that could cause unpredictable behaviour, we
explore the use of topological features of self-attention maps from
transformer-based language models to detect when input text is out of
distribution. Self-attention forms the core of transformer-based language
models, dynamically assigning vectors to words based on context, thus in theory
our methodology is applicable to any transformer-based language model with
multihead self-attention. We evaluate our approach on BERT and compare it to a
traditional OOD approach using CLS embeddings. Our results show that our
approach outperforms CLS embeddings in distinguishing in-distribution samples
from far-out-of-domain samples, but struggles with near or same-domain
datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 6 figures, 3 tables, to be published in proceedings of the
  IJCAI-2024 AISafety Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Can LLMs Patch Security Issues? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.00024v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.00024v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kamel Alrashedy, Abdullah Aljasser, Pradyumna Tambwekar, Matthew Gombolay
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown impressive proficiency in code
generation. Unfortunately, these models share a weakness with their human
counterparts: producing code that inadvertently has security vulnerabilities.
These vulnerabilities could allow unauthorized attackers to access sensitive
data or systems, which is unacceptable for safety-critical applications. In
this work, we propose Feedback-Driven Security Patching (FDSP), where LLMs
automatically refine generated, vulnerable code. Our approach leverages
automatic static code analysis to empower the LLM to generate and implement
potential solutions to address vulnerabilities. We address the research
communitys needs for safe code generation by introducing a large-scale dataset,
PythonSecurityEval, covering the diversity of real-world applications,
including databases, websites and operating systems. We empirically validate
that FDSP outperforms prior work that uses self-feedback from LLMs by up to
17.6% through our procedure that injects targeted, external feedback. Code and
data are available at \url{https://github.com/Kamel773/LLM-code-refine}
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Personalized Federated Domain-Incremental Learning based on Adaptive
  Knowledge Matching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.05005v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.05005v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yichen Li, Wenchao Xu, Haozhao Wang, Ruixuan Li, Yining Qi, Jingcai Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper focuses on Federated Domain-Incremental Learning (FDIL) where each
client continues to learn incremental tasks where their domain shifts from each
other. We propose a novel adaptive knowledge matching-based personalized FDIL
approach (pFedDIL) which allows each client to alternatively utilize
appropriate incremental task learning strategy on the correlation with the
knowledge from previous tasks. More specifically, when a new task arrives, each
client first calculates its local correlations with previous tasks. Then, the
client can choose to adopt a new initial model or a previous model with similar
knowledge to train the new task and simultaneously migrate knowledge from
previous tasks based on these correlations. Furthermore, to identify the
correlations between the new task and previous tasks for each client, we
separately employ an auxiliary classifier to each target classification model
and propose sharing partial parameters between the target classification model
and the auxiliary classifier to condense model parameters. We conduct extensive
experiments on several datasets of which results demonstrate that pFedDIL
outperforms state-of-the-art methods by up to 14.35\% in terms of average
accuracy of all tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SkyMask: Attack-agnostic Robust Federated Learning with Fine-grained
  Learnable Masks <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.12484v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.12484v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peishen Yan, Hao Wang, Tao Song, Yang Hua, Ruhui Ma, Ningxin Hu, Mohammad R. Haghighat, Haibing Guan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated Learning (FL) is becoming a popular paradigm for leveraging
distributed data and preserving data privacy. However, due to the distributed
characteristic, FL systems are vulnerable to Byzantine attacks that compromised
clients attack the global model by uploading malicious model updates. With the
development of layer-level and parameter-level fine-grained attacks, the
attacks' stealthiness and effectiveness have been significantly improved. The
existing defense mechanisms solely analyze the model-level statistics of
individual model updates uploaded by clients to mitigate Byzantine attacks,
which are ineffective against fine-grained attacks due to unawareness or
overreaction. To address this problem, we propose SkyMask, a new
attack-agnostic robust FL system that firstly leverages fine-grained learnable
masks to identify malicious model updates at the parameter level. Specifically,
the FL server freezes and multiplies the model updates uploaded by clients with
the parameter-level masks, and trains the masks over a small clean dataset
(i.e., root dataset) to learn the subtle difference between benign and
malicious model updates in a high-dimension space. Our extensive experiments
involve different models on three public datasets under state-of-the-art (SOTA)
attacks, where the results show that SkyMask achieves up to 14% higher testing
accuracy compared with SOTA defense strategies under the same attacks and
successfully defends against attacks with malicious clients of a high fraction
up to 80%. Code is available at https://github.com/KoalaYan/SkyMask.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Labelled <span class="highlight-title">Dataset</span> for Sentiment Analysis of Videos on YouTube, TikTok,
  and Other Sources about the 2024 Outbreak of Measles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.07693v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.07693v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nirmalya Thakur, Vanessa Su, Mingchen Shao, Kesha A. Patel, Hongseok Jeong, Victoria Knieling, Andrew Bian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The work of this paper presents a dataset that contains the data of 4011
videos about the ongoing outbreak of measles published on 264 websites on the
internet between January 1, 2024, and May 31, 2024. The dataset is available at
https://dx.doi.org/10.21227/40s8-xf63. These websites primarily include YouTube
and TikTok, which account for 48.6% and 15.2% of the videos, respectively. The
remainder of the websites include Instagram and Facebook as well as the
websites of various global and local news organizations. For each of these
videos, the URL of the video, title of the post, description of the post, and
the date of publication of the video are presented as separate attributes in
the dataset. After developing this dataset, sentiment analysis (using VADER),
subjectivity analysis (using TextBlob), and fine-grain sentiment analysis
(using DistilRoBERTa-base) of the video titles and video descriptions were
performed. This included classifying each video title and video description
into (i) one of the sentiment classes i.e. positive, negative, or neutral, (ii)
one of the subjectivity classes i.e. highly opinionated, neutral opinionated,
or least opinionated, and (iii) one of the fine-grain sentiment classes i.e.
fear, surprise, joy, sadness, anger, disgust, or neutral. These results are
presented as separate attributes in the dataset for the training and testing of
machine learning algorithms for performing sentiment analysis or subjectivity
analysis in this field as well as for other applications. Finally, this paper
also presents a list of open research questions that may be investigated using
this dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Simple Graph Condensation <span class="chip">ECML-PKDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.14951v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.14951v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenbang Xiao, Yu Wang, Shunyu Liu, Huiqiong Wang, Mingli Song, Tongya Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The burdensome training costs on large-scale graphs have aroused significant
interest in graph condensation, which involves tuning Graph Neural Networks
(GNNs) on a small condensed graph for use on the large-scale original graph.
Existing methods primarily focus on aligning key metrics between the condensed
and original graphs, such as gradients, output distribution and trajectories of
GNNs, yielding satisfactory performance on downstream tasks. However, these
complex metrics necessitate intricate external parameters and can potentially
disrupt the optimization process of the condensation graph, making the
condensation process highly demanding and unstable. Motivated by the recent
success of simplified models across various domains, we propose a simplified
approach to metric alignment in graph condensation, aiming to reduce
unnecessary complexity inherited from intricate metrics. We introduce the
Simple Graph Condensation (SimGC) framework, which aligns the condensed graph
with the original graph from the input layer to the prediction layer, guided by
a pre-trained Simple Graph Convolution (SGC) model on the original graph.
Importantly, SimGC eliminates external parameters and exclusively retains the
target condensed graph during the condensation process. This straightforward
yet effective strategy achieves a significant speedup of up to 10 times
compared to existing graph condensation methods while performing on par with
state-of-the-art baselines. Comprehensive experiments conducted on seven
benchmark datasets demonstrate the effectiveness of SimGC in prediction
accuracy, condensation time, and generalization capability. Our code is
available at https://github.com/BangHonor/SimGC.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECML-PKDD 2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">8</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Aligning Sight and Sound: Advanced Sound Source Localization Through
  Audio-Visual Alignment <span class="chip">ICCV 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13676v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13676v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arda Senocak, Hyeonggon Ryu, Junsik Kim, Tae-Hyun Oh, Hanspeter Pfister, Joon Son Chung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies on learning-based sound source localization have mainly
focused on the localization performance perspective. However, prior work and
existing benchmarks overlook a crucial aspect: cross-modal interaction, which
is essential for interactive sound source localization. Cross-modal interaction
is vital for understanding semantically matched or mismatched audio-visual
events, such as silent objects or off-screen sounds. In this paper, we first
comprehensively examine the cross-modal interaction of existing methods,
benchmarks, evaluation metrics, and cross-modal understanding tasks. Then, we
identify the limitations of previous studies and make several contributions to
overcome the limitations. First, we introduce a new synthetic benchmark for
interactive sound source localization. Second, we introduce new evaluation
metrics to rigorously assess sound source localization methods, focusing on
accurately evaluating both localization performance and cross-modal interaction
ability. Third, we propose a learning framework with a cross-modal alignment
strategy to enhance cross-modal interaction. Lastly, we evaluate both
interactive sound source localization and auxiliary cross-modal retrieval tasks
together to thoroughly assess cross-modal interaction capabilities and
benchmark competing methods. Our new benchmarks and evaluation metrics reveal
previously overlooked issues in sound source localization studies. Our proposed
novel method, with enhanced cross-modal alignment, shows superior sound source
localization performance. This work provides the most comprehensive analysis of
sound source localization to date, with extensive validation of competing
methods on both existing and new benchmarks using new and standard evaluation
metrics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Journal Extension of ICCV 2023 paper (arXiV:2309.10724). Code is
  available at https://github.com/kaistmm/SSLalignment</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Similarity over Factuality: Are we making progress on multimodal
  out-of-context misinformation detection? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13488v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13488v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Stefanos-Iordanis Papadopoulos, Christos Koutlis, Symeon Papadopoulos, Panagiotis C. Petrantonakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Out-of-context (OOC) misinformation poses a significant challenge in
multimodal fact-checking, where images are paired with texts that misrepresent
their original context to support false narratives. Recent research in
evidence-based OOC detection has seen a trend towards increasingly complex
architectures, incorporating Transformers, foundation models, and large
language models. In this study, we introduce a simple yet robust baseline,
which assesses MUltimodal SimilaritiEs (MUSE), specifically the similarity
between image-text pairs and external image and text evidence. Our results
demonstrate that MUSE, when used with conventional classifiers like Decision
Tree, Random Forest, and Multilayer Perceptron, can compete with and even
surpass the state-of-the-art on the NewsCLIPpings and VERITE datasets.
Furthermore, integrating MUSE in our proposed "Attentive Intermediate
Transformer Representations" (AITR) significantly improved performance, by 3.3%
and 7.5% on NewsCLIPpings and VERITE, respectively. Nevertheless, the success
of MUSE, relying on surface-level patterns and shortcuts, without examining
factuality and logical inconsistencies, raises critical questions about how we
define the task, construct datasets, collect external evidence and overall, how
we assess progress in the field. We release our code at:
https://github.com/stevejpapad/outcontext-misinfo-progress
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exposure Completing for Temporally Consistent Neural High Dynamic Range
  Video Rendering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13309v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13309v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Cui, Wei Jiang, Zhan Peng, Zhiyu Pan, Zhiguo Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High dynamic range (HDR) video rendering from low dynamic range (LDR) videos
where frames are of alternate exposure encounters significant challenges, due
to the exposure change and absence at each time stamp. The exposure change and
absence make existing methods generate flickering HDR results. In this paper,
we propose a novel paradigm to render HDR frames via completing the absent
exposure information, hence the exposure information is complete and
consistent. Our approach involves interpolating neighbor LDR frames in the time
dimension to reconstruct LDR frames for the absent exposures. Combining the
interpolated and given LDR frames, the complete set of exposure information is
available at each time stamp. This benefits the fusing process for HDR results,
reducing noise and ghosting artifacts therefore improving temporal consistency.
Extensive experimental evaluations on standard benchmarks demonstrate that our
method achieves state-of-the-art performance, highlighting the importance of
absent exposure completing in HDR video rendering. The code is available at
https://github.com/cuijiahao666/NECHDR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 6 figures, accepted by ACM-MM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SOMONITOR: Explainable Marketing Data Processing and Analysis with Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13117v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13117v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qi Yang, Sergey Nikolenko, Marlo Ongpin, Ilia Gossoudarev, Yu-Yi Chu-Farseeva, Aleksandr Farseev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online marketing faces formidable challenges in managing and interpreting
immense volumes of data necessary for competitor analysis, content research,
and strategic branding. It is impossible to review hundreds to thousands of
transient online content items by hand, and partial analysis often leads to
suboptimal outcomes and poorly performing campaigns. We introduce an
explainable AI framework SoMonitor that aims to synergize human intuition with
AI-based efficiency, helping marketers across all stages of the marketing
funnel, from strategic planning to content creation and campaign execution.
SoMonitor incorporates a CTR prediction and ranking model for advertising
content and uses large language models (LLMs) to process high-performing
competitor content, identifying core content pillars such as target audiences,
customer needs, and product features. These pillars are then organized into
broader categories, including communication themes and targeted customer
personas. By integrating these insights with data from the brand's own
advertising campaigns, SoMonitor constructs a narrative for addressing new
customer personas and simultaneously generates detailed content briefs in the
form of user stories that can be directly applied by marketing teams to
streamline content production and campaign execution. The adoption of SoMonitor
in daily operations allows digital marketers to quickly parse through extensive
datasets, offering actionable insights that significantly enhance campaign
effectiveness and overall job satisfaction
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PG-Attack: A Precision-Guided Adversarial Attack Framework Against
  Vision Foundation Models for Autonomous Driving <span class="chip">CVPR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13111v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13111v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiyuan Fu, Zhaoyu Chen, Kaixun Jiang, Haijing Guo, Shuyong Gao, Wenqiang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision foundation models are increasingly employed in autonomous driving
systems due to their advanced capabilities. However, these models are
susceptible to adversarial attacks, posing significant risks to the reliability
and safety of autonomous vehicles. Adversaries can exploit these
vulnerabilities to manipulate the vehicle's perception of its surroundings,
leading to erroneous decisions and potentially catastrophic consequences. To
address this challenge, we propose a novel Precision-Guided Adversarial Attack
(PG-Attack) framework that combines two techniques: Precision Mask Perturbation
Attack (PMP-Attack) and Deceptive Text Patch Attack (DTP-Attack). PMP-Attack
precisely targets the attack region to minimize the overall perturbation while
maximizing its impact on the target object's representation in the model's
feature space. DTP-Attack introduces deceptive text patches that disrupt the
model's understanding of the scene, further enhancing the attack's
effectiveness. Our experiments demonstrate that PG-Attack successfully deceives
a variety of advanced multi-modal large models, including GPT-4V, Qwen-VL, and
imp-V1. Additionally, we won First-Place in the CVPR 2024 Workshop Challenge:
Black-box Adversarial Attacks on Vision Foundation Models and codes are
available at https://github.com/fuhaha824/PG-Attack.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>First-Place in the CVPR 2024 Workshop Challenge: Black-box
  Adversarial Attacks on Vision Foundation Models</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Audio-visual Generalized Zero-shot Learning the Easy Way 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13095v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13095v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shentong Mo, Pedro Morgado
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Audio-visual generalized zero-shot learning is a rapidly advancing domain
that seeks to understand the intricate relations between audio and visual cues
within videos. The overarching goal is to leverage insights from seen classes
to identify instances from previously unseen ones. Prior approaches primarily
utilized synchronized auto-encoders to reconstruct audio-visual attributes,
which were informed by cross-attention transformers and projected text
embeddings. However, these methods fell short of effectively capturing the
intricate relationship between cross-modal features and class-label embeddings
inherent in pre-trained language-aligned embeddings. To circumvent these
bottlenecks, we introduce a simple yet effective framework for Easy
Audio-Visual Generalized Zero-shot Learning, named EZ-AVGZL, that aligns
audio-visual embeddings with transformed text representations. It utilizes a
single supervised text audio-visual contrastive loss to learn an alignment
between audio-visual and textual modalities, moving away from the conventional
approach of reconstructing cross-modal features and text embeddings. Our key
insight is that while class name embeddings are well aligned with
language-based audio-visual features, they don't provide sufficient class
separation to be useful for zero-shot learning. To address this, our method
leverages differential optimization to transform class embeddings into a more
discriminative space while preserving the semantic structure of language
representations. We conduct extensive experiments on VGGSound-GZSL, UCF-GZSL,
and ActivityNet-GZSL benchmarks. Our results demonstrate that our EZ-AVGZL
achieves state-of-the-art performance in audio-visual generalized zero-shot
learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> of Multimodal Large Language Model from A Data-centric
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16640v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16640v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyi Bai, Hao Liang, Binwang Wan, Yanran Xu, Xi Li, Shiyu Li, Ling Yang, Bozhou Li, Yifan Wang, Bin Cui, Ping Huang, Jiulong Shan, Conghui He, Binhang Yuan, Wentao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal large language models (MLLMs) enhance the capabilities of standard
large language models by integrating and processing data from multiple
modalities, including text, vision, audio, video, and 3D environments. Data
plays a pivotal role in the development and refinement of these models. In this
survey, we comprehensively review the literature on MLLMs from a data-centric
perspective. Specifically, we explore methods for preparing multimodal data
during the pretraining and adaptation phases of MLLMs. Additionally, we analyze
the evaluation methods for the datasets and review the benchmarks for
evaluating MLLMs. Our survey also outlines potential future research
directions. This work aims to provide researchers with a detailed understanding
of the data-driven aspects of MLLMs, fostering further exploration and
innovation in this field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AMUSE: Adaptive Multi-Segment Encoding for <span class="highlight-title">Dataset</span> Watermarking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.05628v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.05628v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saeed Ranjbar Alvar, Mohammad Akbari, David Ming Xuan Yue, Yong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Curating high quality datasets that play a key role in the emergence of new
AI applications requires considerable time, money, and computational resources.
So, effective ownership protection of datasets is becoming critical. Recently,
to protect the ownership of an image dataset, imperceptible watermarking
techniques are used to store ownership information (i.e., watermark) into the
individual image samples. Embedding the entire watermark into all samples leads
to significant redundancy in the embedded information which damages the
watermarked dataset quality and extraction accuracy. In this paper, a
multi-segment encoding-decoding method for dataset watermarking (called AMUSE)
is proposed to adaptively map the original watermark into a set of shorter
sub-messages and vice versa. Our message encoder is an adaptive method that
adjusts the length of the sub-messages according to the protection requirements
for the target dataset. Existing image watermarking methods are then employed
to embed the sub-messages into the original images in the dataset and also to
extract them from the watermarked images. Our decoder is then used to
reconstruct the original message from the extracted sub-messages. The proposed
encoder and decoder are plug-and-play modules that can easily be added to any
watermarking method. To this end, extensive experiments are preformed with
multiple watermarking solutions which show that applying AMUSE improves the
overall message extraction accuracy upto 28% for the same given dataset
quality. Furthermore, the image dataset quality is enhanced by a PSNR of
$\approx$2 dB on average, while improving the extraction accuracy for one of
the tested image watermarking methods.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-07-17T00:00:00Z">2024-07-17</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">59</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Establishing Knowledge Preference in Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13048v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13048v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sizhe Zhou, Sha Li, Yu Meng, Yizhu Jiao, Heng Ji, Jiawei Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models are known to encode a great amount of factual knowledge
through pretraining. However, such knowledge might be insufficient to cater to
user requests, requiring the model to integrate external knowledge sources and
adhere to user-provided specifications. When answering questions about ongoing
events, the model should use recent news articles to update its response; when
asked to provide recommendations, the model should prioritize user
specifications over retrieved product reviews; when some facts are edited in
the model, the updated facts should override all prior knowledge learned by the
model even if they are conflicting. In all of the cases above, the model faces
a decision between its own parametric knowledge, (retrieved) contextual
knowledge, and user instruction knowledge. In this paper, we (1) unify such
settings into the problem of knowledge preference and define a three-level
preference hierarchy over these knowledge sources; (2) compile a collection of
existing datasets IfQA, MQuAKE, and MRQA covering a combination of settings
(with/without user specifications, with/without context documents) to
systematically evaluate how well models obey the intended knowledge preference;
and (3) propose a dataset synthesis method that composes diverse
question-answer pairs with user assumptions and related context to directly
fine-tune LMs for instilling the hierarchy of knowledge. We demonstrate that a
7B model, fine-tuned on only a few thousand examples automatically generated by
our proposed method, effectively achieves superior performance (more than 18%
improvement across all evaluation benchmarks) in adhering to the desired
knowledge preference hierarchy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 8 figures, 23 tables, working in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Turkish Delights: a <span class="highlight-title">Dataset</span> on Turkish Euphemisms <span class="chip">ACL
  2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13040v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13040v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hasan Can Biyik, Patrick Lee, Anna Feldman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Euphemisms are a form of figurative language relatively understudied in
natural language processing. This research extends the current computational
work on potentially euphemistic terms (PETs) to Turkish. We introduce the
Turkish PET dataset, the first available of its kind in the field. By creating
a list of euphemisms in Turkish, collecting example contexts, and annotating
them, we provide both euphemistic and non-euphemistic examples of PETs in
Turkish. We describe the dataset and methodologies, and also experiment with
transformer-based models on Turkish euphemism detection by using our dataset
for binary classification. We compare performances across models using F1,
accuracy, and precision as evaluation metrics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Proceedings of The First SIGTURK workshop co-located with ACL
  2024: https://sigturk.github.io/workshop/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Pre-Train</span>ed Foundation Model representations to uncover Breathing
  patterns in Speech <span class="chip">KDD</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13035v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13035v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vikramjit Mitra, Anirban Chatterjee, Ke Zhai, Helen Weng, Ayuko Hill, Nicole Hay, Christopher Webb, Jamie Cheng, Erdrin Azemi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The process of human speech production involves coordinated respiratory
action to elicit acoustic speech signals. Typically, speech is produced when
air is forced from the lungs and is modulated by the vocal tract, where such
actions are interspersed by moments of breathing in air (inhalation) to refill
the lungs again. Respiratory rate (RR) is a vital metric that is used to assess
the overall health, fitness, and general well-being of an individual. Existing
approaches to measure RR (number of breaths one takes in a minute) are
performed using specialized equipment or training. Studies have demonstrated
that machine learning algorithms can be used to estimate RR using bio-sensor
signals as input. Speech-based estimation of RR can offer an effective approach
to measure the vital metric without requiring any specialized equipment or
sensors. This work investigates a machine learning based approach to estimate
RR from speech segments obtained from subjects speaking to a close-talking
microphone device. Data were collected from N=26 individuals, where the
groundtruth RR was obtained through commercial grade chest-belts and then
manually corrected for any errors. A convolutional long-short term memory
network (Conv-LSTM) is proposed to estimate respiration time-series data from
the speech signal. We demonstrate that the use of pre-trained representations
obtained from a foundation model, such as Wav2Vec2, can be used to estimate
respiration-time-series with low root-mean-squared error and high correlation
coefficient, when compared with the baseline. The model-driven time series can
be used to estimate $RR$ with a low mean absolute error (MAE) ~ 1.6
breaths/min.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 6 figures, BioKDD workshop paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> of <span class="highlight-title">Prompt</span> Engineering Methods in Large Language Models for
  Different NLP Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12994v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12994v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubham Vatsal, Harsh Dubey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown remarkable performance on many
different Natural Language Processing (NLP) tasks. Prompt engineering plays a
key role in adding more to the already existing abilities of LLMs to achieve
significant performance gains on various NLP tasks. Prompt engineering requires
composing natural language instructions called prompts to elicit knowledge from
LLMs in a structured way. Unlike previous state-of-the-art (SoTA) models,
prompt engineering does not require extensive parameter re-training or
fine-tuning based on the given NLP task and thus solely operates on the
embedded knowledge of LLMs. Additionally, LLM enthusiasts can intelligently
extract LLMs' knowledge through a basic natural language conversational
exchange or prompt engineering, allowing more and more people even without deep
mathematical machine learning background to experiment with LLMs. With prompt
engineering gaining popularity in the last two years, researchers have come up
with numerous engineering techniques around designing prompts to improve
accuracy of information extraction from the LLMs. In this paper, we summarize
different prompting techniques and club them together based on different NLP
tasks that they have been used for. We further granularly highlight the
performance of these prompting strategies on various datasets belonging to that
NLP task, talk about the corresponding LLMs used, present a taxonomy diagram
and discuss the possible SoTA for specific datasets. In total, we read and
present a survey of 44 research papers which talk about 39 different prompting
methods on 29 different NLP tasks of which most of them have been published in
the last two years.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retrieval-Enhanced Machine Learning: Synthesis and Opportunities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12982v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12982v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        To Eun Kim, Alireza Salemi, Andrew Drozdov, Fernando Diaz, Hamed Zamani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the field of language modeling, models augmented with retrieval components
have emerged as a promising solution to address several challenges faced in the
natural language processing (NLP) field, including knowledge grounding,
interpretability, and scalability. Despite the primary focus on NLP, we posit
that the paradigm of retrieval-enhancement can be extended to a broader
spectrum of machine learning (ML) such as computer vision, time series
prediction, and computational biology. Therefore, this work introduces a formal
framework of this paradigm, Retrieval-Enhanced Machine Learning (REML), by
synthesizing the literature in various domains in ML with consistent notations
which is missing from the current literature. Also, we found that while a
number of studies employ retrieval components to augment their models, there is
a lack of integration with foundational Information Retrieval (IR) research. We
bridge this gap between the seminal IR research and contemporary REML studies
by investigating each component that comprises the REML framework. Ultimately,
the goal of this work is to equip researchers across various disciplines with a
comprehensive, formally structured framework of retrieval-enhanced models,
thereby fostering interdisciplinary future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Halu-J: Critique-Based Hallucination Judge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12943v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12943v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Binjie Wang, Steffi Chern, Ethan Chern, Pengfei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) frequently generate non-factual content, known
as hallucinations. Existing retrieval-augmented-based hallucination detection
approaches typically address this by framing it as a classification task,
evaluating hallucinations based on their consistency with retrieved evidence.
However, this approach usually lacks detailed explanations for these
evaluations and does not assess the reliability of these explanations.
Furthermore, deficiencies in retrieval systems can lead to irrelevant or
partially relevant evidence retrieval, impairing the detection process.
Moreover, while real-world hallucination detection requires analyzing multiple
pieces of evidence, current systems usually treat all evidence uniformly
without considering its relevance to the content. To address these challenges,
we introduce Halu-J, a critique-based hallucination judge with 7 billion
parameters. Halu-J enhances hallucination detection by selecting pertinent
evidence and providing detailed critiques. Our experiments indicate that Halu-J
outperforms GPT-4o in multiple-evidence hallucination detection and matches its
capability in critique generation and evidence selection. We also introduce
ME-FEVER, a new dataset designed for multiple-evidence hallucination detection.
Our code and dataset can be found in https://github.com/GAIR-NLP/factool .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12772v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12772v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaichen Zhang, Bo Li, Peiyuan Zhang, Fanyi Pu, Joshua Adrian Cahyono, Kairui Hu, Shuai Liu, Yuanhan Zhang, Jingkang Yang, Chunyuan Li, Ziwei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advances of large foundation models necessitate wide-coverage, low-cost,
and zero-contamination benchmarks. Despite continuous exploration of language
model evaluations, comprehensive studies on the evaluation of Large Multi-modal
Models (LMMs) remain limited. In this work, we introduce LMMS-EVAL, a unified
and standardized multimodal benchmark framework with over 50 tasks and more
than 10 models to promote transparent and reproducible evaluations. Although
LMMS-EVAL offers comprehensive coverage, we find it still falls short in
achieving low cost and zero contamination. To approach this evaluation
trilemma, we further introduce LMMS-EVAL LITE, a pruned evaluation toolkit that
emphasizes both coverage and efficiency. Additionally, we present Multimodal
LIVEBENCH that utilizes continuously updating news and online forums to assess
models' generalization abilities in the wild, featuring a low-cost and
zero-contamination evaluation approach. In summary, our work highlights the
importance of considering the evaluation trilemma and provides practical
solutions to navigate the trade-offs in evaluating large multi-modal models,
paving the way for more effective and reliable benchmarking of LMMs. We
opensource our codebase and maintain leaderboard of LIVEBENCH at
https://github.com/EvolvingLMMs-Lab/lmms-eval and
https://huggingface.co/spaces/lmms-lab/LiveBench.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code ad leaderboard are available at
  https://github.com/EvolvingLMMs-Lab/lmms-eval and
  https://huggingface.co/spaces/lmms-lab/LiveBench</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Role of Network and Identity in the Diffusion of Hashtags 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12771v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12771v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aparna Ananthasubramaniam, Yufei Zhu, David Jurgens, Daniel Romero
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although the spread of behaviors is influenced by many social factors,
existing literature tends to study the effects of single factors -- most often,
properties of the social network -- on the final cascade. In order to move
towards a more integrated view of cascades, this paper offers the first
comprehensive investigation into the role of two social factors in the
diffusion of 1,337 popular hashtags representing the production of novel
culture on Twitter: 1) the topology of the Twitter social network and 2)
performance of each user's probable demographic identity. Here, we show that
cascades are best modeled using a combination of network and identity, rather
than either factor alone. This combined model best reproduces a composite index
of ten cascade properties across all 1,337 hashtags. However, there is
important heterogeneity in what social factors are required to reproduce
different properties of hashtag cascades. For instance, while a combined
network+identity model best predicts the popularity of cascades, a network-only
model has better performance in predicting cascade growth and an identity-only
model in adopter composition. We are able to predict what type of hashtag is
best modeled by each combination of features and use this to further improve
performance. Additionally, consistent with prior literature on the combined
network+identity model most outperforms the single-factor counterfactuals among
hashtags used for expressing racial or regional identity, stance-taking,
talking about sports, or variants of existing cultural trends with very slow-
or fast-growing communicative need. In sum, our results imply the utility of
multi-factor models in predicting cascades, in order to account for the varied
ways in which network, identity, and other social factors play a role in the
diffusion of hashtags on Twitter.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HDLCopilot: Hardware Design Library Querying with Natural Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12749v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12749v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manar Abdelatty, Sherief Reda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hardware design engineers routinely work with multiple Process Design Kits
(PDKs) from various fabrication labs, each containing several standard cell
libraries, optimized for specific metric such as speed, power, or density.
These libraries include multiple views such as liberty files for timing
information, LEF files for abstract layout details, and technology LEF for
process design rules. Navigating this complex landscape to retrieve specific
information about gates or design rules is often time-consuming and
error-prone. To address this, we present HDLCopilot, an LLM-powered PDK query
system that allows engineers to streamline interactions with PDKs in natural
language format, making information retrieval accurate and more efficient.
HDLCopilot achieves an accuracy of 94.23\% on an evaluation set comprised of
diverse and complex natural language queries. HDLCopilot positions itself as a
powerful assistant in the hardware design process, enhancing productivity and
reducing potential human errors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A LLM Benchmark based on the Minecraft Builder Dialog Agent Task 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12734v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12734v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chris Madge, Massimo Poesio
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work we proposing adapting the Minecraft builder task into an LLM
benchmark suitable for evaluating LLM ability in spatially orientated tasks,
and informing builder agent design. Previous works have proposed corpora with
varying complex structures, and human written instructions. We instead attempt
to provide a comprehensive synthetic benchmark for testing builder agents over
a series of distinct tasks that comprise of common building operations. We
believe this approach allows us to probe specific strengths and weaknesses of
different agents, and test the ability of LLMs in the challenging area of
spatial reasoning and vector based math.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language
  Models? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12725v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12725v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ben Yao, Yazhou Zhang, Qiuchi Li, Jing Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Elaborating a series of intermediate reasoning steps significantly improves
the ability of large language models (LLMs) to solve complex problems, as such
steps would evoke LLMs to think sequentially. However, human sarcasm
understanding is often considered an intuitive and holistic cognitive process,
in which various linguistic, contextual, and emotional cues are integrated to
form a comprehensive understanding of the speaker's true intention, which is
argued not be limited to a step-by-step reasoning process. To verify this
argument, we introduce a new prompting framework called SarcasmCue, which
contains four prompting strategies, $viz.$ chain of contradiction (CoC), graph
of cues (GoC), bagging of cues (BoC) and tensor of cues (ToC), which elicits
LLMs to detect human sarcasm by considering sequential and non-sequential
prompting methods. Through a comprehensive empirical comparison on four
benchmarking datasets, we show that the proposed four prompting methods
outperforms standard IO prompting, CoT and ToT with a considerable margin, and
non-sequential prompting generally outperforms sequential prompting.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TTSDS -- Text-to-Speech Distribution Score 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12707v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12707v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christoph Minixhofer, Ondřej Klejch, Peter Bell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many recently published Text-to-Speech (TTS) systems produce audio close to
real speech. However, TTS evaluation needs to be revisited to make sense of the
results obtained with the new architectures, approaches and datasets. We
propose evaluating the quality of synthetic speech as a combination of multiple
factors such as prosody, speaker identity, and intelligibility. Our approach
assesses how well synthetic speech mirrors real speech by obtaining correlates
of each factor and measuring their distance from both real speech datasets and
noise datasets. We benchmark 35 TTS systems developed between 2008 and 2024 and
show that our score computed as an unweighted average of factors strongly
correlates with the human evaluations from each time period.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review for SLT 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Subgraph-Aware Training of Text-based Methods for Knowledge Graph
  Completion <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12703v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12703v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Youmin Ko, Hyemin Yang, Taeuk Kim, Hyunjoon Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fine-tuning pre-trained language models (PLMs) has recently shown a potential
to improve knowledge graph completion (KGC). However, most PLM-based methods
encode only textual information, neglecting various topological structures of
knowledge graphs (KGs). In this paper, we empirically validate the significant
relations between the structural properties of KGs and the performance of the
PLM-based methods. To leverage the structural knowledge, we propose a
Subgraph-Aware Training framework for KGC (SATKGC) that combines (i)
subgraph-aware mini-batching to encourage hard negative sampling, and (ii) a
new contrastive learning method to focus more on harder entities and harder
negative triples in terms of the structural properties. To the best of our
knowledge, this is the first study to comprehensively incorporate the
structural inductive bias of the subgraphs into fine-tuning PLMs. Extensive
experiments on four KGC benchmarks demonstrate the superiority of SATKGC. Our
code is available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, including appendix with 8 figures and 12 tables, currently
  under open review for EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Patch-Level Training for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12665v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12665v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenze Shao, Fandong Meng, Jie Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As Large Language Models (LLMs) achieve remarkable progress in language
understanding and generation, their training efficiency has become a critical
concern. Traditionally, LLMs are trained to predict the next token in a
sequence. Despite the success of token-level training, it suffers from
considerable computational costs due to the need to process an extensive number
of tokens. To mitigate this issue, this paper introduces patch-level training
for LLMs, which reduces the sequence length by compressing multiple tokens into
a single patch. During patch-level training, we feed the language model shorter
sequences of patches and train it to predict the next patch, thereby processing
the majority of the training data at a significantly reduced computational
cost. Following this, the model continues token-level training on the remaining
training data to align with the inference mode. Experiments on a diverse range
of models (370M-2.7B parameters) demonstrate that patch-level training can
reduce overall computational costs to 0.5$\times$, without compromising the
model performance compared to token-level training. Source code:
\url{https://github.com/shaochenze/PatchTrain}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Domain-specific or Uncertainty-aware models: Does it really make a
  difference for biomedical text classification? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12626v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12626v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aman Sinha, Timothee Mickus, Marianne Clausel, Mathieu Constant, Xavier Coubez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The success of pretrained language models (PLMs) across a spate of use-cases
has led to significant investment from the NLP community towards building
domain-specific foundational models. On the other hand, in mission critical
settings such as biomedical applications, other aspects also factor in-chief of
which is a model's ability to produce reasonable estimates of its own
uncertainty. In the present study, we discuss these two desiderata through the
lens of how they shape the entropy of a model's output probability
distribution. We find that domain specificity and uncertainty awareness can
often be successfully combined, but the exact task at hand weighs in much more
strongly.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>BioNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Harnessing the Power of Artificial Intelligence to Vitalize Endangered
  Indigenous Languages: Technologies and Experiences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12620v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12620v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Claudio Pinhanez, Paulo Cavalin, Luciana Storto, Thomas Fimbow, Alexander Cobbinah, Julio Nogima, Marisa Vasconcelos, Pedro Domingues, Priscila de Souza Mizukami, Nicole Grell, Majoí Gongora, Isabel Gonçalves
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Since 2022 we have been exploring application areas and technologies in which
Artificial Intelligence (AI) and modern Natural Language Processing (NLP), such
as Large Language Models (LLMs), can be employed to foster the usage and
facilitate the documentation of Indigenous languages which are in danger of
disappearing. We start by discussing the decreasing diversity of languages in
the world and how working with Indigenous languages poses unique ethical
challenges for AI and NLP. To address those challenges, we propose an
alternative development AI cycle based on community engagement and usage. Then,
we report encouraging results in the development of high-quality machine
learning translators for Indigenous languages by fine-tuning state-of-the-art
(SOTA) translators with tiny amounts of data and discuss how to avoid some
common pitfalls in the process. We also present prototypes we have built in
projects done in 2023 and 2024 with Indigenous communities in Brazil, aimed at
facilitating writing, and discuss the development of Indigenous Language Models
(ILMs) as a replicable and scalable way to create spell-checkers, next-word
predictors, and similar tools. Finally, we discuss how we envision a future for
language documentation where dying languages are preserved as interactive
language models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AudienceView: AI-Assisted Interpretation of Audience Feedback in
  Journalism <span class="chip">SC</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12613v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12613v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        William Brannon, Doug Beeferman, Hang Jiang, Andrew Heyward, Deb Roy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding and making use of audience feedback is important but difficult
for journalists, who now face an impractically large volume of audience
comments online. We introduce AudienceView, an online tool to help journalists
categorize and interpret this feedback by leveraging large language models
(LLMs). AudienceView identifies themes and topics, connects them back to
specific comments, provides ways to visualize the sentiment and distribution of
the comments, and helps users develop ideas for subsequent reporting projects.
We consider how such tools can be useful in a journalist's workflow, and
emphasize the importance of contextual awareness and human judgment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CSCW Demo 2024. 5 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ E5-V: Universal Embeddings with Multimodal Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12580v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12580v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ting Jiang, Minghui Song, Zihan Zhang, Haizhen Huang, Weiwei Deng, Feng Sun, Qi Zhang, Deqing Wang, Fuzhen Zhuang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal large language models (MLLMs) have shown promising advancements in
general visual and language understanding. However, the representation of
multimodal information using MLLMs remains largely unexplored. In this work, we
introduce a new framework, E5-V, designed to adapt MLLMs for achieving
universal multimodal embeddings. Our findings highlight the significant
potential of MLLMs in representing multimodal inputs compared to previous
approaches. By leveraging MLLMs with prompts, E5-V effectively bridges the
modality gap between different types of inputs, demonstrating strong
performance in multimodal embeddings even without fine-tuning. We propose a
single modality training approach for E5-V, where the model is trained
exclusively on text pairs. This method demonstrates significant improvements
over traditional multimodal training on image-text pairs, while reducing
training costs by approximately 95%. Additionally, this approach eliminates the
need for costly multimodal training data collection. Extensive experiments
across four types of tasks demonstrate the effectiveness of E5-V. As a
universal multimodal model, E5-V not only achieves but often surpasses
state-of-the-art performance in each task, despite being trained on a single
modality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code and models are available at https://github.com/kongds/E5-V</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Abstraction Alignment: Comparing Model and Human Conceptual
  Relationships 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12543v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12543v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Angie Boggust, Hyemin Bang, Hendrik Strobelt, Arvind Satyanarayan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Abstraction -- the process of generalizing specific examples into broad
reusable patterns -- is central to how people efficiently process and store
information and apply their knowledge to new data. Promisingly, research has
shown that ML models learn representations that span levels of abstraction,
from specific concepts like "bolo tie" and "car tire" to more general concepts
like "CEO" and "model". However, existing techniques analyze these
representations in isolation, treating learned concepts as independent
artifacts rather than an interconnected web of abstraction. As a result,
although we can identify the concepts a model uses to produce its output, it is
difficult to assess if it has learned a human-aligned abstraction of the
concepts that will generalize to new data. To address this gap, we introduce
abstraction alignment, a methodology to measure the agreement between a model's
learned abstraction and the expected human abstraction. We quantify abstraction
alignment by comparing model outputs against a human abstraction graph, such as
linguistic relationships or medical disease hierarchies. In evaluation tasks
interpreting image models, benchmarking language models, and analyzing medical
datasets, abstraction alignment provides a deeper understanding of model
behavior and dataset content, differentiating errors based on their agreement
with human knowledge, expanding the verbosity of current model quality metrics,
and revealing ways to improve existing human abstractions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Collaborative Intelligence: Propagating Intentions and Reasoning
  for Multi-Agent Coordination with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12532v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12532v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xihe Qiu, Haoyu Wang, Xiaoyu Tan, Chao Qu, Yujie Xiong, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Effective collaboration in multi-agent systems requires communicating goals
and intentions between agents. Current agent frameworks often suffer from
dependencies on single-agent execution and lack robust inter-module
communication, frequently leading to suboptimal multi-agent reinforcement
learning (MARL) policies and inadequate task coordination. To address these
challenges, we present a framework for training large language models (LLMs) as
collaborative agents to enable coordinated behaviors in cooperative MARL. Each
agent maintains a private intention consisting of its current goal and
associated sub-tasks. Agents broadcast their intentions periodically, allowing
other agents to infer coordination tasks. A propagation network transforms
broadcast intentions into teammate-specific communication messages, sharing
relevant goals with designated teammates. The architecture of our framework is
structured into planning, grounding, and execution modules. During execution,
multiple agents interact in a downstream environment and communicate intentions
to enable coordinated behaviors. The grounding module dynamically adapts
comprehension strategies based on emerging coordination patterns, while
feedback from execution agents influnces the planning module, enabling the
dynamic re-planning of sub-tasks. Results in collaborative environment
simulation demonstrate intention propagation reduces miscoordination errors by
aligning sub-task dependencies between agents. Agents learn when to communicate
intentions and which teammates require task details, resulting in emergent
coordinated behaviors. This demonstrates the efficacy of intention sharing for
cooperative multi-agent RL based on LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Crafting the Path: Robust Query Rewriting for Information Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12529v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12529v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ingeol Baek, Jimin Lee, Joonho Yang, Hwanhee Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Query rewriting aims to generate a new query that can complement the original
query to improve the information retrieval system. Recent studies on query
rewriting, such as query2doc (Q2D), query2expand (Q2E) and querey2cot (Q2C),
rely on the internal knowledge of Large Language Models (LLMs) to generate a
relevant passage to add information to the query. Nevertheless, the efficacy of
these methodologies may markedly decline in instances where the requisite
knowledge is not encapsulated within the model's intrinsic parameters. In this
paper, we propose a novel structured query rewriting method called Crafting the
Path tailored for retrieval systems. Crafting the Path involves a three-step
process that crafts query-related information necessary for finding the
passages to be searched in each step. Specifically, the Crafting the Path
begins with Query Concept Comprehension, proceeds to Query Type Identification,
and finally conducts Expected Answer Extraction. Experimental results show that
our method outperforms previous rewriting methods, especially in less familiar
domains for LLMs. We demonstrate that our method is less dependent on the
internal parameter knowledge of the model and generates queries with fewer
factual inaccuracies. Furthermore, we observe that Crafting the Path has less
latency compared to the baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>1 figure, 12 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Struct-X: Enhancing Large Language Models Reasoning with Structured Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12522v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12522v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyu Tan, Haoyu Wang, Xihe Qiu, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Structured data, rich in logical and relational information, has the
potential to enhance the reasoning abilities of large language models (LLMs).
Still, its integration poses a challenge due to the risk of overwhelming LLMs
with excessive tokens and irrelevant context information. To address this, we
propose Struct-X, a novel framework that operates through five key phases:
``read-model-fill-reflect-reason'' efficiently enabling LLMs to utilize
structured data. It begins by encoding structured data into a topological space
using graph embeddings, followed by filling in missing entity information with
knowledge retrieval modules, and filtering out irrelevant tokens via a
self-supervised module. The final phase involves constructing a topological
network with selected tokens to further reduce the total token length for more
effective LLM inference. Additionally, Struct-X includes an Auxiliary Module
trained to generate prompts, aiding LLMs in analyzing structured data.
Extensive experiments on benchmarks, including the knowledge graph
question-answer task and the long document reading comprehension task, show
that Struct-X notably improves LLM reasoning, demonstrating the effectiveness
of structured data augmentation in improving LLM inference with complex input
context.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Initializing <span class="highlight-title">Transformer</span>s with <span class="highlight-title">Pre-train</span>ed Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12514v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12514v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ha Young Kim, Niranjan Balasubramanian, Byungkon Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  It has become common practice now to use random initialization schemes,
rather than the pre-trained embeddings, when training transformer based models
from scratch. Indeed, we find that pre-trained word embeddings from GloVe, and
some sub-word embeddings extracted from language models such as T5 and mT5 fare
much worse compared to random initialization. This is counter-intuitive given
the well-known representational and transfer-learning advantages of
pre-training. Interestingly, we also find that BERT and mBERT embeddings fare
better than random initialization, showing the advantages of pre-trained
representations. In this work, we posit two potential factors that contribute
to these mixed results: the model sensitivity to parameter distribution and the
embedding interactions with position encodings. We observe that pre-trained
GloVe, T5, and mT5 embeddings have a wider distribution of values. As argued in
the initialization studies, such large value initializations can lead to poor
training because of saturated outputs. Further, the larger embedding values
can, in effect, absorb the smaller position encoding values when added
together, thus losing position information. Standardizing the pre-trained
embeddings to a narrow range (e.g. as prescribed by Xavier) leads to
substantial gains for Glove, T5, and mT5 embeddings. On the other hand, BERT
pre-trained embeddings, while larger, are still relatively closer to Xavier
initialization range which may allow it to effectively transfer the pre-trained
knowledge.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ $\textit{GeoHard}$: Towards Measuring Class-wise Hardness through
  Modelling Class Semantics <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12512v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12512v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fengyu Cai, Xinran Zhao, Hongming Zhang, Iryna Gurevych, Heinz Koeppl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in measuring hardness-wise properties of data guide language
models in sample selection within low-resource scenarios. However,
class-specific properties are overlooked for task setup and learning. How will
these properties influence model learning and is it generalizable across
datasets? To answer this question, this work formally initiates the concept of
$\textit{class-wise hardness}$. Experiments across eight natural language
understanding (NLU) datasets demonstrate a consistent hardness distribution
across learning paradigms, models, and human judgment. Subsequent experiments
unveil a notable challenge in measuring such class-wise hardness with
instance-level metrics in previous works. To address this, we propose
$\textit{GeoHard}$ for class-wise hardness measurement by modeling class
geometry in the semantic embedding space. $\textit{GeoHard}$ surpasses
instance-level metrics by over 59 percent on $\textit{Pearson}$'s correlation
on measuring class-wise hardness. Our analysis theoretically and empirically
underscores the generality of $\textit{GeoHard}$ as a fresh perspective on data
diagnosis. Additionally, we showcase how understanding class-wise hardness can
practically aid in improving task learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Findings of ACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MERLIN: Multimodal Embedding Refinement via LLM-based Iterative
  Navigation for Text-Video Retrieval-Rerank Pipeline 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12508v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12508v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Donghoon Han, Eunhwan Park, Gisang Lee, Adam Lee, Nojun Kwak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid expansion of multimedia content has made accurately retrieving
relevant videos from large collections increasingly challenging. Recent
advancements in text-video retrieval have focused on cross-modal interactions,
large-scale foundation model training, and probabilistic modeling, yet often
neglect the crucial user perspective, leading to discrepancies between user
queries and the content retrieved. To address this, we introduce MERLIN
(Multimodal Embedding Refinement via LLM-based Iterative Navigation), a novel,
training-free pipeline that leverages Large Language Models (LLMs) for
iterative feedback learning. MERLIN refines query embeddings from a user
perspective, enhancing alignment between queries and video content through a
dynamic question answering process. Experimental results on datasets like
MSR-VTT, MSVD, and ActivityNet demonstrate that MERLIN substantially improves
Recall@1, outperforming existing systems and confirming the benefits of
integrating LLMs into multimodal retrieval systems for more responsive and
context-aware multimedia retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Case2Code: Learning Inductive Reasoning with Synthetic Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12504v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12504v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunfan Shao, Linyang Li, Yichuan Ma, Peiji Li, Demin Song, Qinyuan Cheng, Shimin Li, Xiaonan Li, Pengyu Wang, Qipeng Guo, Hang Yan, Xipeng Qiu, Xuanjing Huang, Dahua Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Complex reasoning is an impressive ability shown by large language models
(LLMs). Most LLMs are skilled in deductive reasoning, such as chain-of-thought
prompting or iterative tool-using to solve challenging tasks step-by-step. In
this paper, we hope to focus on evaluating and teaching LLMs to conduct
inductive reasoning, that is, LLMs are supposed to infer underlying rules by
observing examples or sequential transformations. However, collecting
large-scale and diverse human-generated inductive data is challenging. We focus
on data synthesis in the code domain and propose a \textbf{Case2Code} task by
exploiting the expressiveness and correctness of programs. Specifically, we
collect a diverse set of executable programs, synthesize input-output
transformations for each program, and force LLMs to infer the underlying code
implementations based on the synthetic I/O cases. We first evaluate
representative LLMs on the synthesized Case2Code task and demonstrate that the
Case-to-code induction is challenging for LLMs. Then, we synthesize large-scale
Case2Code training samples to train LLMs to perform inductive reasoning.
Experimental results show that such induction training benefits not only in
distribution Case2Code performance but also enhances various coding abilities
of trained LLMs, demonstrating the great potential of learning inductive
reasoning via synthetic data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automate or Assist? The Role of Computational Models in Identifying
  Gendered Discourse in US Capital Trial Transcripts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12500v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12500v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrea W Wen-Yi, Kathryn Adamson, Nathalie Greenfield, Rachel Goldberg, Sandra Babcock, David Mimno, Allison Koenecke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The language used by US courtroom actors in criminal trials has long been
studied for biases. However, systematic studies for bias in high-stakes court
trials have been difficult, due to the nuanced nature of bias and the legal
expertise required. New large language models offer the possibility to automate
annotation, saving time and cost. But validating these approaches requires both
high quantitative performance as well as an understanding of how automated
methods fit in existing workflows, and what they really offer. In this paper we
present a case study of adding an automated system to a complex and high-stakes
problem: identifying gender-biased language in US capital trials for women
defendants. Our team of experienced death-penalty lawyers and NLP technologists
pursued a three-phase study: first annotating manually, then training and
evaluating computational models, and finally comparing human annotations to
model predictions. Unlike many typical NLP tasks, annotating for gender bias in
months-long capital trials was a complicated task that involves with many
individual judgment calls. In contrast to standard arguments for automation
that are based on efficiency and scalability, legal experts found the
computational models most useful in challenging their personal bias in
annotation and providing opportunities to refine and build consensus on rules
for annotation. This suggests that seeking to replace experts with
computational models is both unrealistic and undesirable. Rather, computational
models offer valuable opportunities to assist the legal experts in
annotation-based studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Linguistic Capabilities of Multimodal LLMs in the Lens of
  Few-Shot Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12498v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12498v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mustafa Dogan, Ilker Kesen, Iacer Calixto, Aykut Erdem, Erkut Erdem
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The linguistic capabilities of Multimodal Large Language Models (MLLMs) are
critical for their effective application across diverse tasks. This study aims
to evaluate the performance of MLLMs on the VALSE benchmark, focusing on the
efficacy of few-shot In-Context Learning (ICL), and Chain-of-Thought (CoT)
prompting. We conducted a comprehensive assessment of state-of-the-art MLLMs,
varying in model size and pretraining datasets. The experimental results reveal
that ICL and CoT prompting significantly boost model performance, particularly
in tasks requiring complex reasoning and contextual understanding. Models
pretrained on captioning datasets show superior zero-shot performance, while
those trained on interleaved image-text data benefit from few-shot learning.
Our findings provide valuable insights into optimizing MLLMs for better
grounding of language in visual contexts, highlighting the importance of the
composition of pretraining data and the potential of few-shot learning
strategies to improve the reasoning abilities of MLLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. 33 pages, 17 Figures, 3 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Pretrain</span>ing Data and Tokenizer for Indic LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12481v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12481v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rahul Kumar, Shubham Kakde, Divyansh Rajput, Daud Ibrahim, Rishabh Nahata, Pidathala Sowjanya, Deepak Kumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel approach to data preparation for developing multilingual
Indic large language model. Our meticulous data acquisition spans open-source
and proprietary sources, including Common Crawl, Indic books, news articles,
and Wikipedia, ensuring a diverse and rich linguistic representation. For each
Indic language, we design a custom preprocessing pipeline to effectively
eliminate redundant and low-quality text content. Additionally, we perform
deduplication on Common Crawl data to address the redundancy present in 70% of
the crawled web pages. This study focuses on developing high-quality data,
optimizing tokenization for our multilingual dataset for Indic large language
models with 3B and 7B parameters, engineered for superior performance in Indic
languages. We introduce a novel multilingual tokenizer training strategy,
demonstrating our custom-trained Indic tokenizer outperforms the
state-of-the-art OpenAI Tiktoken tokenizer, achieving a superior token-to-word
ratio for Indic languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Linear Representation Hypothesis and the Geometry of Large Language
  Models <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.03658v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.03658v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kiho Park, Yo Joong Choe, Victor Veitch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Informally, the 'linear representation hypothesis' is the idea that
high-level concepts are represented linearly as directions in some
representation space. In this paper, we address two closely related questions:
What does "linear representation" actually mean? And, how do we make sense of
geometric notions (e.g., cosine similarity or projection) in the representation
space? To answer these, we use the language of counterfactuals to give two
formalizations of "linear representation", one in the output (word)
representation space, and one in the input (sentence) space. We then prove
these connect to linear probing and model steering, respectively. To make sense
of geometric notions, we use the formalization to identify a particular
(non-Euclidean) inner product that respects language structure in a sense we
make precise. Using this causal inner product, we show how to unify all notions
of linear representation. In particular, this allows the construction of probes
and steering vectors using counterfactual pairs. Experiments with LLaMA-2
demonstrate the existence of linear representations of concepts, the connection
to interpretation and control, and the fundamental role of the choice of inner
product.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for a presentation at ICML 2024 and an oral presentation at
  NeurIPS 2023 Workshop on Causal Representation Learning. Code is available at
  https://github.com/KihoPark/linear_rep_geometry</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unconstrained Open Vocabulary Image Classification: Zero-Shot Transfer
  from Text to Image via CLIP Inversion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11211v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11211v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Philipp Allgeuer, Kyra Ahrens, Stefan Wermter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce NOVIC, an innovative uNconstrained Open Vocabulary Image
Classifier that uses an autoregressive transformer to generatively output
classification labels as language. Leveraging the extensive knowledge of CLIP
models, NOVIC harnesses the embedding space to enable zero-shot transfer from
pure text to images. Traditional CLIP models, despite their ability for open
vocabulary classification, require an exhaustive prompt of potential class
labels, restricting their application to images of known content or context. To
address this, we propose an "object decoder" model that is trained on a
large-scale 92M-target dataset of templated object noun sets and LLM-generated
captions to always output the object noun in question. This effectively inverts
the CLIP text encoder and allows textual object labels to be generated directly
from image-derived embedding vectors, without requiring any a priori knowledge
of the potential content of an image. The trained decoders are tested on a mix
of manually and web-curated datasets, as well as standard image classification
benchmarks, and achieve fine-grained prompt-free prediction scores of up to
87.5%, a strong result considering the model must work for any conceivable
image and without any contextual clues.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Language models show human-like content effects on reasoning tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2207.07051v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2207.07051v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ishita Dasgupta, Andrew K. Lampinen, Stephanie C. Y. Chan, Hannah R. Sheahan, Antonia Creswell, Dharshan Kumaran, James L. McClelland, Felix Hill
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reasoning is a key ability for an intelligent system. Large language models
(LMs) achieve above-chance performance on abstract reasoning tasks, but exhibit
many imperfections. However, human abstract reasoning is also imperfect. For
example, human reasoning is affected by our real-world knowledge and beliefs,
and shows notable "content effects"; humans reason more reliably when the
semantic content of a problem supports the correct logical inferences. These
content-entangled reasoning patterns play a central role in debates about the
fundamental nature of human intelligence. Here, we investigate whether language
models $\unicode{x2014}$ whose prior expectations capture some aspects of human
knowledge $\unicode{x2014}$ similarly mix content into their answers to logical
problems. We explored this question across three logical reasoning tasks:
natural language inference, judging the logical validity of syllogisms, and the
Wason selection task. We evaluate state of the art large language models, as
well as humans, and find that the language models reflect many of the same
patterns observed in humans across these tasks $\unicode{x2014}$ like humans,
models answer more accurately when the semantic content of a task supports the
logical inferences. These parallels are reflected both in answer patterns, and
in lower-level features like the relationship between model answer
distributions and human response times. Our findings have implications for
understanding both these cognitive effects in humans, and the factors that
contribute to language model performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published version of record:
  https://academic.oup.com/pnasnexus/article/3/7/pgae233/7712372</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sparse-IFT: Sparse Iso-FLOP Transformations for Maximizing Training
  Efficiency <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.11525v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.11525v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vithursan Thangarasa, Shreyas Saxena, Abhay Gupta, Sean Lie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent research has focused on weight sparsity in deep neural network
training to reduce FLOPs, aiming for improved efficiency (test accuracy w.r.t
training FLOPs). However, sparse weight training often compromises accuracy,
requiring extended training schedules to attain the accuracy of dense models.
In contrast, our approach, Sparse Iso-FLOP Transformations (Sparse-IFT), uses
sparsity to improve accuracy while maintaining dense model FLOPs. Using a
single hyperparameter (i.e., the sparsity level), Sparse-IFTs efficiently
replace dense layers, expanding the search space for optimal sparse masks. In
addition, dynamic sparse training (DST) with Sparse-IFT models effectively
navigate this larger sparse mask-weight space, which is evidenced by a spectral
analysis using Ramanujan graph properties. Our study reveals a robust
correlation among mask topology, weights, and final performance. Notably,
without adjusting any training hyperparameters, replacing dense layers with
Sparse-IFT yields significant improvements, such as a +3.5% boost for ResNet-18
on ImageNet and +0.9% for GPT-3 Small on the Open LLM leaderboard. To the best
of our knowledge, this is the first work to demonstrate the use of sparsity for
improving the accuracy of dense models through a set of simple-to-use sparse
transformations. Code is available at:
https://github.com/CerebrasResearch/Sparse-IFT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 5 figures, 6 Tables (Main Paper) + 8 pages (Supplementary
  Material). Published at ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards continually learning new languages 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2211.11703v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2211.11703v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ngoc-Quan Pham, Jan Niehues, Alexander Waibel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multilingual speech recognition with neural networks is often implemented
with batch-learning, when all of the languages are available before training.
An ability to add new languages after the prior training sessions can be
economically beneficial, but the main challenge is catastrophic forgetting. In
this work, we combine the qualities of weight factorization and elastic weight
consolidation in order to counter catastrophic forgetting and facilitate
learning new languages quickly. Such combination allowed us to eliminate
catastrophic forgetting while still achieving performance for the new languages
comparable with having all languages at once, in experiments of learning from
an initial 10 languages to achieve 26 languages without catastrophic forgetting
and a reasonable performance compared to training all languages from scratch.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ QuRating: Selecting High-Quality Data for Training Language Models <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.09739v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.09739v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Wettig, Aatmik Gupta, Saumya Malik, Danqi Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Selecting high-quality pre-training data is important for creating capable
language models, but existing methods rely on simple heuristics. We introduce
QuRating, a method for selecting pre-training data that can capture human
intuitions about data quality. In this paper, we investigate four qualities -
writing style, required expertise, facts & trivia, and educational value - and
find that LLMs are able to discern these qualities, especially when making
pairwise judgments of texts. We train a QuRater model to learn scalar ratings
from pairwise judgments, and use it to annotate a 260B training corpus with
quality ratings for each of the four criteria. In our experiments, we select
30B tokens according to the different quality ratings and train 1.3B-parameter
language models on the selected data. We find that it is important to balance
quality and diversity. When we sample using quality ratings as logits over
documents, our models obtain lower perplexity and stronger in-context learning
performance than baselines. Our best model is based on educational value and
performs similarly to a model trained with uniform sampling for 50% more steps.
Beyond data selection, we use the quality ratings to construct a training
curriculum which improves performance without changing the training dataset. We
extensively analyze the quality ratings and discuss their characteristics,
biases, and wider implications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICML 2024. The results for top-k selection have been
  corrected. The code, models and data are available at
  https://github.com/princeton-nlp/QuRating</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SambaLingo: Teaching Large Language Models New Languages 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.05829v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.05829v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zoltan Csaki, Bo Li, Jonathan Li, Qiantong Xu, Pian Pawakapan, Leon Zhang, Yun Du, Hengyu Zhao, Changran Hu, Urmish Thakker
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the widespread availability of LLMs, there remains a substantial gap
in their capabilities and availability across diverse languages. One approach
to address these issues has been to take an existing pre-trained LLM and
continue to train it on new languages. While prior works have experimented with
language adaptation, many questions around best practices and methodology have
not been covered. In this paper, we present a comprehensive investigation into
the adaptation of LLMs to new languages. Our study covers the key components in
this process, including vocabulary extension, direct preference optimization
and the data scarcity problem for human alignment in low-resource languages. We
scale these experiments across 9 languages and 2 parameter scales (7B and 70B).
We compare our models against Llama 2, Aya-101, XGLM, BLOOM and existing
language experts, outperforming all prior published baselines. Additionally,
all evaluation code and checkpoints are made public to facilitate future
research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Task Decomposition to Assist Humans in Competitive Programming <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04604v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04604v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaxin Wen, Ruiqi Zhong, Pei Ke, Zhihong Shao, Hongning Wang, Minlie Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When using language models (LMs) to solve complex problems, humans might
struggle to understand the LM-generated solutions and repair the flawed ones.
To assist humans in repairing them, we propose to automatically decompose
complex solutions into multiple simpler pieces that correspond to specific
subtasks. We introduce a novel objective for learning task decomposition,
termed assistive value (AssistV), which measures the feasibility and speed for
humans to repair the decomposed solution. We collect a dataset of human repair
experiences on different decomposed solutions. Utilizing the collected data as
in-context examples, we then learn to critique, refine, and rank decomposed
solutions to improve AssistV. We validate our method under competitive
programming problems: under 177 hours of human study, our method enables
non-experts to solve 33.3\% more problems, speeds them up by 3.3x, and empowers
them to match unassisted experts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FarsInstruct: Empowering Large Language Models for Persian Instruction
  Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11186v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11186v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hojjat Mokhtarabadi, Ziba Zamani, Abbas Maazallahi, Hossein Manshaei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction-tuned large language models, such as T0, have demonstrated
remarkable capabilities in following instructions across various domains.
However, their proficiency remains notably deficient in many low-resource
languages. To address this challenge, we introduce FarsInstruct: a
comprehensive instruction dataset designed to enhance the instruction-following
ability of large language models specifically for the Persian language, a
significant yet underrepresented language globally. FarsInstruct encompasses a
wide range of task types and datasets, each containing a mix of straightforward
to complex manual written instructions, as well as translations from Public
Pool of Prompts, ensuring a rich linguistic and cultural representation.
Furthermore, we introduce Co-CoLA, a framework designed to enhance the
multi-task adaptability of LoRA-tuned models. Through extensive experimental
analyses, our study showcases the effectiveness of FarsInstruct dataset coupled
with training by Co-CoLA framework, in improving the performance of large
language models within the Persian context. As of the current writing,
FarsInstruct comprises more than 200 templates across 21 distinct datasets, and
we intend to update it consistently, thus augmenting its applicability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Future Events as Backdoor Triggers: Investigating Temporal
  Vulnerabilities in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.04108v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.04108v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sara Price, Arjun Panickssery, Sam Bowman, Asa Cooper Stickland
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Backdoors are hidden behaviors that are only triggered once an AI system has
been deployed. Bad actors looking to create successful backdoors must design
them to avoid activation during training and evaluation. Since data used in
these stages often only contains information about events that have already
occurred, a component of a simple backdoor trigger could be a model recognizing
data that is in the future relative to when it was trained. Through prompting
experiments and by probing internal activations, we show that current large
language models (LLMs) can distinguish past from future events, with probes on
model activations achieving 90% accuracy. We train models with backdoors
triggered by a temporal distributional shift; they activate when the model is
exposed to news headlines beyond their training cut-off dates. Fine-tuning on
helpful, harmless and honest (HHH) data does not work well for removing simpler
backdoor triggers but is effective on our backdoored models, although this
distinction is smaller for the larger-scale model we tested. We also find that
an activation-steering vector representing a model's internal representation of
the date influences the rate of backdoor activation. We take these results as
initial evidence that, at least for models at the modest scale we test,
standard safety measures are enough to remove these backdoors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Breaking Boundaries: Investigating the Effects of Model Editing on
  Cross-linguistic Performance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11139v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11139v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Somnath Banerjee, Avik Halder, Rajarshi Mandal, Sayan Layek, Ian Soboroff, Rima Hazra, Animesh Mukherjee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of pretrained language models (PLMs) like BERT and GPT has
revolutionized NLP, particularly for English, but it has also created
linguistic imbalances. This paper strategically identifies the need for
linguistic equity by examining several knowledge editing techniques in
multilingual contexts. We evaluate the performance of models such as Mistral,
TowerInstruct, OpenHathi, Tamil-Llama, and Kan-Llama across languages including
English, German, French, Italian, Spanish, Hindi, Tamil, and Kannada. Our
research identifies significant discrepancies in normal and merged models
concerning cross-lingual consistency. We employ strategies like 'each language
for itself' (ELFI) and 'each language for others' (ELFO) to stress-test these
models. Our findings demonstrate the potential for LLMs to overcome linguistic
barriers, laying the groundwork for future research in achieving linguistic
inclusivity in AI technologies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PrE-Text: Training Language Models on Private Federated Data in the Age
  of LLMs <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.02958v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.02958v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Charlie Hou, Akshat Shrivastava, Hongyuan Zhan, Rylan Conway, Trang Le, Adithya Sagar, Giulia Fanti, Daniel Lazar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  On-device training is currently the most common approach for training machine
learning (ML) models on private, distributed user data. Despite this, on-device
training has several drawbacks: (1) most user devices are too small to train
large models on-device, (2) on-device training is communication- and
computation-intensive, and (3) on-device training can be difficult to debug and
deploy. To address these problems, we propose Private Evolution-Text
(PrE-Text), a method for generating differentially private (DP) synthetic
textual data. First, we show that across multiple datasets, training small
models (models that fit on user devices) with PrE-Text synthetic data
outperforms small models trained on-device under practical privacy regimes
($\epsilon=1.29$, $\epsilon=7.58$). We achieve these results while using
9$\times$ fewer rounds, 6$\times$ less client computation per round, and
100$\times$ less communication per round. Second, finetuning large models on
PrE-Text's DP synthetic data improves large language model (LLM) performance on
private data across the same range of privacy budgets. Altogether, these
results suggest that training on DP synthetic data can be a better option than
training a model on-device on private distributed data. Code is available at
https://github.com/houcharlie/PrE-Text.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024 (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Can You Learn Semantics Through Next-Word Prediction? The Case of
  Entailment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.13956v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.13956v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        William Merrill, Zhaofeng Wu, Norihito Naka, Yoon Kim, Tal Linzen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Do LMs infer the semantics of text from co-occurrence patterns in their
training data? Merrill et al. (2022) argue that, in theory, sentence
co-occurrence probabilities predicted by an optimal LM should reflect the
entailment relationship of the constituent sentences, but it is unclear whether
probabilities predicted by neural LMs encode entailment in this way because of
strong assumptions made by Merrill et al. (namely, that humans always avoid
redundancy). In this work, we investigate whether their theory can be used to
decode entailment relations from neural LMs. We find that a test similar to
theirs can decode entailment relations between natural sentences, well above
random chance, though not perfectly, across many datasets and LMs. This
suggests LMs implicitly model aspects of semantics to predict semantic effects
on sentence co-occurrence patterns. However, we find the test that predicts
entailment in practice works in the opposite direction to the theoretical test.
We thus revisit the assumptions underlying the original test, finding its
derivation did not adequately account for redundancy in human-written text. We
argue that better accounting for redundancy related to explanations might
derive the observed flipped test and, more generally, improve computational
models of speakers in linguistics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the Effect of (Near) Duplicate Subwords in Language Modelling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.06508v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.06508v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anton Schäfer, Thomas Hofmann, Imanol Schlag, Tiago Pimentel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tokenisation is a core part of language models (LMs). It involves splitting a
character sequence into subwords which are assigned arbitrary indices before
being served to the LM. While typically lossless, however, this process may
lead to less sample efficient LM training: as it removes character-level
information, it could make it harder for LMs to generalise across similar
subwords, such as now and Now. We refer to such subwords as near duplicates. In
this paper, we study the impact of near duplicate subwords on LM training
efficiency. First, we design an experiment that gives us an upper bound to how
much we should expect a model to improve if we could perfectly generalise
across near duplicates. We do this by duplicating each subword in our LM's
vocabulary, creating perfectly equivalent classes of subwords. Experimentally,
we find that LMs need roughly 17% more data when trained in a fully duplicated
setting. Second, we investigate the impact of naturally occurring near
duplicates on LMs. Here, we see that merging them considerably hurts LM
performance. Therefore, although subword duplication negatively impacts LM
training efficiency, naturally occurring near duplicates may not be as similar
as anticipated, limiting the potential for performance improvements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Role of Language Imbalance in Cross-lingual Generalisation: Insights
  from Cloned Language Experiments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.07982v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.07982v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anton Schäfer, Shauli Ravfogel, Thomas Hofmann, Tiago Pimentel, Imanol Schlag
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multilinguality is crucial for extending recent advancements in language
modelling to diverse linguistic communities. To maintain high performance while
representing multiple languages, multilingual models ideally align
representations, allowing what is learned in one language to generalise to
others. Prior research has emphasised the importance of parallel data and
shared vocabulary elements as key factors for such alignment. In this study, we
investigate an unintuitive novel driver of cross-lingual generalisation:
language imbalance. In controlled experiments on perfectly equivalent cloned
languages, we observe that the existence of a predominant language during
training boosts the performance of less frequent languages and leads to
stronger alignment of model representations across languages. Furthermore, we
find that this trend is amplified with scale: with large enough models or long
enough training, we observe that bilingual training data with a 90/10 language
split yields better performance on both languages than a balanced 50/50 split.
Building on these insights, we design training schemes that can improve
performance in all cloned languages, even without altering the training data.
As we extend our analysis to real languages, we find that infrequent languages
still benefit from frequent ones, yet whether language imbalance causes
cross-lingual generalisation there is not conclusive.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CIC-BART-SSA: Controllable Image Captioning with Structured Semantic
  Augmentation <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11393v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11393v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kalliopi Basioti, Mohamed A. Abdelsalam, Federico Fancellu, Vladimir Pavlovic, Afsaneh Fazly
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controllable Image Captioning (CIC) aims at generating natural language
descriptions for an image, conditioned on information provided by end users,
e.g., regions, entities or events of interest. However, available
image-language datasets mainly contain captions that describe the entirety of
an image, making them ineffective for training CIC models that can potentially
attend to any subset of regions or relationships. To tackle this challenge, we
propose a novel, fully automatic method to sample additional focused and
visually grounded captions using a unified structured semantic representation
built on top of the existing set of captions associated with an image. We
leverage Abstract Meaning Representation (AMR), a cross-lingual graph-based
semantic formalism, to encode all possible spatio-semantic relations between
entities, beyond the typical spatial-relations-only focus of current methods.
We use this Structured Semantic Augmentation (SSA) framework to augment
existing image-caption datasets with the grounded controlled captions,
increasing their spatial and semantic diversity and focal coverage. We then
develop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that
sources its control signals from SSA-diversified datasets. We empirically show
that, compared to SOTA CIC models, CIC-BART-SSA generates captions that are
superior in diversity and text quality, are competitive in controllability,
and, importantly, minimize the gap between broad and highly focused controlled
captioning performance by efficiently generalizing to the challenging highly
focused scenarios. Code is available at
https://github.com/SamsungLabs/CIC-BART-SSA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large
  Language Models -- The Story Goes On 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.08348v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.08348v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liang Zeng, Liangjun Zhong, Liang Zhao, Tianwen Wei, Liu Yang, Jujie He, Cheng Cheng, Rui Hu, Yang Liu, Shuicheng Yan, Han Fang, Yahui Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we investigate the underlying factors that potentially enhance
the mathematical reasoning capabilities of large language models (LLMs). We
argue that the data scaling law for math reasoning capabilities in modern LLMs
is far from being saturated, highlighting how the model's quality improves with
increases in data quantity. To support this claim, we introduce the
Skywork-Math model series, supervised fine-tuned (SFT) on common 7B LLMs using
our proposed 2.5M-instance Skywork-MathQA dataset. Skywork-Math 7B has achieved
impressive accuracies of 51.2% on the competition-level MATH benchmark and
83.9% on the GSM8K benchmark using only SFT data, outperforming an early
version of GPT-4 on MATH. The superior performance of Skywork-Math models
contributes to our novel two-stage data synthesis and model SFT pipelines,
which include three different augmentation methods and a diverse seed problem
set, ensuring both the quantity and quality of Skywork-MathQA dataset across
varying difficulty levels. Most importantly, we provide several practical
takeaways to enhance math reasoning abilities in LLMs for both research and
industry applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tango 2: Aligning Diffusion-based Text-to-Audio Generations through
  Direct Preference Optimization <span class="chip">ACM MM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.09956v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.09956v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Navonil Majumder, Chia-Yu Hung, Deepanway Ghosal, Wei-Ning Hsu, Rada Mihalcea, Soujanya Poria
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative multimodal content is increasingly prevalent in much of the
content creation arena, as it has the potential to allow artists and media
personnel to create pre-production mockups by quickly bringing their ideas to
life. The generation of audio from text prompts is an important aspect of such
processes in the music and film industry. Many of the recent diffusion-based
text-to-audio models focus on training increasingly sophisticated diffusion
models on a large set of datasets of prompt-audio pairs. These models do not
explicitly focus on the presence of concepts or events and their temporal
ordering in the output audio with respect to the input prompt. Our hypothesis
is focusing on how these aspects of audio generation could improve audio
generation performance in the presence of limited data. As such, in this work,
using an existing text-to-audio model Tango, we synthetically create a
preference dataset where each prompt has a winner audio output and some loser
audio outputs for the diffusion model to learn from. The loser outputs, in
theory, have some concepts from the prompt missing or in an incorrect order. We
fine-tune the publicly available Tango text-to-audio model using diffusion-DPO
(direct preference optimization) loss on our preference dataset and show that
it leads to improved audio output over Tango and AudioLDM2, in terms of both
automatic- and manual-evaluation metrics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ACM MM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Muting Whisper: A Universal Acoustic Adversarial Attack on Speech
  Foundation Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.06134v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.06134v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vyas Raina, Rao Ma, Charles McGhee, Kate Knill, Mark Gales
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent developments in large speech foundation models like Whisper have led
to their widespread use in many automatic speech recognition (ASR)
applications. These systems incorporate `special tokens' in their vocabulary,
such as $\texttt{<|endoftext|>}$, to guide their language generation process.
However, we demonstrate that these tokens can be exploited by adversarial
attacks to manipulate the model's behavior. We propose a simple yet effective
method to learn a universal acoustic realization of Whisper's
$\texttt{<|endoftext|>}$ token, which, when prepended to any speech signal,
encourages the model to ignore the speech and only transcribe the special
token, effectively `muting' the model. Our experiments demonstrate that the
same, universal 0.64-second adversarial audio segment can successfully mute a
target Whisper ASR model for over 97\% of speech samples. Moreover, we find
that this universal adversarial audio segment often transfers to new datasets
and tasks. Overall this work demonstrates the vulnerability of Whisper models
to `muting' adversarial attacks, where such attacks can pose both risks and
potential benefits in real-world settings: for example the attack can be used
to bypass speech moderation systems, or conversely the attack can also be used
to protect private speech data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ To Believe or Not to Believe Your LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.02543v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.02543v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yasin Abbasi Yadkori, Ilja Kuzborskij, András György, Csaba Szepesvári
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We explore uncertainty quantification in large language models (LLMs), with
the goal to identify when uncertainty in responses given a query is large. We
simultaneously consider both epistemic and aleatoric uncertainties, where the
former comes from the lack of knowledge about the ground truth (such as about
facts or the language), and the latter comes from irreducible randomness (such
as multiple possible answers). In particular, we derive an
information-theoretic metric that allows to reliably detect when only epistemic
uncertainty is large, in which case the output of the model is unreliable. This
condition can be computed based solely on the output of the model obtained
simply by some special iterative prompting based on the previous responses.
Such quantification, for instance, allows to detect hallucinations (cases when
epistemic uncertainty is high) in both single- and multi-answer responses. This
is in contrast to many standard uncertainty quantification strategies (such as
thresholding the log-likelihood of a response) where hallucinations in the
multi-answer case cannot be detected. We conduct a series of experiments which
demonstrate the advantage of our formulation. Further, our investigations shed
some light on how the probabilities assigned to a given output by an LLM can be
amplified by iterative prompting, which might be of independent interest.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ In-Context Symbolic Regression: Leveraging Large Language Models for
  Function Discovery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.19094v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.19094v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matteo Merler, Katsiaryna Haitsiukevich, Nicola Dainese, Pekka Marttinen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State of the art Symbolic Regression (SR) methods currently build specialized
models, while the application of Large Language Models (LLMs) remains largely
unexplored. In this work, we introduce the first comprehensive framework that
utilizes LLMs for the task of SR. We propose In-Context Symbolic Regression
(ICSR), an SR method which iteratively refines a functional form with an LLM
and determines its coefficients with an external optimizer. ICSR leverages
LLMs' strong mathematical prior both to propose an initial set of possible
functions given the observations and to refine them based on their errors. Our
findings reveal that LLMs are able to successfully find symbolic equations that
fit the given data, matching or outperforming the overall performance of the
best SR baselines on four popular benchmarks, while yielding simpler equations
with better out of distribution generalization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MuggleMath: Assessing the Impact of Query and Response Augmentation on
  Math Reasoning <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.05506v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.05506v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengpeng Li, Zheng Yuan, Hongyi Yuan, Guanting Dong, Keming Lu, Jiancan Wu, Chuanqi Tan, Xiang Wang, Chang Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In math reasoning with large language models (LLMs), fine-tuning data
augmentation by query evolution and diverse reasoning paths is empirically
verified effective, profoundly narrowing the gap between open-sourced LLMs and
cutting-edge proprietary LLMs. In this paper, we conduct an investigation for
such data augmentation in math reasoning and are intended to answer: (1) What
strategies of data augmentation are more effective; (2) What is the scaling
relationship between the amount of augmented data and model performance; and
(3) Can data augmentation incentivize generalization to out-of-domain
mathematical reasoning tasks? To this end, we create two new dataset AugGSM8K
and AugMATH, by complicating and diversifying the queries and sampling multiple
reasoning paths from GSM8K and MATH. We obtained a series of LLMs called
MuggleMath by fine-tuning LLaMA models on AugGSM8K and AugMATH. MuggleMath
substantially achieves new state-of-the-art on GSM8K and MATH. A log-linear
relationship and a segmented log-linear are presented between MuggleMath's
performance and the amount of augmented data on GSM8K and MATH, respectively.
We also find that it is weak in out-of-domain math reasoning generalization
from AugGSM8K to MATH and from AugMATH to GSM8K, which suggests that augmenting
queries that cover a broader range of subjects is more beneficial for
generalization. We release our codes and augmented data in
https://github.com/OFA-Sys/gsm8k-ScRel.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACL 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AnglE-optimized Text Embeddings <span class="chip">ACL24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.12871v8">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.12871v8.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xianming Li, Jing Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-quality text embedding is pivotal in improving semantic textual
similarity (STS) tasks, which are crucial components in Large Language Model
(LLM) applications. However, a common challenge existing text embedding models
face is the problem of vanishing gradients, primarily due to their reliance on
the cosine function in the optimization objective, which has saturation zones.
To address this issue, this paper proposes a novel angle-optimized text
embedding model called AnglE. The core idea of AnglE is to introduce angle
optimization in a complex space. This novel approach effectively mitigates the
adverse effects of the saturation zone in the cosine function, which can impede
gradient and hinder optimization processes. To set up a comprehensive STS
evaluation, we experimented on existing short-text STS datasets and a newly
collected long-text STS dataset from GitHub Issues. Furthermore, we examine
domain-specific STS scenarios with limited labeled data and explore how AnglE
works with LLM-annotated data. Extensive experiments were conducted on various
tasks including short-text STS, long-text STS, and domain-specific STS tasks.
The results show that AnglE outperforms the state-of-the-art (SOTA) STS models
that ignore the cosine saturation zone. These findings demonstrate the ability
of AnglE to generate high-quality text embeddings and the usefulness of angle
optimization in STS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACL24 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Think Big, Generate Quick: LLM-to-SLM for Fast Autoregressive Decoding <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.16844v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.16844v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benjamin Bergner, Andrii Skliar, Amelie Royer, Tijmen Blankevoort, Yuki Asano, Babak Ehteshami Bejnordi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have become ubiquitous in practice and are
widely used for generation tasks such as translation, summarization and
instruction following. However, their enormous size and reliance on
autoregressive decoding increase deployment costs and complicate their use in
latency-critical applications. In this work, we propose a hybrid approach that
combines language models of different sizes to increase the efficiency of
autoregressive decoding while maintaining high performance. Our method utilizes
a pretrained frozen LLM that encodes all prompt tokens once in parallel, and
uses the resulting representations to condition and guide a small language
model (SLM), which then generates the response more efficiently. We investigate
the combination of encoder-decoder LLMs with both encoder-decoder and
decoder-only SLMs from different model families and only require fine-tuning of
the SLM. Experiments with various benchmarks show substantial speedups of up to
$4\times$, with minor performance penalties of $1-2\%$ for translation and
summarization tasks compared to the LLM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work presented at the ES-FoMo II Workshop at ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Show, Don't Tell: Evaluating Large Language Models Beyond Textual
  Understanding with ChildPlay 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11068v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11068v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gonçalo Hora de Carvalho, Robert Pollice, Oscar Knap
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We explore the hypothesis that LLMs, such as GPT-3.5 and GPT-4, possess
broader cognitive functions, particularly in non-linguistic domains. Our
approach extends beyond standard linguistic benchmarks by incorporating games
like Tic-Tac-Toe, Connect Four, and Battleship, encoded via ASCII, to assess
strategic thinking and decision-making. To evaluate the models' ability to
generalize beyond their training data, we introduce two additional games. The
first game, LEGO Connect Language (LCL), tests the models' capacity to
understand spatial logic and follow assembly instructions. The second game, the
game of shapes, challenges the models to identify shapes represented by 1s
within a matrix of zeros, further testing their spatial reasoning skills. This
"show, don't tell" strategy uses games instead of simply querying the models.
Our results show that despite their proficiency on standard benchmarks, GPT-3.5
and GPT-4's abilities to play and reason about fully observable games without
pre-training is mediocre. Both models fail to anticipate losing moves in
Tic-Tac-Toe and Connect Four, and they are unable to play Battleship correctly.
While GPT-4 shows some success in the game of shapes, both models fail at the
assembly tasks presented in the LCL game. These results suggest that while GPT
models can emulate conversational proficiency and basic rule comprehension,
their performance in strategic gameplay and spatial reasoning tasks is very
limited. Importantly, this reveals a blind spot in current LLM benchmarks that
we highlight with our gameplay benchmark suite ChildPlay
(https://github.com/child-play-neurips/child-play). Our findings provide a
cautionary tale about claims of emergent intelligence and reasoning
capabilities of LLMs that are roughly the size of GPT-3.5 and GPT-4.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DotaMath: Decomposition of Thought with Code Assistance and
  Self-correction for Mathematical Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.04078v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.04078v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengpeng Li, Guanting Dong, Mingfeng Xue, Ru Peng, Xiang Wang, Dayiheng Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have made impressive progress in handling simple
math problems, yet they still struggle with more challenging and complex
mathematical tasks. In this paper, we introduce a series of LLMs that employs
the Decomposition of thought with code assistance and self-correction for
mathematical reasoning, dubbed as DotaMath. DotaMath models tackle complex
mathematical tasks by decomposing them into simpler logical subtasks,
leveraging code to solve these subtasks, obtaining fine-grained feedback from
the code interpreter, and engaging in self-reflection and correction. By
annotating diverse interactive tool-use trajectories and employing query
evolution on GSM8K and MATH datasets, we generate an instruction fine-tuning
dataset called DotaMathQA with 574K query-response pairs. We train a series of
base LLMs using imitation learning on DotaMathQA, resulting in DotaMath models
that achieve remarkable performance compared to open-source LLMs across various
in-domain and out-of-domain benchmarks. Notably, DotaMath-deepseek-7B showcases
an outstanding performance of 64.8% on the competitive MATH dataset and 86.7%
on GSM8K. Besides, DotaMath-deepseek-7B maintains strong competitiveness on a
series of in-domain and out-of-domain benchmarks (Avg. 80.1%). Looking forward,
we anticipate that the DotaMath paradigm will open new pathways for addressing
intricate mathematical problems. Our code is publicly available at
https://github.com/ChengpengLi1003/DotaMath.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Auto-Regressive Next-Token Predictors are Universal Learners 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.06979v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.06979v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eran Malach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models display remarkable capabilities in logical and
mathematical reasoning, allowing them to solve complex tasks. Interestingly,
these abilities emerge in networks trained on the simple task of next-token
prediction. In this work, we present a theoretical framework for studying
auto-regressive next-token predictors. We demonstrate that even simple models
such as linear next-token predictors, trained on Chain-of-Thought (CoT) data,
can approximate any function efficiently computed by a Turing machine. We
introduce a new complexity measure -- length complexity -- which measures the
number of intermediate tokens in a CoT sequence required to approximate some
target function, and analyze the interplay between length complexity and other
notions of complexity. Finally, we show experimentally that simple next-token
predictors, such as linear networks and shallow Multi-Layer Perceptrons (MLPs),
display non-trivial performance on text generation and arithmetic tasks. Our
results demonstrate that the power of today's LLMs can be attributed, to a
great extent, to the auto-regressive next-token training scheme, and not
necessarily to a particular choice of architecture.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Continuously Learning New Words in Automatic Speech Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.04482v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.04482v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christian Huber, Alexander Waibel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite recent advances, Automatic Speech Recognition (ASR) systems are still
far from perfect. Typical errors include acronyms, named entities and
domain-specific special words for which little or no data is available. To
address the problem of recognizing these words, we propose an self-supervised
continual learning approach. Given the audio of a lecture talk with
corresponding slides, we bias the model towards decoding new words from the
slides by using a memory-enhanced ASR model from previous work. Then, we
perform inference on the talk, collecting utterances that contain detected new
words into an adaptation dataset. Continual learning is then performed on this
set by adapting low-rank matrix weights added to each weight matrix of the
model. The whole procedure is iterated for many talks. We show that with this
approach, we obtain increasing performance on the new words when they occur
more frequently (more than 80% recall) while preserving the general performance
of the model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ End-to-End Evaluation for Low-Latency Simultaneous Speech Translation <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.03415v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.03415v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christian Huber, Tu Anh Dinh, Carlos Mullov, Ngoc Quan Pham, Thai Binh Nguyen, Fabian Retkowski, Stefan Constantin, Enes Yavuz Ugan, Danni Liu, Zhaolin Li, Sai Koneru, Jan Niehues, Alexander Waibel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The challenge of low-latency speech translation has recently draw significant
interest in the research community as shown by several publications and shared
tasks. Therefore, it is essential to evaluate these different approaches in
realistic scenarios. However, currently only specific aspects of the systems
are evaluated and often it is not possible to compare different approaches.
  In this work, we propose the first framework to perform and evaluate the
various aspects of low-latency speech translation under realistic conditions.
The evaluation is carried out in an end-to-end fashion. This includes the
segmentation of the audio as well as the run-time of the different components.
  Secondly, we compare different approaches to low-latency speech translation
using this framework. We evaluate models with the option to revise the output
as well as methods with fixed output. Furthermore, we directly compare
state-of-the-art cascaded as well as end-to-end systems. Finally, the framework
allows to automatically evaluate the translation quality as well as latency and
also provides a web interface to show the low-latency model outputs to the
user.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Demo paper at EMNLP 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mismatch Quest: Visual and Textual Feedback for Image-Text Misalignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.03766v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.03766v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brian Gordon, Yonatan Bitton, Yonatan Shafir, Roopal Garg, Xi Chen, Dani Lischinski, Daniel Cohen-Or, Idan Szpektor
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While existing image-text alignment models reach high quality binary
assessments, they fall short of pinpointing the exact source of misalignment.
In this paper, we present a method to provide detailed textual and visual
explanation of detected misalignments between text-image pairs. We leverage
large language models and visual grounding models to automatically construct a
training set that holds plausible misaligned captions for a given image and
corresponding textual explanations and visual indicators. We also publish a new
human curated test set comprising ground-truth textual and visual misalignment
annotations. Empirical results show that fine-tuning vision language models on
our training set enables them to articulate misalignments and visually indicate
them within images, outperforming strong baselines both on the binary alignment
classification and the explanation generation tasks. Our method code and human
curated test set are available at: https://mismatch-quest.github.io/
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">17</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retrieval-Enhanced Machine Learning: Synthesis and Opportunities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12982v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12982v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        To Eun Kim, Alireza Salemi, Andrew Drozdov, Fernando Diaz, Hamed Zamani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the field of language modeling, models augmented with retrieval components
have emerged as a promising solution to address several challenges faced in the
natural language processing (NLP) field, including knowledge grounding,
interpretability, and scalability. Despite the primary focus on NLP, we posit
that the paradigm of retrieval-enhancement can be extended to a broader
spectrum of machine learning (ML) such as computer vision, time series
prediction, and computational biology. Therefore, this work introduces a formal
framework of this paradigm, Retrieval-Enhanced Machine Learning (REML), by
synthesizing the literature in various domains in ML with consistent notations
which is missing from the current literature. Also, we found that while a
number of studies employ retrieval components to augment their models, there is
a lack of integration with foundational Information Retrieval (IR) research. We
bridge this gap between the seminal IR research and contemporary REML studies
by investigating each component that comprises the REML framework. Ultimately,
the goal of this work is to equip researchers across various disciplines with a
comprehensive, formally structured framework of retrieval-enhanced models,
thereby fostering interdisciplinary future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge
  Bases 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12784v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12784v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaorun Chen, Zhen Xiang, Chaowei Xiao, Dawn Song, Bo Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM agents have demonstrated remarkable performance across various
applications, primarily due to their advanced capabilities in reasoning,
utilizing external knowledge and tools, calling APIs, and executing actions to
interact with environments. Current agents typically utilize a memory module or
a retrieval-augmented generation (RAG) mechanism, retrieving past knowledge and
instances with similar embeddings from knowledge bases to inform task planning
and execution. However, the reliance on unverified knowledge bases raises
significant concerns about their safety and trustworthiness. To uncover such
vulnerabilities, we propose a novel red teaming approach AgentPoison, the first
backdoor attack targeting generic and RAG-based LLM agents by poisoning their
long-term memory or RAG knowledge base. In particular, we form the trigger
generation process as a constrained optimization to optimize backdoor triggers
by mapping the triggered instances to a unique embedding space, so as to ensure
that whenever a user instruction contains the optimized backdoor trigger, the
malicious demonstrations are retrieved from the poisoned memory or knowledge
base with high probability. In the meantime, benign instructions without the
trigger will still maintain normal performance. Unlike conventional backdoor
attacks, AgentPoison requires no additional model training or fine-tuning, and
the optimized backdoor trigger exhibits superior transferability, in-context
coherence, and stealthiness. Extensive experiments demonstrate AgentPoison's
effectiveness in attacking three types of real-world LLM agents: RAG-based
autonomous driving agent, knowledge-intensive QA agent, and healthcare
EHRAgent. On each agent, AgentPoison achieves an average attack success rate
higher than 80% with minimal impact on benign performance (less than 1%) with a
poison rate less than 0.1%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 13 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ E5-V: Universal Embeddings with Multimodal Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12580v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12580v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ting Jiang, Minghui Song, Zihan Zhang, Haizhen Huang, Weiwei Deng, Feng Sun, Qi Zhang, Deqing Wang, Fuzhen Zhuang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal large language models (MLLMs) have shown promising advancements in
general visual and language understanding. However, the representation of
multimodal information using MLLMs remains largely unexplored. In this work, we
introduce a new framework, E5-V, designed to adapt MLLMs for achieving
universal multimodal embeddings. Our findings highlight the significant
potential of MLLMs in representing multimodal inputs compared to previous
approaches. By leveraging MLLMs with prompts, E5-V effectively bridges the
modality gap between different types of inputs, demonstrating strong
performance in multimodal embeddings even without fine-tuning. We propose a
single modality training approach for E5-V, where the model is trained
exclusively on text pairs. This method demonstrates significant improvements
over traditional multimodal training on image-text pairs, while reducing
training costs by approximately 95%. Additionally, this approach eliminates the
need for costly multimodal training data collection. Extensive experiments
across four types of tasks demonstrate the effectiveness of E5-V. As a
universal multimodal model, E5-V not only achieves but often surpasses
state-of-the-art performance in each task, despite being trained on a single
modality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code and models are available at https://github.com/kongds/E5-V</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RankTower: A Synergistic Framework for Enhancing Two-Tower Pre-Ranking
  Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12385v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12385v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        YaChen Yan, Liubo Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In large-scale ranking systems, cascading architectures have been widely
adopted to achieve a balance between efficiency and effectiveness. The
pre-ranking module plays a vital role in selecting a subset of candidates for
the subsequent ranking module. It is crucial for the pre-ranking model to
maintain a balance between efficiency and accuracy to adhere to online latency
constraints. In this paper, we propose a novel neural network architecture
called RankTower, which is designed to efficiently capture user-item
interactions while following the user-item decoupling paradigm to ensure online
inference efficiency. The proposed approach employs a hybrid training objective
that learns from samples obtained from the full stage of the cascade ranking
system, optimizing different objectives for varying sample spaces. This
strategy aims to enhance the pre-ranking model's ranking capability and
improvement alignment with the existing cascade ranking system. Experimental
results conducted on public datasets demonstrate that RankTower significantly
outperforms state-of-the-art pre-ranking models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Graph Signal Processing for Cross-Domain Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12374v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12374v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jeongeun Lee, Seongku Kang, Won-Yong Shin, Jeongwhan Choi, Noseong Park, Dongha Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-domain recommendation (CDR) extends conventional recommender systems by
leveraging user-item interactions from dense domains to mitigate data sparsity
and the cold start problem. While CDR offers substantial potential for
enhancing recommendation performance, most existing CDR methods suffer from
sensitivity to the ratio of overlapping users and intrinsic discrepancy between
source and target domains. To overcome these limitations, in this work, we
explore the application of graph signal processing (GSP) in CDR scenarios. We
propose CGSP, a unified CDR framework based on GSP, which employs a
cross-domain similarity graph constructed by flexibly combining target-only
similarity and source-bridged similarity. By processing personalized graph
signals computed for users from either the source or target domain, our
framework effectively supports both inter-domain and intra-domain
recommendations. Our empirical evaluation demonstrates that CGSP consistently
outperforms various encoder-based CDR approaches in both intra-domain and
inter-domain recommendation scenarios, especially when the ratio of overlapping
users is low, highlighting its significant practical implication in real-world
applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Object-Aware Query Perturbation for Cross-Modal Image-Text Retrieval <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12346v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12346v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naoya Sogi, Takashi Shibata, Makoto Terao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The pre-trained vision and language (V\&L) models have substantially improved
the performance of cross-modal image-text retrieval. In general, however, V\&L
models have limited retrieval performance for small objects because of the
rough alignment between words and the small objects in the image. In contrast,
it is known that human cognition is object-centric, and we pay more attention
to important objects, even if they are small. To bridge this gap between the
human cognition and the V\&L model's capability, we propose a cross-modal
image-text retrieval framework based on ``object-aware query perturbation.''
The proposed method generates a key feature subspace of the detected objects
and perturbs the corresponding queries using this subspace to improve the
object awareness in the image. In our proposed method, object-aware cross-modal
image-text retrieval is possible while keeping the rich expressive power and
retrieval performance of existing V\&L models without additional fine-tuning.
Comprehensive experiments on four public datasets show that our method
outperforms conventional algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GUME: Graphs and User Modalities Enhancement for Long-Tail Multimodal
  Recommendation <span class="chip">CIKM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12338v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12338v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guojiao Lin, Zhen Meng, Dongjie Wang, Qingqing Long, Yuanchun Zhou, Meng Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal recommendation systems (MMRS) have received considerable attention
from the research community due to their ability to jointly utilize information
from user behavior and product images and text. Previous research has two main
issues. First, many long-tail items in recommendation systems have limited
interaction data, making it difficult to learn comprehensive and informative
representations. However, past MMRS studies have overlooked this issue.
Secondly, users' modality preferences are crucial to their behavior. However,
previous research has primarily focused on learning item modality
representations, while user modality representations have remained relatively
simplistic.To address these challenges, we propose a novel Graphs and User
Modalities Enhancement (GUME) for long-tail multimodal recommendation.
Specifically, we first enhance the user-item graph using multimodal similarity
between items. This improves the connectivity of long-tail items and helps them
learn high-quality representations through graph propagation. Then, we
construct two types of user modalities: explicit interaction features and
extended interest features. By using the user modality enhancement strategy to
maximize mutual information between these two features, we improve the
generalization ability of user modality representations. Additionally, we
design an alignment strategy for modality data to remove noise from both
internal and external perspectives. Extensive experiments on four publicly
available datasets demonstrate the effectiveness of our approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, accepted by CIKM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing Query Generation for Enhanced Document Retrieval in RAG 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12325v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12325v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hamin Koo, Minseon Kim, Sung Ju Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) excel in various language tasks but they often
generate incorrect information, a phenomenon known as "hallucinations".
Retrieval-Augmented Generation (RAG) aims to mitigate this by using document
retrieval for accurate responses. However, RAG still faces hallucinations due
to vague queries. This study aims to improve RAG by optimizing query generation
with a query-document alignment score, refining queries using LLMs for better
precision and efficiency of document retrieval. Experiments have shown that our
approach improves document retrieval, resulting in an average accuracy gain of
1.6%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ModalChorus: Visual Probing and Alignment of Multi-modal Embeddings via
  Modal Fusion Map 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12315v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12315v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilin Ye, Shishi Xiao, Xingchen Zeng, Wei Zeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-modal embeddings form the foundation for vision-language models, such
as CLIP embeddings, the most widely used text-image embeddings. However, these
embeddings are vulnerable to subtle misalignment of cross-modal features,
resulting in decreased model performance and diminished generalization. To
address this problem, we design ModalChorus, an interactive system for visual
probing and alignment of multi-modal embeddings. ModalChorus primarily offers a
two-stage process: 1) embedding probing with Modal Fusion Map (MFM), a novel
parametric dimensionality reduction method that integrates both metric and
nonmetric objectives to enhance modality fusion; and 2) embedding alignment
that allows users to interactively articulate intentions for both point-set and
set-set alignments. Quantitative and qualitative comparisons for CLIP
embeddings with existing dimensionality reduction (e.g., t-SNE and MDS) and
data fusion (e.g., data context map) methods demonstrate the advantages of MFM
in showcasing cross-modal features over common vision-language datasets. Case
studies reveal that ModalChorus can facilitate intuitive discovery of
misalignment and efficient re-alignment in scenarios ranging from zero-shot
classification to cross-modal retrieval and generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by VIS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Harnessing Large Language Models for Multimodal Product Bundling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11712v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11712v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaohao Liu, Jie Wu, Zhulin Tao, Yunshan Ma, Yinwei Wei, Tat-seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Product bundling provides clients with a strategic combination of individual
items. And it has gained significant attention in recent years as a fundamental
prerequisite for online services. Recent methods utilize multimodal information
through sophisticated extractors for bundling, but remain limited by inferior
semantic understanding, the restricted scope of knowledge, and an inability to
handle cold-start issues. Despite the extensive knowledge and complex reasoning
capabilities of large language models (LLMs), their direct utilization fails to
process multimodalities and exploit their knowledge for multimodal product
bundling. Adapting LLMs for this purpose involves demonstrating the synergies
among different modalities and designing an effective optimization strategy for
bundling, which remains challenging. To this end, we introduce Bundle-LLM to
bridge the gap between LLMs and product bundling tasks. Specifically, we
utilize a hybrid item tokenization to integrate multimodal information, where a
simple yet powerful multimodal fusion module followed by a trainable projector
embeds all non-textual features into a single token. This module not only
explicitly exhibits the interplays among modalities but also shortens the
prompt length, thereby boosting efficiency. By designing a prompt template, we
formulate product bundling as a multiple-choice question given candidate items.
Furthermore, we adopt progressive optimization strategy to fine-tune the LLMs
for disentangled objectives, achieving effective product bundling capability
with comprehensive multimodal semantic understanding. Extensive experiments on
four datasets from two application domains show that our approach outperforms a
range of state-of-the-art (SOTA) methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Recipe Retrieval with Foundation Models: A Data Augmentation
  Perspective <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.04763v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.04763v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fangzhou Song, Bin Zhu, Yanbin Hao, Shuo Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning recipe and food image representation in common embedding space is
non-trivial but crucial for cross-modal recipe retrieval. In this paper, we
propose a new perspective for this problem by utilizing foundation models for
data augmentation. Leveraging on the remarkable capabilities of foundation
models (i.e., Llama2 and SAM), we propose to augment recipe and food image by
extracting alignable information related to the counterpart. Specifically,
Llama2 is employed to generate a textual description from the recipe, aiming to
capture the visual cues of a food image, and SAM is used to produce image
segments that correspond to key ingredients in the recipe. To make full use of
the augmented data, we introduce Data Augmented Retrieval framework (DAR) to
enhance recipe and image representation learning for cross-modal retrieval. We
first inject adapter layers to pre-trained CLIP model to reduce computation
cost rather than fully fine-tuning all the parameters. In addition, multi-level
circle loss is proposed to align the original and augmented data pairs, which
assigns different penalties for positive and negative pairs. On the Recipe1M
dataset, our DAR outperforms all existing methods by a large margin. Extensive
ablation studies validate the effectiveness of each component of DAR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ClimRetrieve: A Benchmarking <span class="highlight-title">Dataset</span> for Information Retrieval from
  Corporate Climate Disclosures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09818v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09818v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tobias Schimanski, Jingwei Ni, Roberto Spacey, Nicola Ranger, Markus Leippold
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To handle the vast amounts of qualitative data produced in corporate climate
communication, stakeholders increasingly rely on Retrieval Augmented Generation
(RAG) systems. However, a significant gap remains in evaluating domain-specific
information retrieval - the basis for answer generation. To address this
challenge, this work simulates the typical tasks of a sustainability analyst by
examining 30 sustainability reports with 16 detailed climate-related questions.
As a result, we obtain a dataset with over 8.5K unique question-source-answer
pairs labeled by different levels of relevance. Furthermore, we develop a use
case with the dataset to investigate the integration of expert knowledge into
information retrieval with embeddings. Although we show that incorporating
expert knowledge works, we also outline the critical limitations of embeddings
in knowledge-intensive downstream domains like climate change communication.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dense Retrieval with Continuous Explicit Feedback for Systematic <span class="highlight-title">Review</span>
  Screening Prioritisation <span class="chip">SIGIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.00635v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.00635v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyu Mao, Shengyao Zhuang, Bevan Koopman, Guido Zuccon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The goal of screening prioritisation in systematic reviews is to identify
relevant documents with high recall and rank them in early positions for
review. This saves reviewing effort if paired with a stopping criterion, and
speeds up review completion if performed alongside downstream tasks. Recent
studies have shown that neural models have good potential on this task, but
their time-consuming fine-tuning and inference discourage their widespread use
for screening prioritisation. In this paper, we propose an alternative approach
that still relies on neural models, but leverages dense representations and
relevance feedback to enhance screening prioritisation, without the need for
costly model fine-tuning and inference. This method exploits continuous
relevance feedback from reviewers during document screening to efficiently
update the dense query representation, which is then applied to rank the
remaining documents to be screened. We evaluate this approach across the CLEF
TAR datasets for this task. Results suggest that the investigated dense
query-driven approach is more efficient than directly using neural models and
shows promising effectiveness compared to previous methods developed on the
considered datasets. Our code is available at
https://github.com/ielab/dense-screening-feedback.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGIR 2024;typos corrected</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Table Meets LLM: Can Large Language Models Understand Structured Table
  Data? A Benchmark and Empirical Study <span class="chip">WSDM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.13062v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.13062v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuan Sui, Mengyu Zhou, Mingjie Zhou, Shi Han, Dongmei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are becoming attractive as few-shot reasoners to
solve Natural Language (NL)-related tasks. However, the understanding of their
capability to process structured data like tables remains an under-explored
area. While tables can be serialized as input for LLMs, there is a lack of
comprehensive studies on whether LLMs genuinely comprehend this data. In this
paper, we try to understand this by designing a benchmark to evaluate the
structural understanding capabilities of LLMs through seven distinct tasks,
e.g., cell lookup, row retrieval and size detection. Specially, we perform a
series of evaluations on the recent most advanced LLM models, GPT-3.5 and GPT-4
and observe that performance varied with different input choices, including
table input format, content order, role prompting, and partition marks. Drawing
from the insights gained through the benchmark evaluations, we propose
$\textit{self-augmentation}$ for effective structural prompting, such as
critical value / range identification using internal knowledge of LLMs. When
combined with carefully chosen input choices, these structural prompting
methods lead to promising improvements in LLM performance on a variety of
tabular tasks, e.g., TabFact($\uparrow2.31\%$), HybridQA($\uparrow2.13\%$),
SQA($\uparrow2.72\%$), Feverous($\uparrow0.84\%$), and ToTTo($\uparrow5.68\%$).
We believe that our open source benchmark and proposed prompting methods can
serve as a simple yet generic selection for future research. The code and data
of this paper will be temporality released at
https://anonymous.4open.science/r/StructuredLLM-76F3/README.md and will be
replaced with an official one at https://github.com/microsoft/TableProvider
later.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted as a full paper at WSDM 2024. Explore
  the MS research blog of our work at
  https://www.microsoft.com/en-us/research/blog/improving-llm-understanding-of-structured-data-and-exploring-advanced-prompting-methods/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Recommendation Unlearning via Influence Function 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.02147v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.02147v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Zhang, Zhiyu Hu, Yimeng Bai, Jiancan Wu, Qifan Wang, Fuli Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommendation unlearning is an emerging task to serve users for erasing
unusable data (e.g., some historical behaviors) from a well-trained recommender
model. Existing methods process unlearning requests by fully or partially
retraining the model after removing the unusable data. However, these methods
are impractical due to the high computation cost of full retraining and the
highly possible performance damage of partial training. In this light, a
desired recommendation unlearning method should obtain a similar model as full
retraining in a more efficient manner, i.e., achieving complete, efficient and
harmless unlearning.
  In this work, we propose a new Influence Function-based Recommendation
Unlearning (IFRU) framework, which efficiently updates the model without
retraining by estimating the influence of the unusable data on the model via
the influence function. In the light that recent recommender models use
historical data for both the constructions of the optimization loss and the
computational graph (e.g., neighborhood aggregation), IFRU jointly estimates
the direct influence of unusable data on optimization loss and the spillover
influence on the computational graph to pursue complete unlearning.
Furthermore, we propose an importance-based pruning algorithm to reduce the
cost of the influence function. IFRU is harmless and applicable to mainstream
differentiable models. Extensive experiments demonstrate that IFRU achieves
more than 250 times acceleration compared to retraining-based methods with
recommendation performance comparable to full retraining. Codes are avaiable at
https://github.com/baiyimeng/IFRU.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unlocking the `Why' of Buying: Introducing a New <span class="highlight-title">Dataset</span> and Benchmark
  for Purchase Reason and Post-Purchase Experience 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.13417v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.13417v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tao Chen, Siqi Zuo, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Explanations are crucial for enhancing user trust and understanding within
modern recommendation systems. To build truly explainable systems, we need
high-quality datasets that elucidate why users make choices. While previous
efforts have focused on extracting users' post-purchase sentiment in reviews,
they ignore the reasons behind the decision to buy.
  In our work, we propose a novel purchase reason explanation task. To this
end, we introduce an LLM-based approach to generate a dataset that consists of
textual explanations of why real users make certain purchase decisions. We
induce LLMs to explicitly distinguish between the reasons behind purchasing a
product and the experience after the purchase in a user review. An automated,
LLM-driven evaluation, as well as a small scale human evaluation, confirms the
effectiveness of our approach to obtaining high-quality, personalized
explanations. We benchmark this dataset on two personalized explanation
generation tasks. We release the code and prompts to spur further research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MerRec: A Large-scale Multipurpose Mercari <span class="highlight-title">Dataset</span> for
  Consumer-to-Consumer Recommendation Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.14230v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.14230v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lichi Li, Zainul Abi Din, Zhen Tan, Sam London, Tianlong Chen, Ajay Daptardar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the evolving e-commerce field, recommendation systems crucially shape user
experience and engagement. The rise of Consumer-to-Consumer (C2C)
recommendation systems, noted for their flexibility and ease of access for
customer vendors, marks a significant trend. However, the academic focus
remains largely on Business-to-Consumer (B2C) models, leaving a gap filled by
the limited C2C recommendation datasets that lack in item attributes, user
diversity, and scale. The intricacy of C2C recommendation systems is further
accentuated by the dual roles users assume as both sellers and buyers,
introducing a spectrum of less uniform and varied inputs. Addressing this, we
introduce MerRec, the first large-scale dataset specifically for C2C
recommendations, sourced from the Mercari e-commerce platform, covering
millions of users and products over 6 months in 2023. MerRec not only includes
standard features such as user_id, item_id, and session_id, but also unique
elements like timestamped action types, product taxonomy, and textual product
attributes, offering a comprehensive dataset for research. This dataset,
extensively evaluated across four recommendation tasks, establishes a new
benchmark for the development of advanced recommendation algorithms in
real-world scenarios, bridging the gap between academia and industry and
propelling the study of C2C recommendations. Our experiment code is available
at https://github.com/mercari/mercari-ml-merrec-pub-us and dataset at
https://huggingface.co/datasets/mercari-us/merrec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Dataset available at:
  https://huggingface.co/datasets/mercari-us/merrec, code available at:
  https://github.com/mercari/mercari-ml-merrec-pub-us</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">8</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DreamStory: Open-Domain Story Visualization by LLM-Guided Multi-Subject
  Consistent Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12899v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12899v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huiguo He, Huan Yang, Zixi Tuo, Yuan Zhou, Qiuyue Wang, Yuhang Zhang, Zeyu Liu, Wenhao Huang, Hongyang Chao, Jian Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Story visualization aims to create visually compelling images or videos
corresponding to textual narratives. Despite recent advances in diffusion
models yielding promising results, existing methods still struggle to create a
coherent sequence of subject-consistent frames based solely on a story. To this
end, we propose DreamStory, an automatic open-domain story visualization
framework by leveraging the LLMs and a novel multi-subject consistent diffusion
model. DreamStory consists of (1) an LLM acting as a story director and (2) an
innovative Multi-Subject consistent Diffusion model (MSD) for generating
consistent multi-subject across the images. First, DreamStory employs the LLM
to generate descriptive prompts for subjects and scenes aligned with the story,
annotating each scene's subjects for subsequent subject-consistent generation.
Second, DreamStory utilizes these detailed subject descriptions to create
portraits of the subjects, with these portraits and their corresponding textual
information serving as multimodal anchors (guidance). Finally, the MSD uses
these multimodal anchors to generate story scenes with consistent
multi-subject. Specifically, the MSD includes Masked Mutual Self-Attention
(MMSA) and Masked Mutual Cross-Attention (MMCA) modules. MMSA and MMCA modules
ensure appearance and semantic consistency with reference images and text,
respectively. Both modules employ masking mechanisms to prevent subject
blending. To validate our approach and promote progress in story visualization,
we established a benchmark, DS-500, which can assess the overall performance of
the story visualization framework, subject-identification accuracy, and the
consistency of the generation model. Extensive experiments validate the
effectiveness of DreamStory in both subjective and objective evaluations.
Please visit our project homepage at https://dream-xyz.github.io/dreamstory.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Film Grain Coding in VVC: Improving Encoding Quality and
  Efficiency 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12465v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12465v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vignesh V Menon, Adam Wieckowski, Christian Stoffers, Jens Brandenburg, Christian Lehmann, Benjamin Bross, Thomas Schierl, Detlev Marpe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an in-depth analysis of film grain handling in
open-source implementations of the Versatile Video Coding (VVC) standard. We
focus on two key components: the Film Grain Analysis (FGA) module implemented
in VVenC and the Film Grain Synthesis (FGS) module implemented in VVdeC. We
describe the methodologies used to implement these modules and discuss the
generation of Supplementary Enhancement Information (SEI) parameters to signal
film grain characteristics in the encoded video sequences. Additionally, we
conduct subjective and objective evaluations across Full HD videos to assess
the effectiveness of film grain handling. Our results demonstrate the
capability of the FGA and FGS techniques to accurately analyze and synthesize
film grain, thereby improving the visual quality of encoded video content.
Overall, our study contributes to advancing the understanding and
implementation of film grain handling techniques in VVC open-source
implementations, with implications for enhancing the viewing experience in
multimedia applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at IBC'24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM-based query paraphrasing for video search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12341v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12341v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaxin Wu, Chong-Wah Ngo, Wing-Kwong Chan, Sheng-Hua Zhong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-video retrieval answers user queries through search by concepts and
embeddings. Limited by the size of the concept bank and the amount of training
data, answering queries in the wild is not always effective due to the
out-of-vocabulary problem. Furthermore, neither concept-based nor
embedding-based search can perform reasoning to consolidate the search results
for complex queries mixed with logical and spatial constraints. To address
these problems, we leverage large language models (LLM) to paraphrase the query
by text-to-text (T2T), text-to-image (T2I), and image-to-text (I2T)
transformations. These transformations rephrase abstract concepts into simple
words to address the out-of-vocabulary problem. Furthermore, the complex
relationship in a query can be decoupled into simpler sub-queries, yielding
better retrieval performance when fusing the search results of these
sub-queries. To address the LLM hallucination problem, this paper also proposes
a novel consistency-based verification strategy to filter the paraphrased
queries that are factually incorrect. Extensive experiments are conducted for
ad-hoc video search and known-item search on the TRECVid datasets. We provide
empirical insights into how traditionally difficult-to-answer queries can be
resolved by query paraphrasing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lightning Fast Video Anomaly Detection via Adversarial Knowledge
  Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2211.15597v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2211.15597v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Florinel-Alin Croitoru, Nicolae-Catalin Ristea, Dana Dascalescu, Radu Tudor Ionescu, Fahad Shahbaz Khan, Mubarak Shah
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a very fast frame-level model for anomaly detection in video,
which learns to detect anomalies by distilling knowledge from multiple highly
accurate object-level teacher models. To improve the fidelity of our student,
we distill the low-resolution anomaly maps of the teachers by jointly applying
standard and adversarial distillation, introducing an adversarial discriminator
for each teacher to distinguish between target and generated anomaly maps. We
conduct experiments on three benchmarks (Avenue, ShanghaiTech, UCSD Ped2),
showing that our method is over 7 times faster than the fastest competing
method, and between 28 and 62 times faster than object-centric models, while
obtaining comparable results to recent methods. Our evaluation also indicates
that our model achieves the best trade-off between speed and accuracy, due to
its previously unheard-of speed of 1480 FPS. In addition, we carry out a
comprehensive ablation study to justify our architectural design choices. Our
code is freely available at: https://github.com/ristea/fast-aed.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in Computer Vision and Image Understanding</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Statistics-aware Audio-visual Deepfake Detector <span class="chip">ICIP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11650v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11650v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marcella Astrid, Enjie Ghorbel, Djamila Aouada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose an enhanced audio-visual deep detection method.
Recent methods in audio-visual deepfake detection mostly assess the
synchronization between audio and visual features. Although they have shown
promising results, they are based on the maximization/minimization of isolated
feature distances without considering feature statistics. Moreover, they rely
on cumbersome deep learning architectures and are heavily dependent on
empirically fixed hyperparameters. Herein, to overcome these limitations, we
propose: (1) a statistical feature loss to enhance the discrimination
capability of the model, instead of relying solely on feature distances; (2)
using the waveform for describing the audio as a replacement of frequency-based
representations; (3) a post-processing normalization of the fakeness score; (4)
the use of shallower network for reducing the computational complexity.
Experiments on the DFDC and FakeAVCeleb datasets demonstrate the relevance of
the proposed method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ICIP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Show Me the World in My Language: Establishing the First Baseline for
  Scene-Text to Scene-Text Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.03024v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.03024v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shreyas Vaidya, Arvind Kumar Sharma, Prajwal Gatti, Anand Mishra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we study the task of visually translating scene text from a
source language (e.g., Hindi) to a target language (e.g., English). Visual
translation involves not just the recognition and translation of scene text but
also the generation of the translated image that preserves visual features of
the source scene text, such as font, size, and background. There are several
challenges associated with this task, such as translation with limited context,
deciding between translation and transliteration, accommodating varying text
lengths within fixed spatial boundaries, and preserving the font and background
styles of the source scene text in the target language. To address this
problem, we make the following contributions: (i) We study visual translation
as a standalone problem for the first time in the literature. (ii) We present a
cascaded framework for visual translation that combines state-of-the-art
modules for scene text recognition, machine translation, and scene text
synthesis as a baseline for the task. (iii) We propose a set of task-specific
design enhancements to design a variant of the baseline to obtain performance
improvements. (iv) Currently, the existing related literature lacks any
comprehensive performance evaluation for this novel task. To fill this gap, we
introduce several automatic and user-assisted evaluation metrics designed
explicitly for evaluating visual translation. Further, we evaluate presented
baselines for translating scene text between Hindi and English. Our experiments
demonstrate that although we can effectively perform visual translation over a
large collection of scene text images, the presented baseline only partially
addresses challenges posed by visual translation tasks. We firmly believe that
this new task and the limitations of existing models, as reported in this
paper, should encourage further research in visual translation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Please be advised that the previous version contained some technical
  issues. Kindly refer to this updated version for accurate information</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Natural Language-Guided Drones: GeoText-1652 Benchmark with
  Spatial Relation Matching <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12751v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12751v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Meng Chu, Zhedong Zheng, Wei Ji, Tingyu Wang, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Navigating drones through natural language commands remains challenging due
to the dearth of accessible multi-modal datasets and the stringent precision
requirements for aligning visual and textual data. To address this pressing
need, we introduce GeoText-1652, a new natural language-guided geo-localization
benchmark. This dataset is systematically constructed through an interactive
human-computer process leveraging Large Language Model (LLM) driven annotation
techniques in conjunction with pre-trained vision models. GeoText-1652 extends
the established University-1652 image dataset with spatial-aware text
annotations, thereby establishing one-to-one correspondences between image,
text, and bounding box elements. We further introduce a new optimization
objective to leverage fine-grained spatial associations, called blending
spatial matching, for region-level spatial relation matching. Extensive
experiments reveal that our approach maintains a competitive recall rate
comparing other prevailing cross-modality methods. This underscores the
promising potential of our approach in elevating drone control and navigation
through the seamless integration of natural language commands in real-world
scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ IG Captioner: Information Gain Captioners are Strong Zero-shot
  Classifiers <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.17072v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.17072v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenglin Yang, Siyuan Qiao, Yuan Cao, Yu Zhang, Tao Zhu, Alan Yuille, Jiahui Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative training has been demonstrated to be powerful for building
visual-language models. However, on zero-shot discriminative benchmarks, there
is still a performance gap between models trained with generative and
discriminative objectives. In this paper, we aim to narrow this gap by
improving the efficacy of generative training on classification tasks, without
any finetuning processes or additional modules.
  Specifically, we focus on narrowing the gap between the generative captioner
and the CLIP classifier. We begin by analysing the predictions made by the
captioner and classifier and observe that the caption generation inherits the
distribution bias from the language model trained with pure text modality,
making it less grounded on the visual signal. To tackle this problem, we
redesign the scoring objective for the captioner to alleviate the
distributional bias and focus on measuring the gain of information brought by
the visual inputs. We further design a generative training objective to match
the evaluation objective. We name our model trained and evaluated from the
novel procedures as Information Gain (IG) captioner. We pretrain the models on
the public Laion-5B dataset and perform a series of discriminative evaluations.
For the zero-shot classification on ImageNet, IG captioner achieves $> 18\%$
improvements over the standard captioner, achieving comparable performances
with the CLIP classifier. IG captioner also demonstrated strong performance on
zero-shot image-text retrieval tasks on MSCOCO and Flickr30K. We hope this
paper inspires further research towards unifying generative and discriminative
training procedures for visual-language models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-07-16T00:00:00Z">2024-07-16</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">16</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mindful-RAG: A Study of Points of Failure in Retrieval Augmented
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12216v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12216v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Garima Agrawal, Tharindu Kumarage, Zeyad Alghamdi, Huan Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are proficient at generating coherent and
contextually relevant text but face challenges when addressing
knowledge-intensive queries in domain-specific and factual question-answering
tasks. Retrieval-augmented generation (RAG) systems mitigate this by
incorporating external knowledge sources, such as structured knowledge graphs
(KGs). However, LLMs often struggle to produce accurate answers despite access
to KG-extracted information containing necessary facts. Our study investigates
this dilemma by analyzing error patterns in existing KG-based RAG methods and
identifying eight critical failure points. We observed that these errors
predominantly occur due to insufficient focus on discerning the question's
intent and adequately gathering relevant context from the knowledge graph
facts. Drawing on this analysis, we propose the Mindful-RAG approach, a
framework designed for intent-based and contextually aligned knowledge
retrieval. This method explicitly targets the identified failures and offers
improvements in the correctness and relevance of responses provided by LLMs,
representing a significant step forward from existing methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ClaimCompare: A Data Pipeline for Evaluation of Novelty Destroying
  Patent Pairs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12193v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12193v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arav Parikh, Shiri Dori-Hacohen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A fundamental step in the patent application process is the determination of
whether there exist prior patents that are novelty destroying. This step is
routinely performed by both applicants and examiners, in order to assess the
novelty of proposed inventions among the millions of applications filed
annually. However, conducting this search is time and labor-intensive, as
searchers must navigate complex legal and technical jargon while covering a
large amount of legal claims. Automated approaches using information retrieval
and machine learning approaches to detect novelty destroying patents present a
promising avenue to streamline this process, yet research focusing on this
space remains limited. In this paper, we introduce a novel data pipeline,
ClaimCompare, designed to generate labeled patent claim datasets suitable for
training IR and ML models to address this challenge of novelty destruction
assessment. To the best of our knowledge, ClaimCompare is the first pipeline
that can generate multiple novelty destroying patent datasets. To illustrate
the practical relevance of this pipeline, we utilize it to construct a sample
dataset comprising of over 27K patents in the electrochemical domain: 1,045
base patents from USPTO, each associated with 25 related patents labeled
according to their novelty destruction towards the base patent. Subsequently,
we conduct preliminary experiments showcasing the efficacy of this dataset in
fine-tuning transformer models to identify novelty destroying patents,
demonstrating 29.2% and 32.7% absolute improvement in MRR and P@1,
respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neural Passage Quality Estimation for Static Pruning <span class="chip">SIGIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12170v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12170v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuejun Chang, Debabrata Mishra, Craig Macdonald, Sean MacAvaney
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural networks -- especially those that use large, pre-trained language
models -- have improved search engines in various ways. Most prominently, they
can estimate the relevance of a passage or document to a user's query. In this
work, we depart from this direction by exploring whether neural networks can
effectively predict which of a document's passages are unlikely to be relevant
to any query submitted to the search engine. We refer to this query-agnostic
estimation of passage relevance as a passage's quality. We find that our novel
methods for estimating passage quality allow passage corpora to be pruned
considerably while maintaining statistically equivalent effectiveness; our best
methods can consistently prune >25% of passages in a corpora, across various
retrieval pipelines. Such substantial pruning reduces the operating costs of
neural search engines in terms of computing resources, power usage, and carbon
footprint -- both when processing queries (thanks to a smaller index size) and
when indexing (lightweight models can prune low-quality passages prior to the
costly dense or learned sparse encoding step). This work sets the stage for
developing more advanced neural "learning-what-to-index" methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SIGIR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12883v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12883v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongjin Su, Howard Yen, Mengzhou Xia, Weijia Shi, Niklas Muennighoff, Han-yu Wang, Haisu Liu, Quan Shi, Zachary S. Siegel, Michael Tang, Ruoxi Sun, Jinsung Yoon, Sercan O. Arik, Danqi Chen, Tao Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing retrieval benchmarks primarily consist of information-seeking
queries (e.g., aggregated questions from search engines) where keyword or
semantic-based retrieval is usually sufficient. However, many complex
real-world queries require in-depth reasoning to identify relevant documents
that go beyond surface form matching. For example, finding documentation for a
coding question requires understanding the logic and syntax of the functions
involved. To better benchmark retrieval on such challenging queries, we
introduce BRIGHT, the first text retrieval benchmark that requires intensive
reasoning to retrieve relevant documents. BRIGHT is constructed from the 1,398
real-world queries collected from diverse domains (such as economics,
psychology, robotics, software engineering, earth sciences, etc.), sourced from
naturally occurring or carefully curated human data. Extensive evaluation
reveals that even state-of-the-art retrieval models perform poorly on BRIGHT.
The leading model on the MTEB leaderboard [38 ], which achieves a score of 59.0
nDCG@10,2 produces a score of nDCG@10 of 18.0 on BRIGHT. We further demonstrate
that augmenting queries with Chain-of-Thought reasoning generated by large
language models (LLMs) improves performance by up to 12.2 points. Moreover,
BRIGHT is robust against data leakage during pretraining of the benchmarked
models as we validate by showing similar performance even when documents from
the benchmark are included in the training data. We believe that BRIGHT paves
the way for future research on retrieval systems in more realistic and
challenging settings. Our code and data are available at
https://brightbenchmark.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>50 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Comprehensive Evaluation of Large Language Models on Temporal Event
  Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11638v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11638v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, Large Language Models (LLMs) have demonstrated great potential in
various data mining tasks, such as knowledge question answering, mathematical
reasoning, and commonsense reasoning. However, the reasoning capability of LLMs
on temporal event forecasting has been under-explored. To systematically
investigate their abilities in temporal event forecasting, we conduct a
comprehensive evaluation of LLM-based methods for temporal event forecasting.
Due to the lack of a high-quality dataset that involves both graph and textual
data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on
this dataset, we design a series of baseline methods, characterized by various
input formats and retrieval augmented generation(RAG) modules. From extensive
experiments, we find that directly integrating raw texts into the input of LLMs
does not enhance zero-shot extrapolation performance. In contrast,
incorporating raw texts in specific complex events and fine-tuning LLMs
significantly improves performance. Moreover, enhanced with retrieval modules,
LLM can effectively capture temporal relational patterns hidden in historical
events. Meanwhile, issues such as popularity bias and the long-tail problem
still persist in LLMs, particularly in the RAG-based method. These findings not
only deepen our understanding of LLM-based event forecasting methods but also
highlight several promising research directions.We consider that this
comprehensive evaluation, along with the identified research opportunities,
will significantly contribute to future research on temporal event forecasting
through LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Interactions with Generative Information Retrieval Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11605v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11605v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Aliannejadi, Jacek Gwizdka, Hamed Zamani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  At its core, information access and seeking is an interactive process. In
existing search engines, interactions are limited to a few pre-defined actions,
such as "requery", "click on a document", "scrolling up/down", "going to the
next result page", "leaving the search engine", etc. A major benefit of moving
towards generative IR systems is enabling users with a richer expression of
information need and feedback and free-form interactions in natural language
and beyond. In other words, the actions users take are no longer limited by the
clickable links and buttons available on the search engine result page and
users can express themselves freely through natural language. This can go even
beyond natural language, through images, videos, gestures, and sensors using
multi-modal generative IR systems. This chapter briefly discusses the role of
interaction in generative IR systems. We will first discuss different ways
users can express their information needs by interacting with generative IR
systems. We then explain how users can provide explicit or implicit feedback to
generative IR systems and how they can consume such feedback. Next, we will
cover how users interactively can refine retrieval results. We will expand upon
mixed-initiative interactions and discuss clarification and preference
elicitation in more detail. We then discuss proactive generative IR systems,
including context-aware recommendation, following up past conversations,
contributing to multi-party conversations, and feedback requests. Providing
explanation is another interaction type that we briefly discuss in this
chapter. We will also briefly describe multi-modal interactions in generative
information retrieval. Finally, we describe emerging frameworks and solutions
for user interfaces with generative AI systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Draft of a chapter intended to appear in a forthcoming book on
  generative information retrieval, co-edited by Chirag Shah and Ryen White</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A PLMs based protein retrieval framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11548v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11548v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Wu, Xiao Yi, Yang Tan, Huiqun Yu, Guisheng Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Protein retrieval, which targets the deconstruction of the relationship
between sequences, structures and functions, empowers the advancing of biology.
Basic Local Alignment Search Tool (BLAST), a sequence-similarity-based
algorithm, has proved the efficiency of this field. Despite the existing tools
for protein retrieval, they prioritize sequence similarity and probably
overlook proteins that are dissimilar but share homology or functionality. In
order to tackle this problem, we propose a novel protein retrieval framework
that mitigates the bias towards sequence similarity. Our framework initiatively
harnesses protein language models (PLMs) to embed protein sequences within a
high-dimensional feature space, thereby enhancing the representation capacity
for subsequent analysis. Subsequently, an accelerated indexed vector database
is constructed to facilitate expedited access and retrieval of dense vectors.
Extensive experiments demonstrate that our framework can equally retrieve both
similar and dissimilar proteins. Moreover, this approach enables the
identification of proteins that conventional methods fail to uncover. This
framework will effectively assist in protein mining and empower the development
of biology.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bootstrapped <span class="highlight-title">Pre-train</span>ing with Dynamic Identifier Prediction for
  Generative Retrieval <span class="chip">ACL</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11504v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11504v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yubao Tang, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Yixing Fan, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative retrieval uses differentiable search indexes to directly generate
relevant document identifiers in response to a query. Recent studies have
highlighted the potential of a strong generative retrieval model, trained with
carefully crafted pre-training tasks, to enhance downstream retrieval tasks via
fine-tuning. However, the full power of pre-training for generative retrieval
remains underexploited due to its reliance on pre-defined static document
identifiers, which may not align with evolving model parameters. In this work,
we introduce BootRet, a bootstrapped pre-training method for generative
retrieval that dynamically adjusts document identifiers during pre-training to
accommodate the continuing memorization of the corpus. BootRet involves three
key training phases: (i) initial identifier generation, (ii) pre-training via
corpus indexing and relevance prediction tasks, and (iii) bootstrapping for
identifier updates. To facilitate the pre-training phase, we further introduce
noisy documents and pseudo-queries, generated by large language models, to
resemble semantic connections in both indexing and retrieval tasks.
Experimental results demonstrate that BootRet significantly outperforms
existing pre-training generative retrieval baselines and performs well even in
zero-shot settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACL Findings 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EndoFinder: Online Image Retrieval for Explainable Colorectal Polyp
  Diagnosis <span class="chip">MICCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11401v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11401v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruijie Yang, Yan Zhu, Peiyao Fu, Yizhe Zhang, Zhihua Wang, Quanlin Li, Pinghong Zhou, Xian Yang, Shuo Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Determining the necessity of resecting malignant polyps during colonoscopy
screen is crucial for patient outcomes, yet challenging due to the
time-consuming and costly nature of histopathology examination. While deep
learning-based classification models have shown promise in achieving optical
biopsy with endoscopic images, they often suffer from a lack of explainability.
To overcome this limitation, we introduce EndoFinder, a content-based image
retrieval framework to find the 'digital twin' polyp in the reference database
given a newly detected polyp. The clinical semantics of the new polyp can be
inferred referring to the matched ones. EndoFinder pioneers a polyp-aware image
encoder that is pre-trained on a large polyp dataset in a self-supervised way,
merging masked image modeling with contrastive learning. This results in a
generic embedding space ready for different downstream clinical tasks based on
image retrieval. We validate the framework on polyp re-identification and
optical biopsy tasks, with extensive experiments demonstrating that EndoFinder
not only achieves explainable diagnostics but also matches the performance of
supervised classification models. EndoFinder's reliance on image retrieval has
the potential to support diverse downstream decision-making tasks during
real-time colonoscopy procedures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>MICCAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bridging the Gap Between Information Seeking and Product Search Systems:
  Q&A Recommendation for E-commerce 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09653v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09653v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saar Kuzi, Shervin Malmasi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Consumers on a shopping mission often leverage both product search and
information seeking systems, such as web search engines and Question Answering
(QA) systems, in an iterative process to improve their understanding of
available products and reach a purchase decision. While product search is
useful for shoppers to find the actual products meeting their requirements in
the catalog, information seeking systems can be utilized to answer any
questions they may have to refine those requirements. The recent success of
Large Language Models (LLMs) has opened up an opportunity to bridge the gap
between the two tasks to help customers achieve their goals quickly and
effectively by integrating conversational QA within product search. In this
paper, we propose to recommend users Question-Answer (Q&A) pairs that are
relevant to their product search and can help them make a purchase decision. We
discuss the different aspects of the problem including the requirements and
characteristics of the Q&A pairs, their generation, and the optimization of the
Q&A recommendation task. We highlight the challenges, open problems, and
suggested solutions to encourage future research in this emerging area.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Models for Relevance Judgment in Product Search <span class="chip">SIGIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.00247v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.00247v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Navid Mehrdad, Hrushikesh Mohapatra, Mossaab Bagdouri, Prijith Chandran, Alessandro Magnani, Xunfan Cai, Ajit Puthenputhussery, Sachin Yadav, Tony Lee, ChengXiang Zhai, Ciya Liao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High relevance of retrieved and re-ranked items to the search query is the
cornerstone of successful product search, yet measuring relevance of items to
queries is one of the most challenging tasks in product information retrieval,
and quality of product search is highly influenced by the precision and scale
of available relevance-labelled data. In this paper, we present an array of
techniques for leveraging Large Language Models (LLMs) for automating the
relevance judgment of query-item pairs (QIPs) at scale. Using a unique dataset
of multi-million QIPs, annotated by human evaluators, we test and optimize
hyper parameters for finetuning billion-parameter LLMs with and without Low
Rank Adaption (LoRA), as well as various modes of item attribute concatenation
and prompting in LLM finetuning, and consider trade offs in item attribute
inclusion for quality of relevance predictions. We demonstrate considerable
improvement over baselines of prior generations of LLMs, as well as
off-the-shelf models, towards relevance annotations on par with the human
relevance evaluators. Our findings have immediate implications for the growing
field of relevance judgment automation in product search.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 1 figure, 11 tables - SIGIR 2024, LLM4Eval</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sociotechnical Implications of Generative Artificial Intelligence for
  Information Access 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.11612v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.11612v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bhaskar Mitra, Henriette Cramer, Olya Gurevich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Robust access to trustworthy information is a critical need for society with
implications for knowledge production, public health education, and promoting
informed citizenry in democratic societies. Generative AI technologies may
enable new ways to access information and improve effectiveness of existing
information retrieval systems but we are only starting to understand and
grapple with their long-term social implications. In this chapter, we present
an overview of some of the systemic consequences and risks of employing
generative AI in the context of information access. We also provide
recommendations for evaluation and mitigation, and discuss challenges for
future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UniRec: A Dual Enhancement of Uniformity and Frequency in Sequential
  Recommendations <span class="chip">CIKM'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18470v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18470v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Liu, Yitong Wang, Chenyue Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Representation learning in sequential recommendation is critical for
accurately modeling user interaction patterns and improving recommendation
precision. However, existing approaches predominantly emphasize item-to-item
transitions, often neglecting the time intervals between interactions, which
are closely related to behavior pattern changes. Additionally, broader
interaction attributes, such as item frequency, are frequently overlooked. We
found that both sequences with more uniform time intervals and items with
higher frequency yield better prediction performance. Conversely, non-uniform
sequences exacerbate user interest drift and less-frequent items are difficult
to model due to sparse sampling, presenting unique challenges inadequately
addressed by current methods. In this paper, we propose UniRec, a novel
bidirectional enhancement sequential recommendation method. UniRec leverages
sequence uniformity and item frequency to enhance performance, particularly
improving the representation of non-uniform sequences and less-frequent items.
These two branches mutually reinforce each other, driving comprehensive
performance optimization in complex sequential recommendation scenarios.
Additionally, we present a multidimensional time module to further enhance
adaptability. To the best of our knowledge, UniRec is the first method to
utilize the characteristics of uniformity and frequency for feature
augmentation. Comparing with eleven advanced models across four datasets, we
demonstrate that UniRec outperforms SOTA models significantly. The code is
available at https://github.com/Linxi000/UniRec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 8 figures, accepted by CIKM'24, for source code, see
  https://github.com/Linxi000/UniRec</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AutoSAM: Towards Automatic Sampling of User Behaviors for Sequential
  Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.00388v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.00388v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Zhang, Mingyue Cheng, Qi Liu, Zhiding Liu, Junzhe Jiang, Enhong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommender systems (SRS) have gained widespread popularity in
recommendation due to their ability to effectively capture dynamic user
preferences. One default setting in the current SRS is to uniformly consider
each historical behavior as a positive interaction. Actually, this setting has
the potential to yield sub-optimal performance, as each item makes a distinct
contribution to the user's interest. For example, purchased items should be
given more importance than clicked ones. Hence, we propose a general automatic
sampling framework, named AutoSAM, to non-uniformly treat historical behaviors.
Specifically, AutoSAM augments the standard sequential recommendation
architecture with an additional sampler layer to adaptively learn the skew
distribution of the raw input, and then sample informative sub-sets to build
more generalizable SRS. To overcome the challenges of non-differentiable
sampling actions and also introduce multiple decision factors for sampling, we
further introduce a novel reinforcement learning based method to guide the
training of the sampler. We theoretically design multi-objective sampling
rewards including Future Prediction and Sequence Perplexity, and then optimize
the whole framework in an end-to-end manner by combining the policy gradient.
We conduct extensive experiments on benchmark recommender models and four
real-world datasets. The experimental results demonstrate the effectiveness of
the proposed approach. We will make our code publicly available after the
acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SciConNav: Knowledge navigation through contextual learning of extensive
  scientific research trajectories 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.11742v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.11742v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shibing Xiang, Xin Jiang, Bing Liu, Yurui Huang, Chaolin Tian, Yifang Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  New knowledge builds upon existing foundations, which means an interdependent
relationship exists between knowledge, manifested in the historical development
of the scientific system for hundreds of years. By leveraging natural language
processing techniques, this study introduces the Scientific Concept Navigator
(SciConNav), an embedding-based navigation model to infer the "knowledge
pathway" from the research trajectories of millions of scholars. We validate
that the learned representations effectively delineate disciplinary boundaries
and capture the intricate relationships between diverse concepts. The utility
of the inferred navigation space is showcased through multiple applications.
Firstly, we demonstrated the multi-step analogy inferences within the knowledge
space and the interconnectivity between concepts in different disciplines.
Secondly, we formulated the attribute dimensions of knowledge across domains,
observing the distributional shifts in the arrangement of 19 disciplines along
these conceptual dimensions, including "Theoretical" to "Applied", and
"Chemical" to "Biomedical', highlighting the evolution of functional attributes
within knowledge domains. Lastly, by analyzing the high-dimensional knowledge
network structure, we found that knowledge connects with shorter global
pathways, and interdisciplinary knowledge plays a critical role in the
accessibility of the global knowledge network. Our framework offers a novel
approach to mining knowledge inheritance pathways in extensive scientific
literature, which is of great significance for understanding scientific
progression patterns, tailoring scientific learning trajectories, and
accelerating scientific progress.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21pages, 13 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CompoDiff: Versatile Composed Image Retrieval With Latent Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.11916v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.11916v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Geonmo Gu, Sanghyuk Chun, Wonjae Kim, HeeJae Jun, Yoohoon Kang, Sangdoo Yun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a novel diffusion-based model, CompoDiff, for solving
zero-shot Composed Image Retrieval (ZS-CIR) with latent diffusion. This paper
also introduces a new synthetic dataset, named SynthTriplets18M, with 18.8
million reference images, conditions, and corresponding target image triplets
to train CIR models. CompoDiff and SynthTriplets18M tackle the shortages of the
previous CIR approaches, such as poor generalizability due to the small dataset
scale and the limited types of conditions. CompoDiff not only achieves a new
state-of-the-art on four ZS-CIR benchmarks, including FashionIQ, CIRR, CIRCO,
and GeneCIS, but also enables a more versatile and controllable CIR by
accepting various conditions, such as negative text, and image mask conditions.
CompoDiff also shows the controllability of the condition strength between text
and image queries and the trade-off between inference speed and performance,
which are unavailable with existing CIR methods. The code and dataset are
available at https://github.com/navervision/CompoDiff
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>TMLR camera-ready; First two authors contributed equally; TMLR Expert
  Certification; 30 pages, 5.9MB</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">10</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TGIF: Text-Guided Inpainting Forgery <span class="highlight-title">Dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11566v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11566v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hannes Mareen, Dimitrios Karageorgiou, Glenn Van Wallendael, Peter Lambert, Symeon Papadopoulos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Digital image manipulation has become increasingly accessible and realistic
with the advent of generative AI technologies. Recent developments allow for
text-guided inpainting, making sophisticated image edits possible with minimal
effort. This poses new challenges for digital media forensics. For example,
diffusion model-based approaches could either splice the inpainted region into
the original image, or regenerate the entire image. In the latter case,
traditional image forgery localization (IFL) methods typically fail. This paper
introduces the Text-Guided Inpainting Forgery (TGIF) dataset, a comprehensive
collection of images designed to support the training and evaluation of image
forgery localization and synthetic image detection (SID) methods. The TGIF
dataset includes approximately 80k forged images, originating from popular
open-source and commercial methods; SD2, SDXL, and Adobe Firefly. Using this
data, we benchmark several state-of-the-art IFL and SID methods. Whereas
traditional IFL methods can detect spliced images, they fail to detect
regenerated inpainted images. Moreover, traditional SID may detect the
regenerated inpainted images to be fake, but cannot localize the inpainted
area. Finally, both types of methods fail when exposed to stronger compression,
while they are less robust to modern compression algorithms, such as WEBP. As
such, this work demonstrates the inefficiency of state-of-the-art detectors on
local manipulations performed by modern generative approaches, and aspires to
help with the development of more capable IFL and SID methods. The dataset can
be downloaded at https://github.com/IDLabMedia/tgif-dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, submitted to conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ReLaX-VQA: Residual Fragment and Layer Stack Extraction for Enhancing
  Video Quality Assessment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11496v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11496v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyi Wang, Angeliki Katsenou, David Bull
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid growth of User-Generated Content (UGC) exchanged between users
and sharing platforms, the need for video quality assessment in the wild has
emerged. UGC is mostly acquired using consumer devices and undergoes multiple
rounds of compression or transcoding before reaching the end user. Therefore,
traditional quality metrics that require the original content as a reference
cannot be used. In this paper, we propose ReLaX-VQA, a novel No-Reference Video
Quality Assessment (NR-VQA) model that aims to address the challenges of
evaluating the diversity of video content and the assessment of its quality
without reference videos. ReLaX-VQA uses fragments of residual frames and
optical flow, along with different expressions of spatial features of the
sampled frames, to enhance motion and spatial perception. Furthermore, the
model enhances abstraction by employing layer-stacking techniques in deep
neural network features (from Residual Networks and Vision Transformers).
Extensive testing on four UGC datasets confirms that ReLaX-VQA outperforms
existing NR-VQA methods with an average SRCC value of 0.8658 and PLCC value of
0.8872. We will open source the code and trained models to facilitate further
research and applications of NR-VQA: https://github.com/xinyiW915/ReLaX-VQA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MMSD-Net: Towards Multi-modal Stuttering Detection <span class="chip">INTERSPEECH 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11492v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11492v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liangyu Nie, Sudarsana Reddy Kadiri, Ruchit Agrawal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stuttering is a common speech impediment that is caused by irregular
disruptions in speech production, affecting over 70 million people across the
world. Standard automatic speech processing tools do not take speech ailments
into account and are thereby not able to generate meaningful results when
presented with stuttered speech as input. The automatic detection of stuttering
is an integral step towards building efficient, context-aware speech processing
systems. While previous approaches explore both statistical and neural
approaches for stuttering detection, all of these methods are uni-modal in
nature. This paper presents MMSD-Net, the first multi-modal neural framework
for stuttering detection. Experiments and results demonstrate that
incorporating the visual signal significantly aids stuttering detection, and
our model yields an improvement of 2-17% in the F1-score over existing
state-of-the-art uni-modal approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at INTERSPEECH 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Lite<span class="highlight-title">GPT</span>: Large Vision-Language Model for Joint Chest X-ray Localization
  and Classification Task 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12064v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12064v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Khai Le-Duc, Ryan Zhang, Ngoc Son Nguyen, Tan-Hanh Pham, Anh Dao, Ba Hung Ngo, Anh Totti Nguyen, Truong-Son Hy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language models have been extensively explored across a wide range of
tasks, achieving satisfactory performance; however, their application in
medical imaging remains underexplored. In this work, we propose a unified
framework - LiteGPT - for the medical imaging. We leverage multiple pre-trained
visual encoders to enrich information and enhance the performance of
vision-language models. To the best of our knowledge, this is the first study
to utilize vision-language models for the novel task of joint localization and
classification in medical images. Besides, we are pioneers in providing
baselines for disease localization in chest X-rays. Finally, we set new
state-of-the-art performance in the image classification task on the
well-benchmarked VinDr-CXR dataset. All code and models are publicly available
online: https://github.com/leduckhai/LiteGPT
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint, 19 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MotionCtrl: A Unified and Flexible Motion Controller for Video
  Generation <span class="chip">SIGGRAPH 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.03641v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.03641v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhouxia Wang, Ziyang Yuan, Xintao Wang, Tianshui Chen, Menghan Xia, Ping Luo, Ying Shan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motions in a video primarily consist of camera motion, induced by camera
movement, and object motion, resulting from object movement. Accurate control
of both camera and object motion is essential for video generation. However,
existing works either mainly focus on one type of motion or do not clearly
distinguish between the two, limiting their control capabilities and diversity.
Therefore, this paper presents MotionCtrl, a unified and flexible motion
controller for video generation designed to effectively and independently
control camera and object motion. The architecture and training strategy of
MotionCtrl are carefully devised, taking into account the inherent properties
of camera motion, object motion, and imperfect training data. Compared to
previous methods, MotionCtrl offers three main advantages: 1) It effectively
and independently controls camera motion and object motion, enabling more
fine-grained motion control and facilitating flexible and diverse combinations
of both types of motion. 2) Its motion conditions are determined by camera
poses and trajectories, which are appearance-free and minimally impact the
appearance or shape of objects in generated videos. 3) It is a relatively
generalizable model that can adapt to a wide array of camera poses and
trajectories once trained. Extensive qualitative and quantitative experiments
have been conducted to demonstrate the superiority of MotionCtrl over existing
methods. Project Page: https://wzhouxiff.github.io/projects/MotionCtrl/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SIGGRAPH 2024 Conference Proceedings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring the Robustness of Decision-Level Through Adversarial Attacks
  on LLM-Based Embodied Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19802v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19802v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuyuan Liu, Jiawei Chen, Shouwei Ruan, Hang Su, Zhaoxia Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embodied intelligence empowers agents with a profound sense of perception,
enabling them to respond in a manner closely aligned with real-world
situations. Large Language Models (LLMs) delve into language instructions with
depth, serving a crucial role in generating plans for intricate tasks. Thus,
LLM-based embodied models further enhance the agent's capacity to comprehend
and process information. However, this amalgamation also ushers in new
challenges in the pursuit of heightened intelligence. Specifically, attackers
can manipulate LLMs to produce irrelevant or even malicious outputs by altering
their prompts. Confronted with this challenge, we observe a notable absence of
multi-modal datasets essential for comprehensively evaluating the robustness of
LLM-based embodied models. Consequently, we construct the Embodied Intelligent
Robot Attack Dataset (EIRAD), tailored specifically for robustness evaluation.
Additionally, two attack strategies are devised, including untargeted attacks
and targeted attacks, to effectively simulate a range of diverse attack
scenarios. At the same time, during the attack process, to more accurately
ascertain whether our method is successful in attacking the LLM-based embodied
model, we devise a new attack success evaluation method utilizing the BLIP2
model. Recognizing the time and cost-intensive nature of the GCG algorithm in
attacks, we devise a scheme for prompt suffix initialization based on various
target tasks, thus expediting the convergence process. Experimental results
demonstrate that our method exhibits a superior attack success rate when
targeting LLM-based embodied models, indicating a lower level of decision-level
robustness in these models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SHMamba: Structured Hyperbolic State Space Model for Audio-Visual
  Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09833v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09833v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhe Yang, Wenrui Li, Guanghui Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Audio-Visual Question Answering (AVQA) task holds significant potential
for applications. Compared to traditional unimodal approaches, the multi-modal
input of AVQA makes feature extraction and fusion processes more challenging.
Euclidean space is difficult to effectively represent multi-dimensional
relationships of data. Especially when extracting and processing data with a
tree structure or hierarchical structure, Euclidean space is not suitable as an
embedding space. Additionally, the self-attention mechanism in Transformers is
effective in capturing the dynamic relationships between elements in a
sequence. However, the self-attention mechanism's limitations in window
modeling and quadratic computational complexity reduce its effectiveness in
modeling long sequences. To address these limitations, we propose SHMamba:
Structured Hyperbolic State Space Model to integrate the advantages of
hyperbolic geometry and state space models. Specifically, SHMamba leverages the
intrinsic properties of hyperbolic space to represent hierarchical structures
and complex relationships in audio-visual data. Meanwhile, the state space
model captures dynamic changes over time by globally modeling the entire
sequence. Furthermore, we introduce an adaptive curvature hyperbolic alignment
module and a cross fusion block to enhance the understanding of hierarchical
structures and the dynamic exchange of cross-modal information, respectively.
Extensive experiments demonstrate that SHMamba outperforms previous methods
with fewer parameters and computational costs. Our learnable parameters are
reduced by 78.12\%, while the average performance improves by 2.53\%.
Experiments show that our method demonstrates superiority among all current
major methods and is more suitable for practical application scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OneDiff: A Generalist Model for Image Difference Captioning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.05645v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.05645v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Erdong Hu, Longteng Guo, Tongtian Yue, Zijia Zhao, Shuning Xue, Jing Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In computer vision, Image Difference Captioning (IDC) is crucial for
accurately describing variations between closely related images. Traditional
IDC methods often rely on specialist models, which restrict their applicability
across varied contexts. This paper introduces the OneDiff model, a novel
generalist approach that utilizes a robust vision-language model architecture,
integrating a siamese image encoder with a Visual Delta Module. This innovative
configuration allows for the precise detection and articulation of fine-grained
differences between image pairs. OneDiff is trained through a dual-phase
strategy, encompassing Coupled Sample Training and multi-task learning across a
diverse array of data types, supported by our newly developed DiffCap Dataset.
This dataset merges real-world and synthetic data, enhancing the training
process and bolstering the model's robustness. Extensive testing on diverse IDC
benchmarks, such as Spot-the-Diff, CLEVR-Change, and Birds-to-Words, shows that
OneDiff consistently outperforms existing state-of-the-art models in accuracy
and adaptability, achieving improvements of up to 85\% CIDEr points in average.
By setting a new benchmark in IDC, OneDiff paves the way for more versatile and
effective applications in detecting and describing visual differences. The
code, models, and data will be made publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multimodal Infusion Tuning for Large Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.05060v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.05060v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Sun, Yu Song, Xinyao Yu, Jiaqing Liu, Yen-Wei Chen, Lanfen Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in large-scale models have showcased remarkable
generalization capabilities in various tasks. However, integrating multimodal
processing into these models presents a significant challenge, as it often
comes with a high computational burden. To address this challenge, we introduce
a new parameter-efficient multimodal tuning strategy for large models in this
paper, referred to as Multimodal Infusion Tuning (MiT). MiT leverages decoupled
self-attention mechanisms within large language models to effectively integrate
information from diverse modalities such as images and acoustics. In MiT, we
also design a novel adaptive rescaling strategy at the attention head level,
which optimizes the representation of infused multimodal features. Notably, all
foundation models are kept frozen during the tuning process to reduce the
computational burden and only 2.5\% parameters are tunable. We conduct
experiments across a range of multimodal tasks, including image-related tasks
like referring segmentation and non-image tasks such as sentiment analysis. Our
results showcase that MiT achieves state-of-the-art performance in multimodal
understanding while significantly reducing computational overhead(10\% of
previous methods). Moreover, our tuned model exhibits robust reasoning
abilities even in complex scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dance Any Beat: Blending Beats with Visuals in Dance Video Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.09266v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.09266v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuanchen Wang, Heng Wang, Dongnan Liu, Weidong Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automated choreography advances by generating dance from music. Current
methods create skeleton keypoint sequences, not full dance videos, and cannot
make specific individuals dance, limiting their real-world use. These methods
also need precise keypoint annotations, making data collection difficult and
restricting the use of self-made video datasets. To overcome these challenges,
we introduce a novel task: generating dance videos directly from images of
individuals guided by music. This task enables the dance generation of specific
individuals without requiring keypoint annotations, making it more versatile
and applicable to various situations. Our solution, the Dance Any Beat
Diffusion model (DabFusion), utilizes a reference image and a music piece to
generate dance videos featuring various dance types and choreographies. The
music is analyzed by our specially designed music encoder, which identifies
essential features including dance style, movement, and rhythm. DabFusion
excels in generating dance videos not only for individuals in the training
dataset but also for any previously unseen person. This versatility stems from
its approach of generating latent optical flow, which contains all necessary
motion information to animate any person in the image. We evaluate DabFusion's
performance using the AIST++ dataset, focusing on video quality, audio-video
synchronization, and motion-music alignment. We propose a 2D Motion-Music
Alignment Score (2D-MM Align), which builds on the Beat Alignment Score to more
effectively evaluate motion-music alignment for this new task. Experiments show
that our DabFusion establishes a solid baseline for this innovative task. Video
results can be found on our project page: https://DabFusion.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 6 figures, demo page: https://DabFusion.github.io</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-07-15T00:00:00Z">2024-07-15</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">14</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pacer and Runner: Cooperative Learning Framework between Single- and
  Cross-Domain Sequential Recommendation <span class="chip">SIGIR'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11245v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11245v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chung Park, Taesan Kim, Hyungjun Yoon, Junui Hong, Yelim Yu, Mincheol Cho, Minsung Choi, Jaegul Choo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-Domain Sequential Recommendation (CDSR) improves recommendation
performance by utilizing information from multiple domains, which contrasts
with Single-Domain Sequential Recommendation (SDSR) that relies on a historical
interaction within a specific domain. However, CDSR may underperform compared
to the SDSR approach in certain domains due to negative transfer, which occurs
when there is a lack of relation between domains or different levels of data
sparsity. To address the issue of negative transfer, our proposed CDSR model
estimates the degree of negative transfer of each domain and adaptively assigns
it as a weight factor to the prediction loss, to control gradient flows through
domains with significant negative transfer. To this end, our model compares the
performance of a model trained on multiple domains (CDSR) with a model trained
solely on the specific domain (SDSR) to evaluate the negative transfer of each
domain using our asymmetric cooperative network. In addition, to facilitate the
transfer of valuable cues between the SDSR and CDSR tasks, we developed an
auxiliary loss that maximizes the mutual information between the representation
pairs from both tasks on a per-domain basis. This cooperative learning between
SDSR and CDSR tasks is similar to the collaborative dynamics between pacers and
runners in a marathon. Our model outperformed numerous previous works in
extensive experiments on two real-world industrial datasets across ten service
domains. We also have deployed our model in the recommendation system of our
personal assistant app service, resulting in 21.4% increase in click-through
rate compared to existing models, which is valuable to real-world business.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGIR'24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluation of RAG Metrics for Question Answering in the Telecom Domain <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12873v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12873v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sujoy Roychowdhury, Sumit Soman, H G Ranjani, Neeraj Gunda, Vansh Chhabra, Sai Krishna Bala
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval Augmented Generation (RAG) is widely used to enable Large Language
Models (LLMs) perform Question Answering (QA) tasks in various domains.
However, RAG based on open-source LLM for specialized domains has challenges of
evaluating generated responses. A popular framework in the literature is the
RAG Assessment (RAGAS), a publicly available library which uses LLMs for
evaluation. One disadvantage of RAGAS is the lack of details of derivation of
numerical value of the evaluation metrics. One of the outcomes of this work is
a modified version of this package for few metrics (faithfulness, context
relevance, answer relevance, answer correctness, answer similarity and factual
correctness) through which we provide the intermediate outputs of the prompts
by using any LLMs. Next, we analyse the expert evaluations of the output of the
modified RAGAS package and observe the challenges of using it in the telecom
domain. We also study the effect of the metrics under correct vs. wrong
retrieval and observe that few of the metrics have higher values for correct
retrieval. We also study for differences in metrics between base embeddings and
those domain adapted via pre-training and fine-tuning. Finally, we comment on
the suitability and challenges of using these metrics for in-the-wild telecom
QA task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication in ICML 2024 Workshop on Foundation Models
  in the Wild</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BiasScanner: Automatic Detection and Classification of News Bias to
  Strengthen Democracy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10829v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10829v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tim Menzner, Jochen L. Leidner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing consumption of news online in the 21st century coincided with
increased publication of disinformation, biased reporting, hate speech and
other unwanted Web content. We describe BiasScanner, an application that aims
to strengthen democracy by supporting news consumers with scrutinizing news
articles they are reading online. BiasScanner contains a server-side
pre-trained large language model to identify biased sentences of news articles
and a front-end Web browser plug-in. At the time of writing, BiasScanner can
identify and classify more than two dozen types of media bias at the sentence
level, making it the most fine-grained model and only deployed application
(automatic system in use) of its kind. It was implemented in a light-weight and
privacy-respecting manner, and in addition to highlighting likely biased
sentence it also provides explanations for each classification decision as well
as a summary analysis for each news article. While prior research has addressed
news bias detection, we are not aware of any work that resulted in a deployed
browser plug-in (c.f. also biasscanner.org for a Web demo).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SEMINAR: Search Enhanced Multi-modal Interest Network and Approximate
  Retrieval for Lifelong Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10714v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10714v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaiming Shen, Xichen Ding, Zixiang Zheng, Yuqi Gong, Qianqian Li, Zhongyi Liu, Guannan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The modeling of users' behaviors is crucial in modern recommendation systems.
A lot of research focuses on modeling users' lifelong sequences, which can be
extremely long and sometimes exceed thousands of items. These models use the
target item to search for the most relevant items from the historical sequence.
However, training lifelong sequences in click through rate (CTR) prediction or
personalized search ranking (PSR) is extremely difficult due to the
insufficient learning problem of ID embedding, especially when the IDs in the
lifelong sequence features do not exist in the samples of training dataset.
Additionally, existing target attention mechanisms struggle to learn the
multi-modal representations of items in the sequence well. The distribution of
multi-modal embedding (text, image and attributes) output of user's interacted
items are not properly aligned and there exist divergence across modalities. We
also observe that users' search query sequences and item browsing sequences can
fully depict users' intents and benefit from each other. To address these
challenges, we propose a unified lifelong multi-modal sequence model called
SEMINAR-Search Enhanced Multi-Modal Interest Network and Approximate Retrieval.
Specifically, a network called Pretraining Search Unit (PSU) learns the
lifelong sequences of multi-modal query-item pairs in a pretraining-finetuning
manner with multiple objectives: multi-modal alignment, next query-item pair
prediction, query-item relevance prediction, etc. After pretraining, the
downstream model restores the pretrained embedding as initialization and
finetunes the network. To accelerate the online retrieval speed of multi-modal
embedding, we propose a multi-modal codebook-based product quantization
strategy to approximate the exact attention calculati
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages,code released</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ $\texttt{MixGR}$: Enhancing Retriever Generalization for Scientific
  Domain through Complementary Granularity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10691v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10691v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fengyu Cai, Xinran Zhao, Tong Chen, Sihao Chen, Hongming Zhang, Iryna Gurevych, Heinz Koeppl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies show the growing significance of document retrieval in the
generation of LLMs, i.e., RAG, within the scientific domain by bridging their
knowledge gap. However, dense retrievers often struggle with domain-specific
retrieval and complex query-document relationships, particularly when query
segments correspond to various parts of a document. To alleviate such prevalent
challenges, this paper introduces $\texttt{MixGR}$, which improves dense
retrievers' awareness of query-document matching across various levels of
granularity in queries and documents using a zero-shot approach.
$\texttt{MixGR}$ fuses various metrics based on these granularities to a united
score that reflects a comprehensive query-document similarity. Our experiments
demonstrate that $\texttt{MixGR}$ outperforms previous document retrieval by
24.7% and 9.8% on nDCG@5 with unsupervised and supervised retrievers,
respectively, averaged on queries containing multiple subqueries from five
scientific retrieval datasets. Moreover, the efficacy of two downstream
scientific question-answering tasks highlights the advantage of
$\texttt{MixGR}$to boost the application of LLMs in the scientific domain.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ General algorithm of assigning raster features to vector maps at any
  resolution or scale 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10599v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10599v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nan Xu, Mark Stevenson, Kerry A. Nice, Sachith Seneviratne
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The fusion of multi-source data is essential for a comprehensive analysis of
geographic applications. Due to distinct data structures, the fusion process
tends to encounter technical difficulties in terms of preservation of the
intactness of each source data. Furthermore, a lack of generalized methods is a
problem when the method is expected to be applicable in multiple resolutions,
sizes, or scales of raster and vector data, to what is being processed. In this
study, we propose a general algorithm of assigning features from raster data
(concentrations of air pollutants) to vector components (roads represented by
edges) in city maps through the iterative construction of virtual layers to
expand geolocation from a city centre to boundaries in a 2D projected map. The
construction follows the rule of perfect squares with a slight difference
depending on the oddness or evenness of the ratio of city size to raster
resolution. We demonstrate the algorithm by applying it to assign accurate
PM$_{2.5}$ and NO$_{2}$ concentrations to roads in 1692 cities globally for a
potential graph-based pollution analysis. This method could pave the way for
agile studies on urgent climate issues by providing a generic and efficient
method to accurately fuse multiple datasets of varying scales and compositions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NTSEBENCH: Cognitive Reasoning Benchmark for Vision Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10380v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10380v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pranshu Pandya, Agney S Talwarr, Vatsal Gupta, Tushar Kataria, Vivek Gupta, Dan Roth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cognitive textual and visual reasoning tasks, such as puzzles, series, and
analogies, demand the ability to quickly reason, decipher, and evaluate
patterns both textually and spatially. While LLMs and VLMs, through extensive
training on large amounts of human-curated data, have attained a high level of
pseudo-human intelligence in some common sense reasoning tasks, they still
struggle with more complex reasoning tasks that require cognitive
understanding. In this work, we introduce a new dataset, NTSEBench, designed to
evaluate the cognitive multi-modal reasoning and problem-solving skills of
large models. The dataset comprises 2,728 multiple-choice questions comprising
of a total of 4,642 images across 26 categories sampled from the NTSE
examination conducted nationwide in India, featuring both visual and textual
general aptitude questions that do not rely on rote learning. We establish
baselines on the dataset using state-of-the-art LLMs and VLMs. To facilitate a
comparison between open source and propriety models, we propose four distinct
modeling strategies to handle different modalities (text and images) in the
dataset instances.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 2 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on
  Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.07103v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.07103v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Jin, Chulin Xie, Jiawei Zhang, Kashob Kumar Roy, Yu Zhang, Zheng Li, Ruirui Li, Xianfeng Tang, Suhang Wang, Yu Meng, Jiawei Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs), while exhibiting exceptional performance,
suffer from hallucinations, especially on knowledge-intensive tasks. Existing
works propose to augment LLMs with individual text units retrieved from
external knowledge corpora to alleviate the issue. However, in many domains,
texts are interconnected (e.g., academic papers in a bibliographic graph are
linked by citations and co-authorships) which form a (text-attributed) graph.
The knowledge in such graphs is encoded not only in single texts/nodes but also
in their associated connections. To facilitate the research of augmenting LLMs
with graphs, we manually construct a Graph Reasoning Benchmark dataset called
GRBench, containing 1,740 questions that can be answered with the knowledge
from 10 domain graphs. Then, we propose a simple and effective framework called
Graph Chain-of-thought (Graph-CoT) to augment LLMs with graphs by encouraging
LLMs to reason on the graph iteratively. Each Graph-CoT iteration consists of
three sub-steps: LLM reasoning, LLM-graph interaction, and graph execution. We
conduct systematic experiments with three LLM backbones on GRBench, where
Graph-CoT outperforms the baselines consistently. The code is available at
https://github.com/PeterGriffinJin/Graph-CoT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages. Code: https://github.com/PeterGriffinJin/Graph-CoT</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Concurrent Robustness of Language Models Across Diverse
  Challenge Sets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.08662v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.08662v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vatsal Gupta, Pranshu Pandya, Tushar Kataria, Vivek Gupta, Dan Roth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models, characterized by their black-box nature, often hallucinate
and display sensitivity to input perturbations, causing concerns about trust.
To enhance trust, it is imperative to gain a comprehensive understanding of the
model's failure modes and develop effective strategies to improve their
performance. In this study, we introduce a methodology designed to examine how
input perturbations affect language models across various scales, including
pre-trained models and large language models (LLMs). Utilizing fine-tuning, we
enhance the model's robustness to input perturbations. Additionally, we
investigate whether exposure to one perturbation enhances or diminishes the
model's performance with respect to other perturbations. To address robustness
against multiple perturbations, we present three distinct fine-tuning
strategies. Furthermore, we broaden the scope of our methodology to encompass
large language models (LLMs) by leveraging a chain of thought (CoT) prompting
approach augmented with exemplars. We employ the Tabular-NLI task to showcase
how our proposed strategies adeptly train a robust model, enabling it to
address diverse perturbations while maintaining accuracy on the original
dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 16 Figure, 10 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scaling Laws For Dense Retrieval <span class="chip">SIGIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.18684v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.18684v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Fang, Jingtao Zhan, Qingyao Ai, Jiaxin Mao, Weihang Su, Jia Chen, Yiqun Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scaling up neural models has yielded significant advancements in a wide array
of tasks, particularly in language generation. Previous studies have found that
the performance of neural models frequently adheres to predictable scaling
laws, correlated with factors such as training set size and model size. This
insight is invaluable, especially as large-scale experiments grow increasingly
resource-intensive. Yet, such scaling law has not been fully explored in dense
retrieval due to the discrete nature of retrieval metrics and complex
relationships between training data and model sizes in retrieval tasks. In this
study, we investigate whether the performance of dense retrieval models follows
the scaling law as other neural models. We propose to use contrastive
log-likelihood as the evaluation metric and conduct extensive experiments with
dense retrieval models implemented with different numbers of parameters and
trained with different amounts of annotated data. Results indicate that, under
our settings, the performance of dense retrieval models follows a precise
power-law scaling related to the model size and the number of annotations.
Additionally, we examine scaling with prevalent data augmentation methods to
assess the impact of annotation quality, and apply the scaling law to find the
best resource allocation strategy under a budget constraint. We believe that
these insights will significantly contribute to understanding the scaling
effect of dense retrieval models and offer meaningful guidance for future
research endeavors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGIR 2024. V2 fixes a bug in the experiments</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing HNSW Index for Real-Time Updates: Addressing Unreachable
  Points and Performance Degradation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07871v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07871v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wentao Xiao, Yueyang Zhan, Rui Xi, Mengshu Hou, Jianming Liao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The approximate nearest neighbor search (ANNS) is a fundamental and essential
component in data mining and information retrieval, with graph-based
methodologies demonstrating superior performance compared to alternative
approaches. Extensive research efforts have been dedicated to improving search
efficiency by developing various graph-based indices, such as HNSW
(Hierarchical Navigable Small World). However, the performance of HNSW and most
graph-based indices become unacceptable when faced with a large number of
real-time deletions, insertions, and updates. Furthermore, during update
operations, HNSW can result in some data points becoming unreachable, a
situation we refer to as the `unreachable points phenomenon'. This phenomenon
could significantly affect the search accuracy of the graph in certain
situations.
  To address these issues, we present efficient measures to overcome the
shortcomings of HNSW, specifically addressing poor performance over long
periods of delete and update operations and resolving the issues caused by the
unreachable points phenomenon. Our proposed MN-RU algorithm effectively
improves update efficiency and suppresses the growth rate of unreachable
points, ensuring better overall performance and maintaining the integrity of
the graph. Our results demonstrate that our methods outperform existing
approaches. Furthermore, since our methods are based on HNSW, they can be
easily integrated with existing indices widely used in the industrial field,
making them practical for future real-world applications. Code is available at
\url{https://github.com/xwt1/MN-RU.git}
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Roadmap to Pluralistic Alignment <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.05070v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.05070v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taylor Sorensen, Jared Moore, Jillian Fisher, Mitchell Gordon, Niloofar Mireshghallah, Christopher Michael Rytting, Andre Ye, Liwei Jiang, Ximing Lu, Nouha Dziri, Tim Althoff, Yejin Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With increased power and prevalence of AI systems, it is ever more critical
that AI systems are designed to serve all, i.e., people with diverse values and
perspectives. However, aligning models to serve pluralistic human values
remains an open research question. In this piece, we propose a roadmap to
pluralistic alignment, specifically using language models as a test bed. We
identify and formalize three possible ways to define and operationalize
pluralism in AI systems: 1) Overton pluralistic models that present a spectrum
of reasonable responses; 2) Steerably pluralistic models that can steer to
reflect certain perspectives; and 3) Distributionally pluralistic models that
are well-calibrated to a given population in distribution. We also formalize
and discuss three possible classes of pluralistic benchmarks: 1)
Multi-objective benchmarks, 2) Trade-off steerable benchmarks, which
incentivize models to steer to arbitrary trade-offs, and 3) Jury-pluralistic
benchmarks which explicitly model diverse human ratings. We use this framework
to argue that current alignment techniques may be fundamentally limited for
pluralistic AI; indeed, we highlight empirical evidence, both from our own
experiments and from other work, that standard alignment procedures might
reduce distributional pluralism in models, motivating the need for further
research on pluralistic alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CWRCzech: 100M Query-Document Czech Click <span class="highlight-title">Dataset</span> and Its Application to
  Web Relevance Ranking <span class="chip">SIGIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.20994v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.20994v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Josef Vonášek, Milan Straka, Rostislav Krč, Lenka Lasoňová, Ekaterina Egorova, Jana Straková, Jakub Náplava
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present CWRCzech, Click Web Ranking dataset for Czech, a 100M
query-document Czech click dataset for relevance ranking with user behavior
data collected from search engine logs of Seznam$.$cz. To the best of our
knowledge, CWRCzech is the largest click dataset with raw text published so
far. It provides document positions in the search results as well as
information about user behavior: 27.6M clicked documents and 10.8M dwell times.
In addition, we also publish a manually annotated Czech test for the relevance
task, containing nearly 50k query-document pairs, each annotated by at least 2
annotators. Finally, we analyze how the user behavior data improve relevance
ranking and show that models trained on data automatically harnessed at
sufficient scale can surpass the performance of models trained on human
annotated data. CWRCzech is published under an academic non-commercial license
and is available to the research community at
https://github.com/seznam/CWRCzech.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to SIGIR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Uncertainty Calibration for Counterfactual Propensity Estimation in
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.12973v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.12973v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenbo Hu, Xin Sun, Qiang liu, Le Wu, Liang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Post-click conversion rate (CVR) is a reliable indicator of online customers'
preferences, making it crucial for developing recommender systems. A major
challenge in predicting CVR is severe selection bias, arising from users'
inherent self-selection behavior and the system's item selection process. To
mitigate this issue, the inverse propensity score (IPS) is employed to weight
the prediction error of each observed instance. However, current propensity
score estimations are unreliable due to the lack of a quality measure. To
address this, we evaluate the quality of propensity scores from the perspective
of uncertainty calibration, proposing the use of expected calibration error
(ECE) as a measure of propensity-score quality. We argue that the performance
of IPS-based recommendations is hampered by miscalibration in propensity
estimation. We introduce a model-agnostic calibration framework for
propensity-based debiasing of CVR predictions. Theoretical analysis on bias and
generalization bounds demonstrates the superiority of calibrated propensity
estimates over uncalibrated ones. Experiments conducted on the Coat, Yahoo and
KuaiRand datasets show improved uncertainty calibration, as evidenced by lower
ECE values, leading to enhanced CVR prediction outcomes.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">5</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ When Synthetic Traces Hide Real Content: Analysis of Stable Diffusion
  Image Laundering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10736v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10736v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sara Mandelli, Paolo Bestagini, Stefano Tubaro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, methods for producing highly realistic synthetic images have
significantly advanced, allowing the creation of high-quality images from text
prompts that describe the desired content. Even more impressively, Stable
Diffusion (SD) models now provide users with the option of creating synthetic
images in an image-to-image translation fashion, modifying images in the latent
space of advanced autoencoders. This striking evolution, however, brings an
alarming consequence: it is possible to pass an image through SD autoencoders
to reproduce a synthetic copy of the image with high realism and almost no
visual artifacts. This process, known as SD image laundering, can transform
real images into lookalike synthetic ones and risks complicating forensic
analysis for content authenticity verification. Our paper investigates the
forensic implications of image laundering, revealing a serious potential to
obscure traces of real content, including sensitive and harmful materials that
could be mistakenly classified as synthetic, thereby undermining the protection
of individuals depicted. To address this issue, we propose a two-stage
detection pipeline that effectively differentiates between pristine, laundered,
and fully synthetic images (those generated from text prompts), showing
robustness across various conditions. Finally, we highlight another alarming
property of image laundering, which appears to mask the unique artifacts
exploited by forensic detectors to solve the camera model identification task,
strongly undermining their performance. Our experimental code is available at
https://github.com/polimi-ispl/synthetic-image-detection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-source Knowledge Enhanced Graph Attention Networks for Multimodal
  Fact Verification <span class="chip">ICME 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10474v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10474v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Cao, Lingwei Wei, Wei Zhou, Songlin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal fact verification is an under-explored and emerging field that has
gained increasing attention in recent years. The goal is to assess the veracity
of claims that involve multiple modalities by analyzing the retrieved evidence.
The main challenge in this area is to effectively fuse features from different
modalities to learn meaningful multimodal representations. To this end, we
propose a novel model named Multi-Source Knowledge-enhanced Graph Attention
Network (MultiKE-GAT). MultiKE-GAT introduces external multimodal knowledge
from different sources and constructs a heterogeneous graph to capture complex
cross-modal and cross-source interactions. We exploit a Knowledge-aware Graph
Fusion (KGF) module to learn knowledge-enhanced representations for each claim
and evidence and eliminate inconsistencies and noises introduced by redundant
entities. Experiments on two public benchmark datasets demonstrate that our
model outperforms other comparison methods, showing the effectiveness and
superiority of the proposed model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICME 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BandControlNet: Parallel <span class="highlight-title">Transformer</span>s-based Steerable Popular Music
  Generation with Fine-Grained Spatiotemporal Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10462v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10462v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jing Luo, Xinyu Yang, Dorien Herremans
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controllable music generation promotes the interaction between humans and
composition systems by projecting the users' intent on their desired music. The
challenge of introducing controllability is an increasingly important issue in
the symbolic music generation field. When building controllable generative
popular multi-instrument music systems, two main challenges typically present
themselves, namely weak controllability and poor music quality. To address
these issues, we first propose spatiotemporal features as powerful and
fine-grained controls to enhance the controllability of the generative model.
In addition, an efficient music representation called REMI_Track is designed to
convert multitrack music into multiple parallel music sequences and shorten the
sequence length of each track with Byte Pair Encoding (BPE) techniques.
Subsequently, we release BandControlNet, a conditional model based on parallel
Transformers, to tackle the multiple music sequences and generate high-quality
music samples that are conditioned to the given spatiotemporal control
features. More concretely, the two specially designed modules of
BandControlNet, namely structure-enhanced self-attention (SE-SA) and
Cross-Track Transformer (CTT), are utilized to strengthen the resulting musical
structure and inter-track harmony modeling respectively. Experimental results
tested on two popular music datasets of different lengths demonstrate that the
proposed BandControlNet outperforms other conditional music generation models
on most objective metrics in terms of fidelity and inference speed and shows
great robustness in generating long music samples. The subjective evaluations
show BandControlNet trained on short datasets can generate music with
comparable quality to state-of-the-art models, while outperforming them
significantly using longer datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Demo page: https://chinglohsiu.github.io/files/bandcontrolnet.html</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Avalanche of Images on Telegram Preceded Russia's Full-Scale Invasion
  of Ukraine 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.14947v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.14947v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        William Theisen, Michael Yankoski, Kristina Hook, Ernesto Verdeja, Walter Scheirer, Tim Weninger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Governments use propaganda, including through visual content -- or
Politically Salient Image Patterns (PSIP) -- on social media, to influence and
manipulate public opinion. In the present work, we collected Telegram
post-history of from 989 Russian milbloggers to better understand the social
and political narratives that circulated online in the months surrounding
Russia's 2022 full-scale invasion of Ukraine. Overall, we found an 8,925%
increase (p<0.001) in the number of posts and a 5,352% increase (p<0.001) in
the number of images posted by these accounts in the two weeks prior to the
invasion. We also observed a similar increase in the number and intensity of
politically salient manipulated images that circulated on Telegram. Although
this paper does not evaluate malice or coordination in these activities, we do
conclude with a call for further research into the role that manipulated visual
media has in the lead-up to instability events and armed conflict.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ALMol: Aligned Language-Molecule Translation LLMs through Offline
  Preference Contrastive Optimisation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.08619v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.08619v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dimitris Gkoumas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The field of chemistry and Artificial Intelligence (AI) intersection is an
area of active research that aims to accelerate scientific discovery. The
integration of large language models (LLMs) with scientific modalities has
shown significant promise in this endeavour. However, challenges persist in
effectively addressing training efficacy and the out-of-distribution problem,
particularly as existing approaches rely on larger models and datasets. In this
context, we focus on machine language-molecule translation and deploy a novel
training approach called contrastive preference optimisation, which avoids
generating translations that are merely adequate but not perfect. To ensure
generalisability and mitigate memorisation effects, we conduct experiments
using only 10% of the data. Our results demonstrate that our models achieve up
to a 32% improvement compared to counterpart models. Finally, we introduce a
fine-grained, domain-agnostic evaluation method to assess hallucination in LLMs
and promote responsible use.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-07-14T00:00:00Z">2024-07-14</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">10</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Numbers Matter! Bringing Quantity-awareness to Retrieval Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10283v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10283v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Satya Almasian, Milena Bruseva, Michael Gertz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Quantitative information plays a crucial role in understanding and
interpreting the content of documents. Many user queries contain quantities and
cannot be resolved without understanding their semantics, e.g., ``car that
costs less than $10k''. Yet, modern search engines apply the same ranking
mechanisms for both words and quantities, overlooking magnitude and unit
information. In this paper, we introduce two quantity-aware ranking techniques
designed to rank both the quantity and textual content either jointly or
independently. These techniques incorporate quantity information in available
retrieval systems and can address queries with numerical conditions equal,
greater than, and less than. To evaluate the effectiveness of our proposed
models, we introduce two novel quantity-aware benchmark datasets in the domains
of finance and medicine and compare our method against various lexical and
neural models. The code and data are available under
https://github.com/satya77/QuantityAwareRankers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GenSco: Can Question Decomposition based Passage Alignment improve
  Question Answering? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10245v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10245v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Barah Fazili, Koustava Goswami, Natwar Modani, Inderjeet Nair
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval augmented generation (RAG) with large language models (LLMs) for
Question Answering (QA) entails furnishing relevant context within the prompt
to facilitate the LLM in answer generation. During the generation, inaccuracies
or hallucinations frequently occur due to two primary factors: inadequate or
distracting context in the prompts, and the inability of LLMs to effectively
reason through the facts. In this paper, we investigate whether providing
aligned context via a carefully selected passage sequence leads to better
answer generation by the LLM for multi-hop QA. We introduce, "GenSco", a novel
approach of selecting passages based on the predicted decomposition of the
multi-hop questions}. The framework consists of two distinct LLMs: (i)
Generator LLM, which is used for question decomposition and final answer
generation; (ii) an auxiliary open-sourced LLM, used as the scorer, to
semantically guide the Generator for passage selection. The generator is
invoked only once for the answer generation, resulting in a cost-effective and
efficient approach. We evaluate on three broadly established multi-hop question
answering datasets: 2WikiMultiHop, Adversarial HotPotQA and MuSiQue and achieve
an absolute gain of $15.1$ and $5.9$ points in Exact Match score with respect
to the best performing baselines over MuSiQue and 2WikiMultiHop respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Robust Recommendation via Decision Boundary-aware Graph
  Contrastive Learning <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10184v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10184v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiakai Tang, Sunhao Dai, Zexu Sun, Xu Chen, Jun Xu, Wenhui Yu, Lantao Hu, Peng Jiang, Han Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, graph contrastive learning (GCL) has received increasing
attention in recommender systems due to its effectiveness in reducing bias
caused by data sparsity. However, most existing GCL models rely on heuristic
approaches and usually assume entity independence when constructing contrastive
views. We argue that these methods struggle to strike a balance between
semantic invariance and view hardness across the dynamic training process, both
of which are critical factors in graph contrastive learning.
  To address the above issues, we propose a novel GCL-based recommendation
framework RGCL, which effectively maintains the semantic invariance of
contrastive pairs and dynamically adapts as the model capability evolves
through the training process. Specifically, RGCL first introduces decision
boundary-aware adversarial perturbations to constrain the exploration space of
contrastive augmented views, avoiding the decrease of task-specific
information. Furthermore, to incorporate global user-user and item-item
collaboration relationships for guiding on the generation of hard contrastive
views, we propose an adversarial-contrastive learning objective to construct a
relation-aware view-generator. Besides, considering that unsupervised GCL could
potentially narrower margins between data points and the decision boundary,
resulting in decreased model robustness, we introduce the adversarial examples
based on maximum perturbations to achieve margin maximization. We also provide
theoretical analyses on the effectiveness of our designs. Through extensive
experiments on five public datasets, we demonstrate the superiority of RGCL
compared against twelve baseline models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>KDD 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Bag of Tricks for Scaling CPU-based Deep FFMs to more than 300m
  Predictions per Second <span class="chip">KDD2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10115v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10115v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Blaž Škrlj, Benjamin Ben-Shalom, Grega Gašperšič, Adi Schwartz, Ramzi Hoseisi, Naama Ziporin, Davorin Kopič, Andraž Tori
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Field-aware Factorization Machines (FFMs) have emerged as a powerful model
for click-through rate prediction, particularly excelling in capturing complex
feature interactions. In this work, we present an in-depth analysis of our
in-house, Rust-based Deep FFM implementation, and detail its deployment on a
CPU-only, multi-data-center scale. We overview key optimizations devised for
both training and inference, demonstrated by previously unpublished benchmark
results in efficient model search and online training. Further, we detail an
in-house weight quantization that resulted in more than an order of magnitude
reduction in bandwidth footprint related to weight transfers across
data-centres. We disclose the engine and associated techniques under an
open-source license to contribute to the broader machine learning community.
This paper showcases one of the first successful CPU-only deployments of Deep
FFMs at such scale, marking a significant stride in practical, low-footprint
click-through rate prediction methodologies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6p, KDD2024 - AdKDD workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Warming Up Cold-Start CTR Prediction by Learning Item-Specific Feature
  Interactions <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10112v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10112v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaqing Wang, Hongming Piao, Daxiang Dong, Quanming Yao, Jingbo Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recommendation systems, new items are continuously introduced, initially
lacking interaction records but gradually accumulating them over time.
Accurately predicting the click-through rate (CTR) for these items is crucial
for enhancing both revenue and user experience. While existing methods focus on
enhancing item ID embeddings for new items within general CTR models, they tend
to adopt a global feature interaction approach, often overshadowing new items
with sparse data by those with abundant interactions. Addressing this, our work
introduces EmerG, a novel approach that warms up cold-start CTR prediction by
learning item-specific feature interaction patterns. EmerG utilizes
hypernetworks to generate an item-specific feature graph based on item
characteristics, which is then processed by a Graph Neural Network (GNN). This
GNN is specially tailored to provably capture feature interactions at any order
through a customized message passing mechanism. We further design a meta
learning strategy that optimizes parameters of hypernetworks and GNN across
various item CTR prediction tasks, while only adjusting a minimal set of
item-specific parameters within each task. This strategy effectively reduces
the risk of overfitting when dealing with limited data. Extensive experiments
on benchmark datasets validate that EmerG consistently performs the best given
no, a few and sufficient instances of new items.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>KDD 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ All Roads Lead to Rome: Unveiling the Trajectory of Recommender Systems
  Across the LLM Era 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10081v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10081v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bo Chen, Xinyi Dai, Huifeng Guo, Wei Guo, Weiwen Liu, Yong Liu, Jiarui Qin, Ruiming Tang, Yichao Wang, Chuhan Wu, Yaxiong Wu, Hao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems (RS) are vital for managing information overload and
delivering personalized content, responding to users' diverse information
needs. The emergence of large language models (LLMs) offers a new horizon for
redefining recommender systems with vast general knowledge and reasoning
capabilities. Standing across this LLM era, we aim to integrate recommender
systems into a broader picture, and pave the way for more comprehensive
solutions for future research. Therefore, we first offer a comprehensive
overview of the technical progression of recommender systems, particularly
focusing on language foundation models and their applications in
recommendation. We identify two evolution paths of modern recommender systems
-- via list-wise recommendation and conversational recommendation. These two
paths finally converge at LLM agents with superior capabilities of long-term
memory, reflection, and tool intelligence. Along these two paths, we point out
that the information effectiveness of the recommendation is increased, while
the user's acquisition cost is decreased. Technical features, research
methodologies, and inherent challenges for each milestone along the path are
carefully investigated -- from traditional list-wise recommendation to
LLM-enhanced recommendation to recommendation with LLM agents. Finally, we
highlight several unresolved challenges crucial for the development of future
personalization technologies and interfaces and discuss the future prospects.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semantic Understanding and Data Imputation using Large Language Model to
  Accelerate Recommendation System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10078v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10078v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhicheng Ding, Jiahao Tian, Zhenkai Wang, Jinman Zhao, Siyang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper aims to address the challenge of sparse and missing data in
recommendation systems, a significant hurdle in the age of big data.
Traditional imputation methods struggle to capture complex relationships within
the data. We propose a novel approach that fine-tune Large Language Model (LLM)
and use it impute missing data for recommendation systems. LLM which is trained
on vast amounts of text, is able to understand complex relationship among data
and intelligently fill in missing information. This enriched data is then used
by the recommendation system to generate more accurate and personalized
suggestions, ultimately enhancing the user experience. We evaluate our
LLM-based imputation method across various tasks within the recommendation
system domain, including single classification, multi-classification, and
regression compared to traditional data imputation methods. By demonstrating
the superiority of LLM imputation over traditional methods, we establish its
potential for improving recommendation system performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Harnessing Feature Clustering For Enhanced Anomaly Detection With
  Variational Autoencoder And Dynamic Threshold 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10042v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10042v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tolulope Ale, Nicole-Jeanne Schlegel, Vandana P. Janeja
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce an anomaly detection method for multivariate time series data
with the aim of identifying critical periods and features influencing extreme
climate events like snowmelt in the Arctic. This method leverages the
Variational Autoencoder (VAE) integrated with dynamic thresholding and
correlation-based feature clustering. This framework enhances the VAE's ability
to identify localized dependencies and learn the temporal relationships in
climate data, thereby improving the detection of anomalies as demonstrated by
its higher F1-score on benchmark datasets. The study's main contributions
include the development of a robust anomaly detection method, improving feature
representation within VAEs through clustering, and creating a dynamic threshold
algorithm for localized anomaly detection. This method offers explainability of
climate anomalies across different regions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work was presented at the 2024 IEEE International Geoscience and
  Remote Sensing Symposium, IGARSS 2024, 07-12 July 2024, Athens, Greece</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Empowering Chat<span class="highlight-title">GPT</span>-Like Large-Scale Language Models with Local Knowledge
  Base for Industrial Prognostics and Health Management 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.14945v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.14945v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huan Wang, Yan-Fu Li, Min Xie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prognostics and health management (PHM) is essential for industrial operation
and maintenance, focusing on predicting, diagnosing, and managing the health
status of industrial systems. The emergence of the ChatGPT-Like large-scale
language model (LLM) has begun to lead a new round of innovation in the AI
field. It has extensively promoted the level of intelligence in various fields.
Therefore, it is also expected further to change the application paradigm in
industrial PHM and promote PHM to become intelligent. Although ChatGPT-Like
LLMs have rich knowledge reserves and powerful language understanding and
generation capabilities, they lack domain-specific expertise, significantly
limiting their practicability in PHM applications. To this end, this study
explores the ChatGPT-Like LLM empowered by the local knowledge base (LKB) in
industrial PHM to solve the above limitations. In addition, we introduce the
method and steps of combining the LKB with LLMs, including LKB preparation, LKB
vectorization, prompt engineering, etc. Experimental analysis of real cases
shows that combining the LKB with ChatGPT-Like LLM can significantly improve
its performance and make ChatGPT-Like LLMs more accurate, relevant, and able to
provide more insightful information. This can promote the development of
ChatGPT-Like LLMs in industrial PHM and promote their efficiency and quality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLM-Assisted Multi-Teacher Continual Learning for Visual Question
  Answering in Robotic Surgery <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.16664v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.16664v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuyang Du, Kexin Chen, Yue Zhan, Chang Han Low, Tao You, Mobarakol Islam, Ziyu Guo, Yueming Jin, Guangyong Chen, Pheng-Ann Heng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual question answering (VQA) is crucial for promoting surgical education.
In practice, the needs of trainees are constantly evolving, such as learning
more surgical types, adapting to different robots, and learning new surgical
instruments and techniques for various surgeries. However, patient data privacy
often restricts the availability of old data when updating the model,
necessitating an exemplar-free continual learning (CL) setup. Prior CL studies
overlooked two vital problems in the surgical domain: 1) large domain shifts
from diverse surgical operations collected from multiple sources, and 2) severe
data imbalance arising from the uneven presence of surgical instruments or
activities. This paper proposes addressing these problems with a multimodal
large language model (LLM) and an adaptive weight assignment methodology. We
first develop a new multi-teacher CL framework that leverages a multimodal LLM
as the additional teacher. The strong generalization ability of the LLM can
bridge the knowledge gap when domain shifts and data imbalances occur. We then
put forth a novel data processing method that transforms complex LLM embeddings
into logits compatible with our CL framework. We further design an adaptive
weight assignment approach that balances the generalization ability of the LLM
and the domain expertise of the old CL model. Finally, to comprehensively test
the effectiveness of our proposed method, we have also constructed two new
surgical VQA datasets that are largely different from existing ones and could
be valuable resources for future research. Extensive experimental results on
the tested datasets demonstrate the superiority of our method to other advanced
CL schemes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accapted by 2024 IEEE International Conference on
  Robotics and Automation (ICRA)</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-07-13T00:00:00Z">2024-07-13</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">4</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Causality extraction from medical text using Large Language Models
  (LLMs) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10020v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10020v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seethalakshmi Gopalakrishnan, Luciana Garbayo, Wlodek Zadrozny
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study explores the potential of natural language models, including large
language models, to extract causal relations from medical texts, specifically
from Clinical Practice Guidelines (CPGs). The outcomes causality extraction
from Clinical Practice Guidelines for gestational diabetes are presented,
marking a first in the field. We report on a set of experiments using variants
of BERT (BioBERT, DistilBERT, and BERT) and using Large Language Models (LLMs),
namely GPT-4 and LLAMA2. Our experiments show that BioBERT performed better
than other models, including the Large Language Models, with an average
F1-score of 0.72. GPT-4 and LLAMA2 results show similar performance but less
consistency. We also release the code and an annotated a corpus of causal
statements within the Clinical Practice Guidelines for gestational diabetes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Correlating Power Outage Spread with Infrastructure Interdependencies
  During Hurricanes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09962v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09962v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Avishek Bose, Sangkeun Lee, Narayan Bhusal, Supriya Chinthavali
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Power outages caused by extreme weather events, such as hurricanes, can
significantly disrupt essential services and delay recovery efforts,
underscoring the importance of enhancing our infrastructure's resilience. This
study investigates the spread of power outages during hurricanes by analyzing
the correlation between the network of critical infrastructure and outage
propagation. We leveraged datasets from Hurricanemapping.com, the North
American Energy Resilience Model Interdependency Analysis (NAERM-IA), and
historical power outage data from the Oak Ridge National Laboratory (ORNL)'s
EAGLE-I system. Our analysis reveals a consistent positive correlation between
the extent of critical infrastructure components accessible within a certain
number of steps (k-hop distance) from initial impact areas and the occurrence
of power outages in broader regions. This insight suggests that understanding
the interconnectedness among critical infrastructure elements is key to
identifying areas indirectly affected by extreme weather events.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE 25th International Conference on Information Reuse and
  Integration for Data Science (IEEE IRI-2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Popular News Always Compete for the User's Attention! POPK: Mitigating
  Popularity Bias via a Temporal-Counterfactual 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09939v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09939v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Igor L. R. Azevedo, Toyotaro Suzumura, Yuichiro Yasui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In news recommendation systems, reducing popularity bias is essential for
delivering accurate and diverse recommendations. This paper presents POPK, a
new method that uses temporal-counterfactual analysis to mitigate the influence
of popular news articles. By asking, "What if, at a given time $t$, a set of
popular news articles were competing for the user's attention to be clicked?",
POPK aims to improve recommendation accuracy and diversity. We tested POPK on
three different language datasets (Japanese, English, and Norwegian) and found
that it successfully enhances traditional methods. POPK offers flexibility for
customization to enhance either accuracy or diversity, alongside providing
distinct ways of measuring popularity. We argue that popular news articles
always compete for attention, even if they are not explicitly present in the
user's impression list. POPK systematically eliminates the implicit influence
of popular news articles during each training step. We combine counterfactual
reasoning with a temporal approach to adjust the negative sample space,
refining understanding of user interests. Our findings underscore how POPK
effectively enhances the accuracy and diversity of recommended articles while
also tailoring the approach to specific needs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SocialRec: User Activity Based Post Weighted Dynamic Personalized Post
  Recommendation System in Social Media 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09747v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09747v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ismail Hossain, Sai Puppala, Md Jahangir Alam, Sajedul Talukder
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  User activities can influence their subsequent interactions with a post,
generating interest in the user. Typically, users interact with posts from
friends by commenting and using reaction emojis, reflecting their level of
interest on social media such as Facebook, Twitter, and Reddit. Our objective
is to analyze user history over time, including their posts and engagement on
various topics. Additionally, we take into account the user's profile, seeking
connections between their activities and social media platforms. By integrating
user history, engagement, and persona, we aim to assess recommendation scores
based on relevant item sharing by Hit Rate (HR) and the quality of the ranking
system by Normalized Discounted Cumulative Gain (NDCG), where we achieve the
highest for NeuMF 0.80 and 0.6 respectively. Our hybrid approach solves the
cold-start problem when there is a new user, for new items cold-start problem
will never occur, as we consider the post category values. To improve the
performance of the model during cold-start we introduce collaborative filtering
by looking for similar users and ranking the users based on the highest
similarity scores.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This research paper has been accepted in the Social Media Sway:
  Unraveling the Impact of Social Media on Human Behavior - SMS workshop, to be
  held in conjunction with the International Conference on Social Networks
  Analysis and Mining (ASONAM 2024) and will be published in Springer</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">6</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TOP:A New Target-Audience Oriented Content Paraphrase Task 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09992v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09992v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boda Lin, Jiaxin Shi, Haolong Yan, Binghao Tang, Xiaocheng Gong, Si Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommendation systems usually recommend the existing contents to different
users. However, in comparison to static recommendation methods, a
recommendation logic that dynamically adjusts based on user interest
preferences may potentially attract a larger user base. Thus, we consider
paraphrasing existing content based on the interests of the users to modify the
content to better align with the preferences of users. In this paper, we
propose a new task named Target-Audience Oriented Content Paraphrase aims to
generate more customized contents for the target audience. We introduce the
task definition and the corresponding framework for the proposed task and the
creation of the corresponding datasets. We utilize the Large Language Models
(LLMs) and Large Vision Models (LVMs) to accomplish the base implementation of
the TOP framework and provide the referential baseline results for the proposed
task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LeRF: Learning Resampling Function for Adaptive and Efficient Image
  Interpolation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09935v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09935v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiacheng Li, Chang Chen, Fenglong Song, Youliang Yan, Zhiwei Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image resampling is a basic technique that is widely employed in daily
applications, such as camera photo editing. Recent deep neural networks (DNNs)
have made impressive progress in performance by introducing learned data
priors. Still, these methods are not the perfect substitute for interpolation,
due to the drawbacks in efficiency and versatility. In this work, we propose a
novel method of Learning Resampling Function (termed LeRF), which takes
advantage of both the structural priors learned by DNNs and the locally
continuous assumption of interpolation. Specifically, LeRF assigns spatially
varying resampling functions to input image pixels and learns to predict the
hyper-parameters that determine the shapes of these resampling functions with a
neural network. Based on the formulation of LeRF, we develop a family of
models, including both efficiency-orientated and performance-orientated ones.
To achieve interpolation-level efficiency, we adopt look-up tables (LUTs) to
accelerate the inference of the learned neural network. Furthermore, we design
a directional ensemble strategy and edge-sensitive indexing patterns to better
capture local structures. On the other hand, to obtain DNN-level performance,
we propose an extension of LeRF to enable it in cooperation with pre-trained
upsampling models for cascaded resampling. Extensive experiments show that the
efficiency-orientated version of LeRF runs as fast as interpolation,
generalizes well to arbitrary transformations, and outperforms interpolation
significantly, e.g., up to 3dB PSNR gain over Bicubic for x2 upsampling on
Manga109. Besides, the performance-orientated version of LeRF reaches
comparable performance with existing DNNs at much higher efficiency, e.g., less
than 25% running time on a desktop GPU.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code: https://github.com/ddlee-cn/LeRF-PyTorch</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IoT-LM: Large Multisensory Language Models for the Internet of Things 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09801v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09801v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shentong Mo, Russ Salakhutdinov, Louis-Philippe Morency, Paul Pu Liang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Internet of Things (IoT) network integrating billions of smart physical
devices embedded with sensors, software, and communication technologies is a
critical and rapidly expanding component of our modern world. The IoT ecosystem
provides a rich source of real-world modalities such as motion, thermal,
geolocation, imaging, depth, sensors, and audio to recognize the states of
humans and physical objects. Machine learning presents a rich opportunity to
automatically process IoT data at scale, enabling efficient inference for
understanding human wellbeing, controlling physical devices, and
interconnecting smart cities. To realize this potential, we introduce IoT-LM,
an open-source large multisensory language model tailored for the IoT
ecosystem. IoT-LM is enabled by two technical contributions: the first is
MultiIoT, the most expansive unified IoT dataset to date, encompassing over
1.15 million samples from 12 modalities and 8 tasks prepared for multisensory
pre-training and instruction-tuning. The second is a new multisensory multitask
adapter layer to condition pre-trained large language models on multisensory
IoT data. Not only does IoT-LM yield substantial improvements on 8 supervised
IoT classification tasks, but it also demonstrates new interactive
question-answering, reasoning, and dialog capabilities conditioned on IoT
sensors. We release IoT-LM's data sources and new multisensory language
modeling framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2311.06217</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TemporalStory: Enhancing Consistency in Story Visualization using
  Spatial-Temporal Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09774v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09774v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sixiao Zheng, Yanwei Fu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Story visualization presents a challenging task in text-to-image generation,
requiring not only the rendering of visual details from text prompt but also
ensuring consistency across images. Recently, most approaches address
inconsistency problem using an auto-regressive manner conditioned on previous
image-sentence pairs. However, they overlook the fact that story context is
dispersed across all sentences. The auto-regressive approach fails to encode
information from susequent image-sentence pairs, thus unable to capture the
entirety of the story context. To address this, we introduce TemporalStory,
leveraging Spatial-Temporal attention to model complex spatial and temporal
dependencies in images, enabling the generation of coherent images based on a
given storyline. In order to better understand the storyline context, we
introduce a text adapter capable of integrating information from other
sentences into the embedding of the current sentence. Additionally, to utilize
scene changes between story images as guidance for the model, we propose the
StoryFlow Adapter to measure the degree of change between images. Through
extensive experiments on two popular benchmarks, PororoSV and FlintstonesSV,
our TemporalStory outperforms the previous state-of-the-art in both story
visualization and story continuation tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ User Digital Twin-Driven Video Streaming for Customized Preferences and
  Adaptive Transcoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09766v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09766v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Stephen Jimmy, Kalkidan Berhane, Kevin Muhammad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the rapidly evolving field of multimedia services, video streaming has
become increasingly prevalent, demanding innovative solutions to enhance user
experience and system efficiency. This paper introduces a novel approach that
integrates user digital twins-a dynamic digital representation of a user's
preferences and behaviors-with traditional video streaming systems. We explore
the potential of this integration to dynamically adjust video preferences and
optimize transcoding processes according to real-time data. The methodology
leverages advanced machine learning algorithms to continuously update the
user's digital twin, which in turn informs the transcoding service to adapt
video parameters for optimal quality and minimal buffering. Experimental
results show that our approach not only improves the personalization of content
delivery but also significantly enhances the overall efficiency of video
streaming services by reducing bandwidth usage and improving video playback
quality. The implications of such advancements suggest a shift towards more
adaptive, user-centric multimedia services, potentially transforming how video
content is consumed and delivered.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Speech Enhancement by Integrating Inter-Channel and Band
  Features with Dual-branch Conformer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06524v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06524v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jizhen Li, Xinmeng Xu, Weiping Tu, Yuhong Yang, Rong Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent speech enhancement methods based on convolutional neural networks
(CNNs) and transformer have been demonstrated to efficaciously capture
time-frequency (T-F) information on spectrogram. However, the correlation of
each channels of speech features is failed to explore. Theoretically, each
channel map of speech features obtained by different convolution kernels
contains information with different scales demonstrating strong correlations.
To fill this gap, we propose a novel dual-branch architecture named
channel-aware dual-branch conformer (CADB-Conformer), which effectively
explores the long range time and frequency correlations among different
channels, respectively, to extract channel relation aware time-frequency
information. Ablation studies conducted on DNS-Challenge 2020 dataset
demonstrate the importance of channel feature leveraging while showing the
significance of channel relation aware T-F information for speech enhancement.
Extensive experiments also show that the proposed model achieves superior
performance than recent methods with an attractive computational costs.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>

</body>

<footer>
    <div>
        <time id="build-timestamp" datetime="2024-07-21T05:24:26.576302258Z">
            2024-07-21 05:24:26 UTC
        </time>
    </div>
</footer>
<script src="index.js"></script>
</html>
